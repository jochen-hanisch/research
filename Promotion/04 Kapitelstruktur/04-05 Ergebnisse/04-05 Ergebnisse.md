\newpage

# 5 Ergebnisse {#sec:Ergebnisse}

Dieses Kapitel führt die empirischen und modellbasierten Befunde zusammen. Es schlägt die Brücke von der Methodologie \hyperref[sec:Methodologie]{Kapitel 4} zur Interpretation in \hyperref[sec:Diskussion]{Kapitel 6} und strukturiert die Ergebnisdarstellung entlang der in in diesem Kapüitel dokumentierten Kernbereiche. Die Ergebnisse werden dabei durchgängig auf die in \hyperref[sec:Theorieteil]{Kapitel 2} entwickelten theoretischen Annahmen und die in \hyperref[sec:Forschungsgegenstand]{Kapitel 3} beschriebene Architektur des Forschungsgegenstandes zurückbezogen.

## 5.1 Überblick und Einordnung {#sec:Ergebnisse-Ueberblick}

#todo Kurzüberblick der wichtigsten Ergebnislinien ergänzen (pro Kernbereich 1–2 Sätze als Hinführung zu Abschnitt 5.2 und 5.3).

## 5.2 Verteilung der Analysen nach Kernbereichen {#sec:Ergebnisse-Verteilung}

Die detaillierte Verteilung der 797 ausgewerteten Analysen auf die einzelnen Forschungsunterfragen (FU1–FU7) ist in Kapitel 3, Quellenanalyse, dokumentiert. Für die Ergebnisdarstellung werden die Forschungsunterfragen zu vier Kernbereichen gebündelt:

- **Kernarchitektur (FU3, FU4a, FU5)** – mit rund 58 % der Analysen der empirische Schwerpunkt der Arbeit (Konzeption, Mechanismen, Möglichkeiten/Grenzen des Learning Management System (LMS)).  
- **Nutzungserleben & Gestaltung (FU1, FU2a, FU4b)** – knapp 30 % der Analysen zu Akzeptanz, subjektivem Lernerleben und technisch-gestalterischen Mechanismen.  
- **Kompetenzorientierung (FU6)** – gut 8 % der Analysen zur Rolle des LMS als Kompetenzerwerbssystem.  
- **Rollen & Strategien (FU2b, FU7)** – rund 4 % der Analysen, die vertiefende Einsichten in Lehrendensicht und strategische Gestaltungsentscheidungen liefern.

Diese Bündelung dient als Strukturierungsrahmen für die Präsentation der Ergebnisse und macht transparent, welche Themenfelder auf einer breiten quantitativen Materialbasis beruhen und wo stärker qualitativ-interpretative Verdichtung im Vordergrund steht.

## 5.3 Beantwortung der Forschungsfragen {#sec:Ergebnisse-Forschungsfragen}

Die Darstellung folgt der in Abschnitt 5.2 beschriebenen Gewichtung der Kernbereiche. Zunächst werden die Forschungsfragen zur Kernarchitektur behandelt, anschließend Nutzungserleben & Gestaltung, danach die Kompetenzorientierung und zum Schluss Rollen & Strategien.
#todo Eye-Tracking: exemplarische Abbildungen je Stimulus (Heatmaps) einbinden und Verweis auf Anhang A.7 für komplette Bildreihen ergänzen.

### 5.3.1 FU3: Didaktische und technologische Merkmale {#sec:Ergebnisse-FU3}

### 5.3.2 FU4a: Bildungswissenschaftliche Mechanismen {#sec:Ergebnisse-FU4a}

### 5.3.3 FU5: Möglichkeiten und Grenzen {#sec:Ergebnisse-FU5}

### 5.3.4 FU1: Akzeptanz und Nützlichkeit {#sec:Ergebnisse-FU1}

#todo Eye-Tracking-Befunde (z.B. F10-S3/F11-S3 Gesamt-Visuals) hier knapp einbinden und mit Umfrage-Ergebnissen spiegeln. Triangulation\label{term:triangulation} mit Umfragewerten ergänzen.

### 5.3.5 FU2a: Effekt auf Lernende {#sec:Ergebnisse-FU2a}

#todo Eye-Tracking-Befunde (F10-S3/F11-S3) zur Nutzung/Orientierung aufnehmen und gegen subjektive Angaben stellen.

### 5.3.6 FU4b: Technisch-gestalterische Mechanismen {#sec:Ergebnisse-FU4b}

Das webcam-basierte Eye-Tracking zeigt klare Mechanismen: (1) Orientierung geht Inhalten voraus; Fixationen starten auf Navigation/Breadcrumbs, erst danach folgen Inhaltszonen. (2) Ein Expertisegradient\label{term:expertisegradient} verschiebt die Muster von breiter Suche (1. Jahr) über fokussierte Pfade (2. Jahr) hin zu kurzen, zielgerichteten Scanpaths\label{term:scanpath} (3. Jahr). (3) Salienz konkurriert mit Funktion: starke Bilder ziehen Hotspots von Buttons ab; reduzierte Layouts erhöhen die Fixationsdichte auf Interaktionen. (4) Rechtsbündige Steuerungselemente werden verspätet fixiert, links/oben platzierte Navigation und Progress-Indikatoren fungieren als Anker. (5) Triangulation mit der Umfrage: hohe Bewertungen für Struktur/Klarheit stützen die beobachtete Orientierung, niedrige Interaktionswerte passen zu spät fixierten Steuerungselementen. Gestalterisch folgen daraus Salienzsteuerung zugunsten funktionaler Elemente, Reduktion von Ablenkungsflächen und eine expertise-adaptive UI-Logik. Vollständige Bildreihen sind in \hyperref[sec:A-7]{Anhang A-7} dokumentiert.

### 5.3.7 FU6: LMS als Kompetenzerwerbssystem {#sec:Ergebnisse-FU6}

Der digitale Bildungsraum wirkt als erste professionelle Handlungssituation. Die invariante Aufgabenarchitektur zwingt Lernende zu Orientierung, Musterbildung und operativer Auswahl – exakt den Operationen, die § 4 NotSanG/Anlage 1 verlangt. Eye-Tracking belegt, dass diese Operationen schon im Interface sichtbar sind (Orientierung -> Stabilität -> Handlung). Die Umfrage zeigt parallele Jahrgangsgradienten (unsicher -> stabil -> souverän) und hohe Relevanz der Struktur. Die in \hyperref[tab:lms-konsequenzen]{Tabelle \ref{tab:lms-konsequenzen}} abgeleiteten rechtlich-funktionalen Anforderungen bilden dabei den normativen Rahmen, in dem diese Ergebnisse verortet werden. Damit generiert das LMS den Kompetenzerwerb nicht ergänzend, sondern konstitutiv. Visualisierungen sind in \hyperref[sec:A-7]{Anhang A-7} dokumentiert.

### 5.3.8 FU2b: Effekt auf Lehrende {#sec:Ergebnisse-FU2b}

### 5.3.9 FU7: Erweiterung von Kausalgesetzen {#sec:Ergebnisse-FU7}

## 5.4 Zusammenfassung der Ergebnisse {#sec:Ergebnisse-Zusammenfassung}

#todo Kurze Verdichtung der wichtigsten Befunde als Brücke zur Diskussion in Kapitel 6.
Diese Ergebnisbündelung fungiert als direkte Brücke in die interdependente Diskussion (\hyperref[sec:Diskussion-Interdependenz]{Kapitel 6.3.1}) und liefert die empirische Grundlage für die manifestartige Verdichtung in \hyperref[sec:Conclusio-Manifest]{Kapitel 7}.

### 5.4.1 Arbeitshypothesen aus der Triangulation {#sec:Ergebnisse-Arbeitshypothesen}

Die nachfolgenden Arbeitshypothesen dienen der begründeten Verdichtung der Ergebnislinien und verbinden (a) die P‑QIA-Metaanalysen der FU (Anhang \hyperref[sec:A-9]{A‑9}), (b) die qualitativ rekonstruierten Eye-Tracking-Befunde (Kapitel \hyperref[sec:Ergebnisse-FU4b]{5.3.6} sowie Anhang \hyperref[sec:A-7]{A‑7}) und (c) die deskriptiven Umfragebefunde (Anhang \hyperref[sec:A-12]{A‑12}). Sie sind nicht als inferenzstatistische Hypothesentests formuliert, sondern als prüfbare, FU‑geleitete Mechanismen, die die interdependente Diskussion in Kapitel \hyperref[sec:Diskussion]{6} strukturieren.

#### Kernhypothesen

**K1: Salienz erzeugt Statusmodus (Überblick) statt Lernhandlungsmodus (Bearbeitung).**  
Die P‑QIA-Ergebnisse zu FU4b zeigen, dass visuelle Hierarchie, Salienzsteuerung und Feedback-/Fortschrittsvisualisierungen als wiederkehrende Gestaltungslinien beschrieben werden (Anhang \hyperref[sec:A-9-FU4b]{A‑9‑FU4b}). Die Eye-Tracking-Befunde stützen diese Linie empirisch, indem sie wiederholt Ankerbildungen auf navigationellen und statusbezogenen Elementen vor nachgeordneten Handlungszonen rekonstruieren (Kapitel \hyperref[sec:Ergebnisse-FU4b]{5.3.6}; Anhang \hyperref[sec:A-7]{A‑7}). Zugleich zeigen die Umfragewerte, dass Fortschritts- und Bewertungssysteme eher als mittelgradig unterstützend erlebt werden (Anhang \hyperref[sec:A-12]{A‑12}, Item Q08), was auf eine mögliche Diskrepanz zwischen Sichtbarkeit und didaktischem Nutzen verweist. Daraus folgt die Hypothese, dass starke, statusorientierte Salienz zwar Orientierung stabilisiert, aber die Überleitung in konkrete Lernhandlungen nicht automatisch herstellt. Prüfbarkeit entsteht über die systematische Gegenüberstellung von (a) salienzdominanten Zonen (z.B. Progress/CTA) und (b) handlungsrelevanten Zonen (z.B. Auswahl/Weiterarbeit) in den Eye-Tracking-Visualisierungen sowie der Parallelität zu den Umfragetendenzen zu Fortschritt, Feedback und Interaktion (Anhang \hyperref[sec:A-12]{A‑12}).

**K2: UI-Komplexität erhöht Orientierungskosten und fragmentiert Verarbeitung.**  
Die P‑QIA-Ergebnisse zu FU1 zeigen, dass Benutzerfreundlichkeit/Orientierung und technische Rahmenbedingungen als zentrale Bedingungen von Akzeptanz und Nutzung wiederkehren (Anhang \hyperref[sec:A-9-FU1]{A‑9‑FU1}). In den Eye-Tracking-Visualisierungen treten bei navigations- und optionsreichen Oberflächen wiederkehrend explorative Suchmuster und peripher bleibende Bereiche auf, was als erhöhte extrinsische kognitive Belastung interpretierbar ist (Kapitel \hyperref[sec:Ergebnisse-FU4b]{5.3.6}; Anhang \hyperref[sec:A-7]{A‑7}). Die Umfragebefunde ergänzen dies, indem (a) die UI als Interaktionsfaktor im Zeitverlauf weniger positiv bewertet wird und (b) Ressourcen-/Integrationsaspekte in Teilen kritisch ausfallen (Anhang \hyperref[sec:A-12]{A‑12}, Items Q06, Q13, Q14). Zusätzlich verdichten die Freitextkommentare das Muster „Überblicken statt Verarbeiten“ und betonen Einfachheit/Reduktion als Bedingung (Anhang \hyperref[sec:A-12]{A‑12}). Daraus folgt die Hypothese, dass Komplexität nicht nur die Nutzung verlangsamt, sondern den Wahrnehmungsmodus in eine orientierungsdominante Exploration verschiebt, wodurch inhaltliche Verarbeitung und zielgerichtete Handlung erschwert werden. Prüfbarkeit ergibt sich über die konsistente Kopplung von explorativen Blickpfaden/Coldspots an Handlungszonen mit den Umfragetendenzen zu UI, Zugriff und Integration (Anhang \hyperref[sec:A-12]{A‑12}).

#### Nebenhypothesen

**N1: Soziale Interaktion benötigt visuelle und didaktische Trigger nahe an Rezeption.**  
Die P‑QIA-Ergebnisse zu FU4a und FU2a/FU2b betonen soziale Interaktion, Feedback und strukturierte Kooperation als Mechanismen bzw. Effektbedingungen (Anhang \hyperref[sec:A-9-FU4a]{A‑9‑FU4a}, \hyperref[sec:A-9-FU2a]{A‑9‑FU2a}, \hyperref[sec:A-9-FU2b]{A‑9‑FU2b}). Eye-Tracking zeigt zugleich, dass Rezeptionszonen (z.B. Video/Leitfragen) die Aufmerksamkeit dominieren können und Handlungsangebote nur dann zuverlässig folgen, wenn sie unmittelbar gekoppelt sind (Kapitel \hyperref[sec:Ergebnisse-FU4b]{5.3.6}; Anhang \hyperref[sec:A-7]{A‑7}). Die Umfragewerte zu Diskussion/Austausch und Kollaboration liegen überwiegend im neutralen Bereich (Anhang \hyperref[sec:A-12]{A‑12}, Items Q04 und Q05). Daraus folgt die Hypothese, dass soziale Funktionen zwar vorhanden sein können, aber ohne lokal sichtbare Trigger (räumliche Kopplung, klare Affordanzen) nicht stabil in Lernhandlungen überführt werden. Prüfbarkeit ergibt sich über die Prüfung, ob Social-CTAs in den Visualisierungen tatsächlich in der Nähe der Rezeptionsanker liegen und ob dies mit höheren Interaktionsbewertungen korrespondiert (Anhang \hyperref[sec:A-12]{A‑12}).

**N2: Personalisierung bleibt subjektiv „unsichtbar“, wenn Filterzustände nicht handlungsleitend sind.**  
Die P‑QIA-Ergebnisse zu FU2a/FU4a machen Passung, Selbststeuerung und Personalisierung als wiederkehrende Bedingung wirksamer Lernprozesse sichtbar (Anhang \hyperref[sec:A-9-FU2a]{A‑9‑FU2a}, \hyperref[sec:A-9-FU4a]{A‑9‑FU4a}). Eye-Tracking zeigt bei filter-/kartenbasierten Oberflächen häufig eine „above-the-fold“-Dominanz und peripher bleibende Bereiche, was nahelegt, dass Steuerungsoptionen zwar wahrgenommen, aber nicht zwingend als wirksam erlebt werden (Anhang \hyperref[sec:A-7]{A‑7}). Parallel fällt die Umfragebewertung zur Adaptivität niedrig aus (Anhang \hyperref[sec:A-12]{A‑12}, Item Q10). Daraus folgt die Hypothese, dass Personalisierungsfunktionen erst dann als Adaptivität erlebt werden, wenn ihr Zustand und Ergebnis unmittelbar sichtbar und handlungsleitend ist (z.B. klare Rückmeldung „Filter wirkt“ und reduzierte Wahlkomplexität). Prüfbarkeit ergibt sich über den Vergleich von filterzentrierten Blickstarts, der tatsächlichen Bündelung der Exploration und den Adaptivitätsurteilen (Anhang \hyperref[sec:A-12]{A‑12}).

**N3: Feedbackqualität wird primär durch Prozessqualität bestimmt, nicht durch UI-Sichtbarkeit.**  
Die P‑QIA-Ergebnisse zu FU2a und FU6 verorten Effekte von Feedback in seiner Qualität, Verlässlichkeit und organisatorischen Einbettung (Anhang \hyperref[sec:A-9-FU2a]{A‑9‑FU2a}, \hyperref[sec:A-9-FU6]{A‑9‑FU6}). Eye-Tracking kann Sichtbarkeit und Ankerbildung von Status-/Feedbackelementen rekonstruieren, liefert aber keine direkte Aussage zur inhaltlichen Qualität des Feedbacks (Kapitel \hyperref[sec:Ergebnisse-FU4b]{5.3.6}; Anhang \hyperref[sec:A-7]{A‑7}). Die Umfrage zeigt zugleich eher niedrige Werte für zeitnahes/hilfreiches Feedback (Anhang \hyperref[sec:A-12]{A‑12}, Item Q07), was nahelegt, dass sichtbare Statusanzeigen allein nicht ausreichen. Daraus folgt die Hypothese, dass UI-Sichtbarkeit von Feedback nur dann positiv wirkt, wenn die zugrunde liegende Feedbackpraxis (Timing, Spezifität, Dosierung) didaktisch konsistent realisiert ist. Prüfbarkeit entsteht über die kombinierte Analyse: (a) Sichtbarkeits-/Ankerindikatoren in den Visualisierungen und (b) Umfrageurteile zu Feedback, flankiert durch die FU‑Verdichtungen zu Prozess-/Kulturbedingungen (Anhang \hyperref[sec:A-9]{A‑9}).
