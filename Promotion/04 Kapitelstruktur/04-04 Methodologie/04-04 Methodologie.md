\newpage

# 4 Methodologie {#sec:Methodologie}

Kapitel 4 stellt die in dieser Arbeit entwickelte, eigenständige Methodologie dar und spiegelt sie an den wissenschaftlichen Gütekriterien. Das methodische Vorgehen folgt nicht einem klassischen Mixed‑Methods‑Design, sondern einem selbst entwickelten, systemisch‑forschungsfragengeleiteten Paradigma. Dieses Paradigma orientiert sich an systemtheoretischen Prinzipien, koppelt qualitative, quantitative und simulationsbasierte Verfahren über die Forschungsunterfragen und bindet sowohl die in \hyperref[sec:Theorieteil]{Kapitel 2} entwickelte Theorie als auch die in Kapitel \@ref(sec:Forschungsgegenstand) dargestellte Architektur des digitalen Bildungsraums ein. Ziel ist es, die zirkuläre Komplexität des Forschungsgegenstandes abzubilden und methodisch zu strukturieren. Die Auswahl der Verfahren – darunter Literaturanalysen, Eye‑Tracking\label{term:eye-tracking} [@hanisch-johannsen_wirkgefuge_2025-1], simulationsgestützte Modellierungen und quantitative Evaluationsansätze – folgt ausschließlich der Logik der Forschungsunterfragen und dient nicht der Umsetzung eines etablierten Methodendesigns, sondern der Realisierung eines kohärenten, interdependenten und emergenzsensiblen Forschungsansatzes.

Die methodische Kopplung liefert die empirische Basis für die interdependente Argumentation in \hyperref[sec:Diskussion-Interdependenz]{Kapitel 6.3.1} und die manifestartige Zuspitzung in \hyperref[sec:Conclusio-Manifest]{Kapitel 7}.

## 4.1 Forschungsparadigma und methodologischer Ansatz {#sec:Forschungsparadigma}

\label{term:systemisch-forschungsfragengeleitet}

Methodenkompetenz in den Human- und Sozialwissenschaften meint nach @doring_forschungsmethoden_2023 die Fähigkeit, empirische Studien zu lesen, zu interpretieren und eigenständig durchzuführen, um systematische und nachvollziehbare Erkenntnisse zu gewinnen. In der empirischen Sozialforschung werden traditionell drei methodologische Paradigmen unterschieden [@doring_forschungsmethoden_2023, Seiten 4–5 und 32–33]:

a. quantitative Ansätze im kritischen Realismus,
b. qualitative Ansätze im Sozialkonstruktivismus und
c. pragmatische Integrationsansätze, die beide Logiken situativ verbinden.

Weiterhin stellt @doring_forschungsmethoden_2023 dar, dass das quantitative Paradigma einem linear‑strukturierten Forschungsprozess mit vorab formulierten Hypothesen folgt, während das qualitative Paradigma einen zirkulären, offen strukturierten Prozess mit explorativen Fragestellungen abbildet. Ausschlaggebend ist weniger die Datenform als die Frage, welches Vorgehen die Forschungsfragen angemessen bearbeitet. Dieses Begründungsgebot strukturiert auch den hier entwickelten systemischen Ansatz. [@doring_forschungsmethoden_2023, Kapitel 2.2 und 2.3]

Für das vorliegende Forschungsvorhaben reicht keines dieser Paradigmen aus, weil der Gegenstand zirkulär angelegt ist und die Verfahren deshalb eng aufeinander bezogen werden müssen. Stattdessen wird ein eigenständiger, systemisch‑forschungsfragengeleiteter Ansatz entwickelt, der die Verfahren über die Forschungsunterfragen verbindet. Ob diese Logik trägt, wird im Kapitelverlauf eingelöst:

- Abschnitt 4.1 beschreibt den erkenntnistheoretischen Rahmen.
- Abschnitt 4.1.1 erläutert die methodischen Vorüberlegungen (Auswahl und Kombination der Verfahren aus den Forschungsfragen) und begründet die Kopplung sowie Methodenwahl.
- Abschnitt 4.1.2 erläutert die systemische Integrationslogik und ordnet die Verfahren den Forschungsunterfragen zu.
- Abschnitt 4.2 beschreibt die Datenerhebungsverfahren.

### 4.1.1 Vorüberlegungen zur Methodologie {#sec:Voruberlegungen-Methodologie}

Methodisch herausfordernd ist die Verbindung der unterschiedlichen Facetten dieses bildungstheoretischen Forschungsvorhabens. Die Datenformen aus Eye‑Tracking [@hanisch-johannsen_wirkgefuge_2025-1], Umfrage [@hanisch-johannsen_wirkgefuge_2025], systematischer Literaturarbeit und simulationsgestützter Modellierung werden entlang der Forschungsfragen koordiniert und in einem eigenen Integrationsprinzip zusammengeführt. Diese Integration folgt keinem etablierten Kombinationsschema; sie orientiert sich an der Logik der Forschungsfragengeleitetheit. Die Hauptforschungsfrage legitimiert dabei sowohl qualitative als auch quantitative Zugriffe, weil sie Muster und Regelmäßigkeiten im Learning Management System (LMS) sichtbar machen soll. Das Spannungsfeld zwischen subjektiven Akteur*innenurteilen und einer formalisierenden, modellbasierten Dynamikperspektive verlangt eine präzise methodische Betrachtung. Die strikt getrennte Zuschreibung „quantitativ = deduktiv“ und „qualitativ = induktiv“ greift dabei zu kurz, weil sie die Komplexität des Gegenstands nicht abbildet [@reinders_uberblick_2022, Seite 157].

Forschung in Gesundheitskontexten muss divergierende methodische Strömungen mehrerer Disziplinen integrieren. Komplexität, Vielfalt der Disziplinen und unterschiedliche Ressourcen sind auszubalancieren; deshalb werden hier die Stärken bestehender Methoden in einen neuen, interdisziplinären und generativen Kontext gestellt [@niederberger_qualitative_2021, Seite 4-5].

Der hier entwickelte Ansatz verzichtet bewusst auf die Einordnung in Mixed‑Methods‑Traditionen. Stattdessen werden qualitative, quantitative und simulationsbasierte Verfahren so gekoppelt, dass sie die zirkuläre Komplexität des Forschungsgegenstandes systemisch abbilden. Die Methoden stehen nicht nebeneinander, sondern werden über Interdependenz, Emergenz und Rückkopplung verbunden.

Das Forschungsvorhaben verlangt aufgrund seiner zirkulären Komplexität einen mehrdimensionalen Ansatz, der die Ebenen systematisch koppelt. Wie Rosenthal und Witte ausführen, stützt sich die Methodik auf die Anerkennung unterschiedlicher Zugänge zur Erforschung sozialer Phänomene und auf die grundlagentheoretische Differenzierung zwischen quantitativen und qualitativen bzw. interpretativen Ansätzen [@mays_quanti_2020, Seite 198-199]. Die Arbeit positioniert sich als abstrakt-theoretische Grundlagenforschung und will methodische Vielfalt anerkennen sowie systematisch integrieren.

Das forschungsparadigmatische Spannungsfeld wird aufgelöst, indem die Methoden konsequent aus den Forschungsfragen abgeleitet werden. Dadurch entsteht eine zielgerichtete Auswahl, die Komplexität reduziert, der Mehrdimensionalität gerecht wird und die Stärken etablierter Methoden bündelt.

Die dargestellten Vorüberlegungen verdeutlichen, dass die Methodologie nicht durch bestehende Designs vorstrukturiert ist, sondern ihre Logik unmittelbar aus den Forschungsunterfragen ableitet. Darauf aufbauend entwickelt Abschnitt 4.1.2 die systemische Ausgestaltung dieses Ansatzes und präzisiert die operative Verbindung zwischen Paradigma, Forschungslogik und Methodenwahl.

### 4.1.2 Systemisch-forschungsfragengeleiteter Ansatz {#sec:Systemisch-Forschungsfragengeleitet}

Der systemische, forschungsfragengeleitete Ansatz fußt auf den Forschungsfragen FU$_{1}$ bis FU$_{7}$ (\hyperref[sec:FU-Herleitung]{Abschnitt 1.4}), abgeleitet aus Erkenntnisinteresse (\hyperref[sec:Erkenntnisinteresse]{Abschnitt 1.1.1}) und LMS-Produkt (\hyperref[sec:Forschungsgegenstand]{Kapitel 3}). Diese Fragen strukturieren sämtliche Entscheidungen und Analysen. Diese Methodik verschränkt qualitative, quantitative und simulationsbasierte Zugänge über die Logik der Forschungsunterfragen, ohne sie einem übergeordneten Mixed‑Methods‑Schema zu unterstellen. Die Verbindung entsteht ausschließlich über die Forschungsfragen und ihre systemische Logik.

Interdependenz meint die enge Verknüpfung der Forschungsfragen und die Wechselwirkungen zwischen qualitativen und quantitativen Daten, die die Mehrdimensionalität erfassen. Emergenz beschreibt die Entstehung neuer Erkenntnisse [@bertalanffy_general_1968, Seite 16, 103], wenn Ergebnisse aus Literaturanalysen, Simulationen und empirischen Untersuchungen wie Eye-Tracking [@hanisch-johannsen_wirkgefuge_2025-1] und Befragungen [@hanisch-johannsen_wirkgefuge_2025] verbunden werden. Rückkopplung heißt, dass Analyseergebnisse iterativ in die Methodik zurückfließen und weitere Schritte steuern, sodass der Prozess dynamisch bleibt.


Konkret werden Methoden aus den Forschungsfragen abgeleitet; jede Frage bestimmt die Auswahl. Qualitative Literaturanalysen werden mit Eye-Tracking-Analysen (z.B. Heatmaps) [@hanisch-johannsen_wirkgefuge_2025-1] und quantitativen Befragungen [@hanisch-johannsen_wirkgefuge_2025] systematisch in Beziehung gesetzt, um subjektive Wahrnehmungen und beobachtbare Nutzungsmuster zugleich abzubilden. Die passgenaue Methodenkombination reduziert Komplexität auf ein analytisch erfassbares Maß, ohne wesentliche Wirkungsmechanismen zu verlieren. Iterative Rückkopplung und systemische Verknüpfung erzeugen Einsichten, die isoliert verborgen blieben, und erweitern bestehende Ansätze um einen Rahmen, der Offenheit und strukturelle Präzision verbindet.

Auf dieser Grundlage beschreibt Abschnitt 4.2 die konkrete Umsetzung der Datenerhebungsverfahren. Die dort erläuterten Schritte – von der systematischen Literaturrecherche über das Eye-Tracking [@hanisch-johannsen_wirkgefuge_2025-1] bis zur LMS‑Umfrage [@hanisch-johannsen_wirkgefuge_2025] – sind direkt aus der hier beschriebenen Paradigma‑Logik abgeleitet und folgen der systemischen Kopplung der Forschungsunterfragen.

Table: Zuordnung der Bearbeitungsmethoden zu den Forschungsunterfragen {#tab:methoden_FU}

| Forschungsunterfrage | Bearbeitungsmethode | Erfüllungskriterien |
| --- | --- | --- |
| **FU$_{1}$: Akzeptanz und Nützlichkeit** | Qualitative Metaanalyse zur Darstellung des aktuellen Forschungsstandes im Kontext digitaler Bildungsräume [@doring_forschungsmethoden_2023, Seite 194]. | Darstellung und Einordnung der Akzeptanz- und Nutzenargumente in das Gesamtgefüge. |
| **FU$_{2a}$: Effekt auf Lernende** | An Evaluationslogiken (Kirkpatrick, TEI) anschließende Literaturanalyse (Primär-/Sekundäranalyse + P‑QIA) sowie quantitative LMS‑Umfrage (UM1) [@hanisch-johannsen_wirkgefuge_2025] zur Spiegelung zentraler Wirkungsdimensionen [@kirkpatrick_evaluating_1998; @ritzmann_training_2014; @ritzmann_tei_2020]. | Rekonstruktion der Effektdimensionen (z.B. Reaktion/Lernen) und ihrer Bedingungen; triangulative Einordnung über Umfrage- und Nutzungsdaten. |
| **FU$_{2b}$: Effekt auf Lehrende** | Literaturanalyse (Primär-/Sekundäranalyse + P‑QIA) zur Rekonstruktion von Lehrendenbedingungen (Kompetenzen, Monitoring/Assessment, Belastungen) sowie Kontextspiegelung über LMS‑Umfrage (UM1) [@hanisch-johannsen_wirkgefuge_2025]. | Ableitung plausibler Einflussfaktoren und Arbeitsbedingungen; Zusammenführung zu überprüfbaren Tendenzaussagen. |
| **FU$_{3}$: Didaktische und technologische Merkmale** | Theoriearbeit zur systemisch-konstruktivistischen Gestaltung des LMS und zur Beschreibung seiner Architektur [@doring_forschungsmethoden_2023, Kapitel 6.3.1]. | Herleitung, Beschreibung und Absicherung der relevanten Merkmale des LMS. |
| **FU$_{4a}$: Bildungswissenschaftliche Mechanismen** | Qualitative Inhaltsanalyse nach Mayring sowie deren Weiterentwicklungen [@mey_qualitative_2010; @mayring_neuere_2008]. | Herleitung, Beschreibung und Absicherung der bildungswissenschaftlichen Wirkmechanismen. |
| **FU$_{4b}$: Technisch-gestalterische Mechanismen** | Quantitative Beobachtung (inkl. Eye-Tracking [@hanisch-johannsen_wirkgefuge_2025-1]) zur Rekonstruktion technisch-gestalterischer Wirkmechanismen [@doring_forschungsmethoden_2023, Kapitel 10.1.3]. | Datenerhebung, Auswertung sowie Rückbindung an die systemische Einordnung der Mechanismen. |
| **FU$_{5}$: Möglichkeiten und Grenzen** | Kombination aus Qualitativer Inhaltsanalyse und SWOT-Analyse zur systemischen Bewertung [@mey_qualitative_2010; @niederberger_swot-analyse_2015]. | Strukturierte Darstellung der Potenziale und Limitationen des Trainingsmodells. |
| **FU$_{6}$: LMS als Kompetenzerwerbssystem** | Systemische Theoriearbeit zur Verschränkung von Kompetenzforschung und LMS-Architektur [@doring_forschungsmethoden_2023, Kapitel 5] sowie simulationsgestützte Modellierung zur dynamischen Plausibilisierung (Abschnitt \hyperref[sec:Simulation-Kompetenzentwicklung]{4.4}). | Transfer und Einordnung der Ergebnisse in ein konsistentes Kompetenzentwicklungsmodell; dynamische Verdichtung zentraler Kopplungen als Reflexionsfolie. |
| **FU$_{7}$: Erweiterung von Kausalgesetzen** | Grounded-Theory-basierte „Einfall und Theorieentwicklung“ sowie Analyse des Technologiedefizits [@pentzold_praxis_2018, Einleitung; @luhmann_technologiedefizit_1982]. | Entwicklung und Ableitung eines kausalen Ursachen-Wirkungstheoriemodells. |

```{=latex}
\tabsubcaption{Übersicht der forschungsfragengeleiteten Methodenkopplung. Dargestellt ist die Zuordnung der Forschungsunterfragen (FU$_{1}$--FU$_{7}$) zu Bearbeitungsmethoden und den jeweiligen Erfüllungskriterien; die Tabelle dient als Orientierungsfolie für die Triangulation der Datensorten (Literatur/P-QIA, Eye-Tracking, UM1, Simulation).}
```

Die Tabelle fasst die Forschungsunterfragen zusammen und verknüpft sie mit den jeweils eingesetzten Methoden sowie ihren Erfüllungskriterien. Auf diese Weise wird nachvollziehbar, wie qualitative Literaturarbeit, empirische Erhebungen (Eye-Tracking [@hanisch-johannsen_wirkgefuge_2025-1], Umfragen [@hanisch-johannsen_wirkgefuge_2025]) und simulationsbasierte Verfahren im Zusammenspiel verwendet wurden, um die unterschiedlichen Facetten des Lernmanagementsystems abzubilden. Die P‑QIA‑Auswertungen (Analysen dritter Ordnung; Abschnitt \hyperref[sec:P-QIA]{4.3.4}) werden FU‑übergreifend auf den Literaturkorpus angewandt; FU‑spezifische empirische Erhebungen dienen der Spiegelung und Triangulation der rekonstruierten Tendenzen.

Methodisch ist dabei zu betonen, dass die LMS‑Umfrage (UM1) [@hanisch-johannsen_wirkgefuge_2025] eine eigenständige, quantitative Perspektive in den Analyseprozess einbringt. Sie erweitert die Evidenzbasis um standardisierte Urteile zu Struktur, Interaktion, Feedback und Adaptivität und ermöglicht damit eine Spiegelung der literaturbasiert rekonstruierten Wirkannahmen (FU$_{1}$/FU$_{2a}$/FU$_{2b}$) an einer eigenen Datenerhebung im Systemkontext. Die Umfrage ist Teil der triangulativen Kopplung (Literatur/P‑QIA × Eye‑Tracking [@hanisch-johannsen_wirkgefuge_2025-1] × UM1) und macht Tendenzen sowie Spannungsfelder (z.B. wahrgenommene Interaktion vs. beobachtete Orientierungsmuster) sichtbar; zugleich bleibt die Datensorte klar konturiert, da sie auf standardisierten Selbstauskünften beruht.

Methodische Konsequenzen der Forschungsfragen

- Die Forschungsfragen bestimmten:
  - Auswahl und Strukturierung der Literatur.
  - Entwicklung von Kategorien und Schlagworten zur thematischen Verknüpfung.
  - Kombination und Anpassung klassischer Methoden.
- **Begründung**:
  - Die Komplexität des digitalen Bildungsraums erforderte eine Methodenkombination, um die Forschungsfragen adäquat zu beantworten.

## 4.2 Datenerhebung {#sec:Datenerhebung}

### 4.2.1 Systematische Literaturrecherche {#sec:Systematische-Literaturrecherche}

Die systematische Literaturrecherche bildet die Grundlage für die Beantwortung der Forschungsfragen FU$_{1}$, FU$_{3}$, FU$_{4a}$ und FU$_{6}$. Ziel ist hierbei, ein umfassendes Verständnis der bestehenden wissenschaftlichen Diskussionen und Erkenntnisse im Bereich digitaler Bildungsräume zu erlangen. Der Korpus umfasst insgesamt 3 733 wissenschaftliche Arbeiten, die algorithmisch aus verschiedenen Datenbanken extrahiert und thematisch kategorisiert wurden (Datenstand: 13.12.2025).

Die systematische Literaturrecherche folgt einem klar definierten, mehrstufigen Workflow (vgl. Abbildung X). Ausgangspunkt sind zwei kontinuierliche Zuführungen von Quellen: (1) automatisierte Google-Alerts, die einschlägige Veröffentlichungen zu vordefinierten Stichworten melden, und (2) zufällige Quellenfunde, die im Rahmen der laufenden Forschungs- und Praxistätigkeit auftreten. Beide Zuführungen werden zunächst als „Einzelne Quelle“ in das Literaturmanagementsystem überführt und mit den notwendigen Metadaten (Titel, Autor*in, Jahr, Publikationstyp) versehen.

In einem ersten Entscheidungsschritt wird die Verfügbarkeit der Quelle geprüft (Zugriff auf Volltext, Abstract, bibliografische Angaben). Ist der Volltext nicht zugänglich, kann die Quelle dennoch als Impulsgeber für die Suchstrategie dienen, wird aber nicht in die inhaltliche Hauptanalyse übernommen. Verfügbare Quellen durchlaufen eine Prüfung, ob sich aus ihnen konkrete Suchbegriffe ableiten lassen. Ergibt sich ein inhaltlicher Mehrwert, werden sie im Sinne einer „Erweiterung“ genutzt, um das Suchvokabular zu verfeinern und zusätzliche, thematisch angrenzende Begriffskombinationen zu identifizieren.

Kern der Suchstrategie ist ein Set aus zwölf priorisierten Schlagwortclustern, die jeweils als Suchpfad in unterschiedlichen Datenbanken (z. B. Google Scholar, BASE, FIS Bildung, PubMed) umgesetzt wurden: #1 Learning Management System, #2 Online Lernplattform, #3 Online Lernumgebung, #4 MOOCs, #5 E-Learning, #6 Bildung, #7 Digitale Medien, #8 Blended Learning, #9 Digitales Lernen, #10 Online Lernen, #11 Online Learning und #12 Digital Learning. Jede Quelle wird einem oder mehreren dieser Suchpfade zugeordnet und im Literaturmanagement als „Eintrag DB“ dokumentiert. Die technische Umsetzung der Ordner- und Tag-Struktur wird in \hyperref[sec:Systematisches-Literaturmanagement]{Abschnitt 4.2.2} detailliert beschrieben.

Die Treffer aus allen Suchpfaden werden einem dreistufigen Screening unterzogen, das zugleich die Ein- und Ausschlusskriterien operationalisiert. In der Titel-Suche werden auf Basis von Titel, Jahr, Sprache und Publikationstyp offensichtlich irrelevante oder außerhalb des Forschungsfeldes liegende Arbeiten ausgeschlossen („Ausschluss“). In der nachfolgenden Abstract-Suche erfolgt eine inhaltlich feinere Prüfung, ob die Quelle tatsächlich einen Beitrag zum Verständnis digitaler Bildungsräume, von Learning-Management-Systemen oder angrenzender Formate leistet. Erst wenn die Relevanz auf Abstract-Ebene bestätigt ist, schließt sich – falls erforderlich – eine Inhaltsuche im Volltext an, in der Kontext, Methode und theoretische Verortung geprüft werden. Quellen, die diesen dreistufigen Filter durchlaufen, bilden den Kernkorpus der Analyse.

Für alle übernommenen Quellen wird anschließend ein erstes, manuelles 1. Tagging vorgenommen. Dabei werden unter anderem Suchpfad, Dokumententyp, thematischer Schwerpunkt, Bezug zu Learning-Management-Systemen sowie eine vorläufige Zuordnung zu den Forschungsunterfragen erfasst. Dieses erste Tagging strukturiert das Korpus und legt die Grundlage für die KI-gestützte Inhaltsanalyse. In einem nächsten Schritt wird jede Quelle in einem standardisierten Prompt-Format mit GPT verarbeitet. Die KI erstellt eine strukturierte Zusammenfassung, extrahiert Kernaussagen, rekonstruiert die Argumentation, schlägt eine Indexierung zentraler Begriffe vor, ordnet die Quelle thematischen Kategorien zu, nimmt eine explizite Zuordnung (FU) zu den Forschungsunterfragen vor und formuliert eine graduelle Relevanzbewertung. Die KI-Ausgaben werden nicht ungeprüft übernommen, sondern im Lektüreprozess kontrolliert, gegebenenfalls korrigiert und mit den eigenen Einschätzungen abgeglichen. Der hier eingesetzte Workflow ist kompatibel mit dem bei @hebbel-seeger_wissenschaftliches_2025 genannten, vierphasigen KI-gestützten Rechercheverständnis (Themensondierung, Inhaltsauswertung, Wissensorganisation, Spezialrecherche) und konzipiert KI somit als kognitive Verstärkung bei fortbestehender menschlicher Validierungsverantwortung [@hebbel-seeger_wissenschaftliches_2025, Seite 434-436].

Auf Basis dieser aufbereiteten Informationen erfolgt ein zweites, vertiefendes 2. Tagging. Hier werden die automatisiert vorgeschlagenen Kategorien konsolidiert, die Zuordnung zu den Forschungsunterfragen geschärft und die Relevanzstufen final festgelegt. Gleichzeitig werden zusätzliche Tags vergeben, die für spätere Netzwerk- und Pfadanalysen erforderlich sind (z. B. didaktische Mechanismen, technologische Funktionen, Kompetenzdimensionen). Das Ergebnis ist ein dicht codierter Literaturkorpus, in dem jede Quelle mehrfach – über Suchpfade, Kategorien, Forschungsunterfragen und Relevanzgrade – verknüpft ist.

Im Anschluss werden die kodierten Daten exportiert und in einer statistischen und graphischen Auswertungsumgebung weiterverarbeitet. Dort entstehen unter anderem Netzwerkvisualisierungen der Tag-Struktur sowie Netzwerk-Plotanalysen, die Co-Vorkommen von Kategorien, Forschungsunterfragen und zentralen Konzepten sichtbar machen. Auf dieser Basis wird ein Pfaddiagramm der Datenflüsse im Korpus rekonstruiert, das die Hauptströme von den Suchpfaden über Kerngedanke und Argumentation hin zu Technologieintegration, Lehr-/Lerneffektivität und weiteren Kategorien nachzeichnet. Die so gewonnenen Pfade dienen der Synthese: Sie markieren jene Segmente des Diskurses, in denen sich theoretische und empirische Verdichtungen zeigen, und bilden die Grundlage für die abschließende Modellbildung und theoretische Strukturierung des digitalen Bildungsraums.

Der gesamte Prozess – von Beginn (Google-Alert beziehungsweise zufällige Quelle) über Screening, doppeltes Tagging und KI-Unterstützung bis hin zu Netzwerk- und Pfadanalysen – ist damit als zirkulärer, transparent dokumentierter Recherche- und Analysepfad angelegt. Er stellt sicher, dass die in dieser Arbeit entwickelten Aussagen zu digitalen Bildungsräumen nicht auf Einzelstudien, sondern auf einem systematisch erschlossenen und strukturell ausgewerteten Literaturfeld beruhen.

Die folgende Abbildung (Abb.~\ref{fig:lit-workflow}) fasst diesen Workflow schematisch zusammen und dient als Referenzrahmen für die in Abschnitt 4.3 beschriebenen Auswertungen; für das Verständnis der weiteren Darstellung sind vor allem die Übergänge zwischen Suche, Tagging und Export relevant.

\input{08 Metaquellen/08-01 Abbildungen/prozesse/lit_workflow.tex}

#todo (#81) prüfen ob alle Abbildung auch eingebunden sind

Die folgenden Zeit‑ und Kohärenzvisualisierungen (Abb.~\ref{fig:time-series}, Abb.~\ref{fig:silhouette-scores} und Abb.~\ref{fig:delta-silhouette}) dienen der volumetrischen und strukturellen Einordnung des Literaturkorpus und bilden die Basis für die anschließende Korpusdiagnostik.

![Zeitreihe der Publikationszahlen im Korpus.](<08 Metaquellen/08-01 Abbildungen/methodik/visualize_time_series_02-01_suchergebnisse.png>){#fig:time-series}

```{=latex}
\figsubcaption{Zeitreihe der jährlichen Veröffentlichungszahlen im Literaturkorpus (Quelle: 02-01 Suchergebnisse; $n=3728$, Stand: 2025-11-26). x-Achse: Jahr; y-Achse: Anzahl Veröffentlichungen; dient der volumetrischen Einordnung von Wachstums-, Konsolidierungs- und Reorganisationsphasen sowie der jahrgangsbezogenen Gewichtung in den folgenden Kohärenzanalysen.}
```

Die Zeitreihe der jährlichen Veröffentlichungszahlen beschreibt die volumetrische Entwicklung des untersuchten Literaturkorpus seit den späten 1970er-Jahren. Die Einordnung der sichtbaren Wachstums-, Konsolidierungs- und Reorganisationsphasen sowie ihre Bedeutung für die weitere Korpusdiagnostik erfolgt in Abschnitt \hyperref[sec:Datenanalyse-Grundlogik]{4.3.1}.

Table: Jährliche Entwicklung der Clusterbildung und Silhouette-Scores \label{tab:cluster_silhouette}

| Jahr | $n$ | Cluster | Silhouette-Score |
| --- | --- | --- | --- |
| 2010 | 7 | 2 | 1.0000 |
| 2011 | 29 | 4 | 0.9655 |
| 2012 | 7 | 3 | 0.8571 |
| 2013 | 28 | 4 | 1.0000 |
| 2014 | 24 | 4 | 0.9583 |
| 2015 | 28 | 3 | 1.0000 |
| 2016 | 25 | 3 | 1.0000 |
| 2017 | 98 | 3 | 1.0000 |
| 2018 | 95 | 4 | 0.9895 |
| 2019 | 202 | 3 | 1.0000 |
| 2020 | 303 | 4 | 0.9968 |
| 2021 | 377 | 4 | 0.9854 |
| 2022 | 430 | 4 | 0.9916 |
| 2023 | 899 | 4 | 0.9702 |
| 2024 | 780 | 4 | 0.9208 |
| 2025 | 192 | 4 | 0.9696 |
| **Summe** | 3524 | — | — |

```{=latex}
\tabsubcaption{Jahresbezogene Kennwerte der Clusterkohärenz (Quelle: 02-01 Suchergebnisse). Spalten: Jahr, Fallzahl ($n$), gewählte Clusterzahl ($k$) und Silhouette-Score; Grundlage für die Drift-/Verdichtungsinterpretation und die Gewichtung der Jahrgänge in den folgenden Abbildungen.}
```

Die Tabelle dokumentiert die jahresbezogenen Kennwerte der Clusterkohärenz (Fallzahlen, $k$, Silhouette-Score) als Referenz für die nachfolgende Auswertung; die Einordnung erfolgt in Abschnitt \hyperref[sec:Datenanalyse-Grundlogik]{4.3.1}.

![Silhouette-Scores und Fallzahlen pro Jahr.](<08 Metaquellen/08-01 Abbildungen/methodik/silhouette-scores-und-fallzahlen.png>){#fig:silhouette-scores}

```{=latex}
\figsubcaption{Gemeinsame Darstellung von Clusterkohärenz und Korpusvolumen pro Jahr (Quelle: 02-01 Suchergebnisse). Linke y-Achse: Silhouette-Score der jährlichen $k$-means-Clusterlösung; rechte y-Achse: Fallzahlen ($n$). Horizontale Referenzlinien markieren Quartile (Q1--Q3) der Silhouette-Verteilung und unterstützen die Identifikation von Verdichtungs- vs. Driftphasen.}
```

Die Abbildung stellt Silhouette-Scores und Fallzahlen je Jahr dar und dient als Grundlage für die Auswertung der Kohärenz- und Driftphasen; die Einordnung erfolgt in Abschnitt \hyperref[sec:Datenanalyse-Grundlogik]{4.3.1}.

![Volumengewichtete Abweichung $\Delta SC_n$ der Clusterkohärenz pro Jahr.](<08 Metaquellen/08-01 Abbildungen/methodik/delta-sc-n-pro-jahr.png>){#fig:delta-silhouette}

```{=latex}
\figsubcaption{Volumengewichtete Abweichung der jährlichen Clusterkohärenz vom Referenzniveau (Quelle: 02-01 Suchergebnisse). $\Delta SC_n$ operationalisiert die Differenz des Silhouette-Scores zum Median, gewichtet mit $n/\max(n)$; 0-Linie: Neutralniveau, gestrichelte Linie: Median. Positive Balken markieren überproportional kohärente Jahrgänge (Verdichtung), negative Balken unterproportionale Kohärenz bei hohem Volumen (Drift/Reorganisation).}
```

Die Abbildung dokumentiert die volumengewichtete Abweichung $\Delta SC_n$ als ergänzende Kennzahl zur Kohärenzdiagnostik; die Einordnung erfolgt in Abschnitt \hyperref[sec:Datenanalyse-Grundlogik]{4.3.1}.

### 4.2.2 Systematisches Literaturmanagement {#sec:Systematisches-Literaturmanagement}

Zur Vorbereitung der Datenanalyse wurden in Zotero 12 priorisierte Suchordner (0 bis b) angelegt. Jeder Ordner enthält eine Kombination aus Eintragstyp und Schlagwortkette. Die Titel wurden in der festgelegten Reihenfolge geprüft und beim ersten Treffer mit dem entsprechenden Tag versehen. Die folgende Tabelle zeigt die vollständige Struktur der Suchordner:

Anhang X: Struktur der Suchordner in Zotero nach semantischen Ebenen

Die folgende Tabelle dokumentiert die finale Systematik der Zotero-Suchordner. Diese ist entlang primärer, sekundärer und tertiärer Suchbegriffe gegliedert. Jeder Ordner beinhaltet strukturierte Suchen nach Eintragstypen und thematischen Schlagwörtern. Die ID der Ordner (z. B. `S:01`) korrespondiert mit der Ordnerstruktur in Zotero und wurde zur Tag-Kodierung verwendet.

**Primäre Suchbegriffe**

Table: Übersicht Primäre Suchbegriffe \label{tab:primaere_suchbegriffe}

| **Ordner-ID** | **Begriff**                | **Synonyme / Varianten**                  |
| ------------- | -------------------------- | ----------------------------------------- |
| `S:01`        | Learning Management System | LMS, Lernmanagementsystem, Kursplattform  |
| `S:02`        | Online-Lernplattform       | Lernplattform, Digitale Plattform         |
| `S:03`        | Online-Lernumgebung        | Virtuelle Lernumgebung, Digitale Umgebung |
| `S:05`        | E-Learning                 | Elektronisches Lernen, Digitales Lernen   |

```{=latex}
\tabsubcaption{Primäre Suchbegriffe der Zotero-Suchordnerlogik. Aufgeführt sind Ordner-IDs, Kernbegriffe und Synonyme/Varianten; diese Ebene adressiert den unmittelbaren Forschungsgegenstand und wird mit hoher Sichtungsquote priorisiert.}
```

Die primären Suchbegriffe adressieren den unmittelbaren Forschungsgegenstand. Sie bündeln alle Kombinationen, in denen das LMS oder der digitale Bildungsraum direkt benannt ist. Für diese Cluster gilt eine hohe Sichtungsquote (mindestens 80 %), weil sie die Kernbefunde zur Wirkweise des eingesetzten Systems liefern und den Ausgangspunkt für die Ableitung der Forschungsunterfragen bilden.

**Sekundäre Suchbegriffe**

Table: Übersicht Sekundäre Suchbegriffe \label{tab:sekundaere_suchbegriffe}

| **Ordner-ID** | **Begriff**         | **Synonyme / Varianten**                             |
| ------------- | ------------------- | ---------------------------------------------------- |
| `S:04`        | MOOC                | Massive Open Online Course                           |
| `S:06`        | Bildungstechnologie | EdTech, Technologie im Bildungssektor                |
| `S:07`        | Digitale Medien     | Medienkompetenz, Medientechnologie                   |
| `S:08`        | Blended Learning    | Integriertes Lernen, Hybridunterricht                |
| `S:09`        | Digitales Lernen    | Digital Learning (dt.), technologiegestütztes Lernen |
| `S:12`        | Digital Learning    | Digitales Lernen (engl.), tech-enhanced learning     |

```{=latex}
\tabsubcaption{Sekundäre Suchbegriffe zur Kontextualisierung des LMS-Feldes. Die Begriffe erweitern den Suchraum um Formate und Bildungstechnologie-Kontexte; die Sichtungsquote wird gegenüber der Primärebene reduziert, um Sensitivität ohne thematische Verwässerung zu sichern.}
```

Sekundäre Begriffe erweitern den Blick auf didaktische und organisatorische Kontexte. Sie erfassen hybride Arrangements, mediale Settings und bildungstechnologische Konzepte, die das LMS funktional einbetten. Die Sichtungsquote liegt hier bei 50 %, weil diese Ebene vor allem der Kontextualisierung und der Identifikation flankierender Mechanismen dient.

**Tertiäre Suchbegriffe**

Table: Übersicht Tertiäre Suchbegriffe \label{tab:tertiäre_suchbegriffe}

| **Ordner-ID** | **Begriff**     | **Synonyme / Varianten**                |
| ------------- | --------------- | --------------------------------------- |
| `S:10`        | Online Lernen   | Lernen im Netz, Web-basiertes Lernen    |
| `S:11`        | Online Learning | Online-based education, remote learning |

```{=latex}
\tabsubcaption{Tertiäre Suchbegriffe als periphere Suchraumerweiterung. Die Begriffe dienen der Trend- und Randfeldvalidierung (niedrige Sichtungsquote) und markieren Anschlussstellen an angrenzende Diskurse.}
```

Tertiäre Begriffe erschließen angrenzende Innovations- und Technologiefelder, die Impulse für zukünftige Erweiterungen liefern. Sie besitzen die niedrigste Sichtungsquote (15 %), werden jedoch zur Validierung neuer Trends genutzt und helfen, emergente Muster in der Literatur frühzeitig zu erkennen.

Die Bool’sche Logik der Suchordner folgt einem konsistenten Ablauf, der von der Auswahl eines Begriffs (primär, sekundär, tertiär) über die Datenbankabfrage, die quotierte Sichtung der Trefferlisten und das Tagging in Zotero bis zur erneuten Suche oder der anschließenden Analyse reicht. Die Struktur der Suchordner ist in \hyperref[sec:A-6]{Anhang A‑6} dokumentiert; die Operationalisierung ist in Abb.~\ref{fig:bool-logik} beispielhaft ausgewiesen.

![Bool’sche Logik der Suchordner und Quotensteuerung.](<08 Metaquellen/08-01 Abbildungen/methodik/Boolsche-Logik Suchordner.png>){#fig:bool-logik}

```{=latex}
\figsubcaption{Screenshot einer exemplarischen Zotero-Suchordnerdefinition (Boolean-Suchstring inkl. Positiv-/Negativtags und Ausschlussregeln) als Operationalisierung der quotierten Sichtung. Dargestellt ist der Ablauf von Trefferliste über Screeningquote (primär/sekundär/tertiär) und Tagging bis zur Übergabe in die Analysepipeline; die Abbildung dokumentiert die Replizierbarkeit der Such- und Selektionslogik.}
```

Diese Abbildung verdeutlicht die Suchorderstrategie innerhalb des Literaturmanagementprogramms. Das zugehörige Zotero-Suchordner-Fenster dokumentiert eine beispielhafte Bool’sche Suchdefinition für Zeitschriftenartikel im Schnittfeld von learning, management und system, ergänzt um die deutschsprachige Variante „Lernmanagementsystem“ und flankiert von negativen Tags (z.B. `Promotion:Ausschluss`, `#2–#b`) sowie dem Ausschluss übergeordneter Sammlungen (z.B. `S:01`). Damit werden nur begutachtete Fachbeiträge selektiert, die thematisch zum Kernfeld gehören, während redundante oder bereits als irrelevant bewertete Einträge ausgenommen bleiben. Methodisch verortet sich diese Definition in der qualitativ-kriterialen Dokumentenselektion nach @doring_forschungsmethoden_2023, Kapitel 10.6 und konkretisiert das dreistufige Suchmodell aus primären, sekundären und tertiären Begriffen: transparent, replizierbar und über die Tag-Struktur skalierbar.

#todo (#55) Suchordnerstrategie weiter ausführen und anpassen

### 4.2.3 Visualisierungen der Literaturbasis {#sec:Visualisierungen-Literaturbasis}

Zur Orientierung innerhalb der Auswertungsschritte strukturiert dieser Abschnitt die Visualisierungen entlang eines konsistenten analytischen Aufbaus. Die Abbildungen bilden die visuelle Grundlage der in Abschnitt \hyperref[sec:Datenanalyse]{4.3} beschriebenen Datenanalyse und ordnen den Quellenkorpus systematisch entlang zentraler Dimensionen: Überblick, Korpusstruktur, FU‑Mapping und Relevanz, Qualitäts- und Statusinformationen, Autor:innenverteilung, Sprachmuster sowie Pfad‑/Sankey‑ und Netzwerksichten. Sie dienen damit der transparenten Rekonstruktion der Datenbasis und der Vorbereitung der späteren Cluster- und Korrelationsanalysen.

Inhaltlich gehören in diesen Abschnitt alle Visualisierungen, die die Relevanz, Struktur und thematische Zuordnung des Korpus abbilden (z. B. Kategorien-, FU‑ und Suchbegriffzuordnungen) sowie Sprach‑ und Kategoriedistributionen. Nicht enthalten sind reine Fortschrittsübersichten der Suchordner; diese gehören als Arbeitsdokumentation in den Anhang (vgl. \hyperref[sec:A-11]{Anhang A‑11}).

Aufbau der Visualisierungen:

- Überblick: Gesamtplot mit Kernkennzahlen (Relevanz, Sprachen, Typen).
- Korpusstruktur: Verteilungen der Kategorien und Indizes.
- FU‑Mapping/Relevanz: Zuordnung zu Forschungsunterfragen sowie Relevanz je FU, Kategorie und Suchbegriff.
- Qualität/Status/Autoren: Status der Quellen und Verteilung der Top‑Autor:innen.
- Sprachen: Gesamtverteilung und Differenzierung nach Dokumententypen.
- Flüsse/Netze: Pfaddiagramm, Suchbegriff‑Sankey‑Darstellung und das semantische Netzwerk.

Alle folgenden Visualisierungen sind als deskriptive Korpusdiagnostik zu lesen (vgl. Abb.~\ref{fig:summary-suchergebnisse}): Sie strukturieren Verteilungen und Relationen (Kopplungen, Häufigkeiten, Flusspfade), sind aber keine Kausalmodelle und enthalten keine normativen Bewertungen. Interpretationen werden daher konsequent als Rückbindung an die Forschungsunterfragen und an die deduktiven Kategorien geführt (vgl. Abschnitt \hyperref[sec:Datenanalyse]{4.3} und Anhang A).

![Gesamtüberblick der Suchergebnisse.](<08 Metaquellen/08-01 Abbildungen/methodik/summary-plot-02-01-suchergebnisse.png>){#fig:summary-suchergebnisse}

```{=latex}
\figsubcaption{Aggregierte Strukturkennzahlen der Suchergebnisse (Quelle: 02-01 Suchergebnisse; Stand: 2025-11-26). Dargestellt sind mittlere Korrelationen je Korrelationstyp ($n=10$ Matrizen); Balkenhöhe: Durchschnittskorrelation, Farbskala: Korrelationswert. Die Übersicht dient als Schnellcheck, welche Ebenen (FU, Suchbegriffe, Indizes, Kategorien) besonders stark gekoppelt sind und wo Entkopplungen auftreten.}
```

Der Überblick bündelt den Korpus ($\approx 3{,}5\text{k}$ Quellen): hohe Relevanzstufen dominieren, Deutsch/Englisch tragen den Hauptanteil, Artikel und Bücher sind die wichtigsten Dokumententypen. Damit ist die Datengrundlage formal solide, sprachlich fokussiert und nur gering durch Randsprachen oder Grauliteratur verzerrt.

![Verteilung der Kategorien im Quellenkorpus.](<08 Metaquellen/08-01 Abbildungen/methodik/visualize_categories_02-01_suchergebnisse.png>){#fig:categories-suchergebnisse}

```{=latex}
\figsubcaption{Textsortenzuordnung der analysierten Quellen (Quelle: 02-01 Suchergebnisse; $n=1109$, Stand: 2025-11-26). Balken: absolute Häufigkeiten der Kategorien Kerngedanke, Argumentation, Weiterführung und Schlussfolgerung; Grundlage für die Einordnung der argumentativen Tiefe des Korpus und für nachfolgende Pfad- und Korrelationsanalysen.}
```

Die Textsortenzuordnung der analysierten Quellen (n = 1 109, Stand: 13.12.2025) zeigt eine deutliche Konzentration auf „Kerngedanke“ und „Argumentation“ (vgl. Abb.~\ref{fig:categories-suchergebnisse}). Weiterführungen und Schlussfolgerungen sind deutlich seltener vertreten. Das Korpus stützt sich damit primär auf zentrale Thesen und Begründungslinien, während synthese- und transferorientierte Passagen unterrepräsentiert sind. Für die spätere Synthese bedeutet dies, dass Schlussfolgerungen gezielt ergänzt und verdichtet werden müssen, um die breit dokumentierte Argumentationsbasis konsistent zu bündeln.

Weitere Detailvisualisierungen zur Korpusdiagnostik sind gesammelt im \hyperref[sec:A-13]{Anhang A‑13} dokumentiert (Abb.~\ref{fig:index-suchergebnisse}, Abb.~\ref{fig:tags-suchergebnisse}, Abb.~\ref{fig:research-questions-suchergebnisse}, Abb.~\ref{fig:relevance-fu}, Abb.~\ref{fig:relevance-categories}, Abb.~\ref{fig:relevance-search}, Abb.~\ref{fig:sources-status}, Abb.~\ref{fig:top-authors}, Abb.~\ref{fig:languages} und Abb.~\ref{fig:language-entrytypes}).

### 4.2.4 Webcam-basiertes Eye-Tracking und KI-gestützte Codierung [@hanisch-johannsen_wirkgefuge_2025-1] {#sec:EyeTracking}

Das Eye-Tracking wurde webbasiert mit RealEye\label{term:realeye} durchgeführt [@lewandowska_realeye_2020]. Die Wahl fiel aus Kostengründen auf ein Webcam-System, dessen Präzision (ca. 110 px) für AOI-Ebene\label{term:aoi} und Layoutanalyse hinreichend ist, jedoch keine millisekundengenaue Fixationsmetriken zulässt; aktuelle Vergleichsstudien stützen den AOI-Einsatz von Webcam-Tracking [@kaduk_webcam_2023; @wisiecka_comparison_2022]. Die Datenbasis umfasst aggregierte Visualisierungen (Heatmaps\label{term:heatmap}, Fog-Views\label{term:fog-view}, Scanpaths); Videorohdaten stehen nicht zur Verfügung. Damit wird das Verfahren ausdrücklich als explorativ-qualitative Methode deklariert, die Wahrnehmungs- und Orientierungsprozesse sichtbar macht, ohne inferenzstatistische Ansprüche zu erheben. Dieser Zugriff ist für FU$_{4b}$ angemessen, da großflächige Interface-Zonen (Navigation, Inhalt, Interaktion, Störflächen) im Fokus stehen [@hanisch-johannsen_wirkgefuge_2025-1].

Die Auswertung folgt einer visuellen AOI-Analyse: (1) Definition weniger, funktionaler AOIs pro Stimulus; (2) Beschreibung der Blickverteilung pro AOI (Hot/Cold-Spots, Reihenfolge, Schleifen im Scanpath); (3) Ableitung technisch-gestalterischer Mechanismen wie Salienz, Auffindbarkeit von Navigation oder Konkurrenz zwischen Dekoration und Funktion. Expertisegradienten werden durch den Vergleich der Jahrgänge sichtbar (breite Explorationsmuster bei Novices, ökonomische Fixationen im dritten Jahrgang). Die Ergebnisse werden mit Umfragedaten trianguliert, um subjektive Wahrnehmung (Struktur/Interaktion) gegen beobachtete Blickmuster zu spiegeln [@hanisch-johannsen_wirkgefuge_2025].

KI dient als Codierhilfe, nicht als Messinstrument: Heatmaps und Fog-Views wurden mit GPT sprachlich beschrieben (z. B. „drei stärkste Aufmerksamkeitszonen markieren“, „Blickpfad A vs. B vergleichen“). Die modellgestützte Beschreibung wird mit der menschlichen AOI-Analyse abgeglichen und in Kategorien („Navigation zuerst“, „Content zuerst“, „Ablenkungszone prominent“) überführt. Damit bleibt die interpretative Verantwortung beim Forschungsteam, während die KI für Konsistenz in der qualitativen Codierung sorgt. Der verbindliche Auswertungs-Prompt ist in \hyperref[sec:A-8]{Anhang A‑8} dokumentiert. Die sequentielle Darstellung erfolgt in Viewmaps\label{term:viewmap}, wobei die Wirksamkeit solcher Aufmerksamkeitslenkung an die Verfügbarkeit kognitiver Ressourcen gebunden bleibt und unter Ablenkung auch instruktionslogisch saubere Unterstützungen ihre Effekte verlieren können. [@storck_learning_2025, Seite 1; Seite 5]

Limitationen: geringere räumliche Präzision als Laborsysteme; Sensitivität für Kopfhaltung und Licht; keine Berechnung klassischer Fixationsmetriken; geringe Stichprobe. Die gewählte Granularität und die triangulative Einbindung (Eye-Tracking × Umfrage × Theorie) sichern dennoch eine robuste, kontextangemessene Evidenzbasis [@hanisch-johannsen_wirkgefuge_2025-1; @hanisch-johannsen_wirkgefuge_2025]. Die vollständigen Bildreihen (Heatmap/Viewmap/Fog-View je Stimulus und Jahrgang) sind in \hyperref[sec:A-7]{Anhang A-7} dokumentiert.

![Stichprobenverteilung der Eye-Tracking-Teilnehmenden nach Ausbildungsjahr [@hanisch-johannsen_wirkgefuge_2025-1].](<08 Metaquellen/08-01 Abbildungen/eye-traking/eye_tracking_verteilung_konfidenz.png>){#fig:eyetracking-verteilung}

```{=latex}
\figsubcaption{Dargestellt sind Anteile je Ausbildungsjahr mit 95\,\%-Konfidenzintervallen im Vergleich zur Grundgesamtheit.}
```

Die Stichprobenverteilung (vgl. Abb.~\ref{fig:eyetracking-verteilung}) zeigt, dass in jedem Ausbildungsjahrgang acht Personen in die Eye-Tracking-Analyse einbezogen wurden ($n_\text{pro Jahrgang} = 8$) und damit jeweils ein Drittel der Kohorte im ersten Jahr (N = 24) sowie einen substantiellen Anteil in den kleineren Jahrgängen (zweites Jahr N = 11, drittes Jahr N = 10) abbilden. Die 95 %-Konfidenzintervalle verdeutlichen die erwarteten Unsicherheiten bei kleinen Grundgesamtheiten, bestätigen aber zugleich, dass die Stichprobe im Rahmen der vorhandenen Kohortengrößen breit gestreut ist. Für die qualitativen, bildbasierten Analysen genügt diese Verteilung, um typische Muster pro Jahrgang sichtbar zu machen, ohne einen Anspruch auf inferenzstatistische Repräsentativität zu erheben [@hanisch-johannsen_wirkgefuge_2025-1].

![Kumulative Zahl potenziell generierter Eye-Tracking-Bilder [@hanisch-johannsen_wirkgefuge_2025-1].](<08 Metaquellen/08-01 Abbildungen/eye-traking/eye_tracking_bildanzahl.png>){#fig:eyetracking-bildanzahl}

```{=latex}
\figsubcaption{Kombiniert werden Stimuli, Jahrgänge und Visualisierungstypen (Heatmaps, Viewmaps, Fog-Views, Screenshots); die Abbildung quantifiziert die Materialmenge der bildbasierten Auswertung.}
```

Die kumulative Bildanzahl (Abb.~\ref{fig:eyetracking-bildanzahl}) illustriert den Umfang der generierten Visualisierungen: Pro Jahrgang entstehen aus den elf Stimuli und drei Visualisierungstypen (Heatmap, Viewmap, Fog-View) bereits mehrere Hundert potenzielle Bilder; hochgerechnet auf alle Jahrgänge ergibt sich ein vierstelliger Bildkorpus. Vor diesem Hintergrund wird die Entscheidung für eine selektive, qualitativ-interpretative Auswertung nachvollziehbar: Statt alle Visualisierungen metrisch auszuwerten, werden zentrale Stimuli und Jahrgänge exemplarisch vertieft analysiert und mit den Umfragebefunden trianguliert [@hanisch-johannsen_wirkgefuge_2025-1; @hanisch-johannsen_wirkgefuge_2025]. Die Kosten-Nutzen-Abwägung fällt damit zugunsten eines theoriegeleiteten, fokussierten Vorgehens aus, das die bildbasierte Stärke des Materials nutzt, ohne in eine unbegründete Quantifizierung zu kippen.

Im nächsten Schritt wird der kodierte Korpus nicht mehr auf Einzelquellenebene, sondern als Gesamtsystem betrachtet. Die folgende Abbildung bündelt die wichtigsten Datenströme und dient als Orientierungsfolie für die Interpretation der später berichteten Cluster- und Korrelationsanalysen; für die laufende Argumentation sind vor allem die Hauptpfade und ihre Abzweigungen relevant.

Die folgenden beiden Abbildungen (Pfaddiagramm und Suchbegriffsnetz) fungieren dabei als zentrale Orientierungsfolie: Sie machen sichtbar, wie sich Suchbegriffe, Kategorien und FU im Korpus zueinander verhalten und welche Schwerpunkte die nachfolgenden Auswertungen tragen. Damit werden die anschließenden Cluster‑ und Korrelationsanalysen nicht nur rechnerisch, sondern auch visuell nachvollziehbar.

![Pfaddiagramm der Datenflüsse und Kategorien im Quellenkorpus.](<08 Metaquellen/08-01 Abbildungen/methodik/create_path_diagram_02-01_suchergebnisse.png>){#fig:path-diagram}

```{=latex}
\figsubcaption{Sankey-Pfaddiagramm der Korpusströme (Quelle: 02-01 Suchergebnisse). Knotenebenen von links nach rechts: Forschungsunterfragen (FU) $\rightarrow$ Textsorten (Kerngedanke/Argumentation/Weiterführung/Schlussfolgerung) $\rightarrow$ deduktive Kategorien $\rightarrow$ Dokumenttypen; Kantenbreite kodiert relative Häufigkeiten und macht dominante Argumentationspfade sowie Randströme sichtbar.}
```

Das Pfaddiagramm dokumentiert die Datenflüsse und Kategorien im Quellenkorpus als Visualisierung der Korpusstruktur; die inhaltliche Einordnung erfolgt in Abschnitt \hyperref[sec:Datenanalyse-Grundlogik]{4.3.1}.

Die anschließende Netzwerkdarstellung fokussiert auf die Suchbegriffe und ihre Verknüpfung mit Tags und Kategorien. Sie macht weniger die zeitliche Abfolge als die semantischen Nachbarschaften sichtbar.

![Netzwerkdarstellung der Beziehungen zwischen Suchbegriffen, Tags und Kategorien.](<08 Metaquellen/08-01 Abbildungen/methodik/visualize_network_02-01_suchergebnisse.png>){#fig:network-suchergebnisse}

```{=latex}
\figsubcaption{Netzwerk/Embedding der Suchbegriffe im zweidimensionalen Raum (Quelle: 02-01 Suchergebnisse). Achsen: technologische vs. pädagogische Dimension; Knotengröße: relative Suchgewichtung/Frequenz; Knotentyp/Farbe: primäre, sekundäre, tertiäre Begriffe; Kanten: semantische Nähe als Ko-Vorkommen in der Tag- und Suchlogik.}
```

Die Netzwerkdarstellung dokumentiert die Beziehungen zwischen Suchbegriffen, Tags und Kategorien als zweidimensionale Übersicht des Suchraums; die inhaltliche Einordnung erfolgt in Abschnitt \hyperref[sec:Datenanalyse-Grundlogik]{4.3.1}. Eine hochauflösende Darstellung des Netzwerks sowie ergänzende strukturbezogene Visualisierungen (Sankey-Diagramm) finden sich im \hyperref[sec:A-4]{Korrelationsatlas (Anhang A-4)}.

Die zugehörigen Korrelationsmatrizen sind als Datensatz auf Zenodo archiviert [@hanisch-johannsen_wirkgefuge_2025-2].

\FloatBarrier

#### Eye-Tracking (RealEye): Design, Durchführung und Qualitätssicherung [@hanisch-johannsen_wirkgefuge_2025-1] {#sec:EyeTracking-Design}

Die Entscheidung für ein webcam-basiertes Eye-Tracking [@hanisch-johannsen_wirkgefuge_2025-1] mit RealEye folgt unmittelbar aus der Forschungsunterfrage FU$_{4b}$, die die technisch‑gestalterischen Wirkmechanismen des LMS untersucht. Für diese Fragestellung sind primär großflächige Aufmerksamkeitszonen, visuelle Hierarchien, Blickpfade und Navigationseffekte relevant. Diese Parameter lassen sich mit webcam‑basierten Verfahren zuverlässig erfassen, ohne dass millimetergenaue Rohdaten oder hochfrequente Sakkadenanalysen erforderlich wären.

Aktuelle Validierungsstudien belegen, dass moderne webcam‑basierte Eye‑Tracking‑Systeme für AOI‑basierte Analysen, UI‑Evaluationen und explorative Aufmerksamkeitstests ausreichend präzise sind. @kaduk_webcam_2023 zeigen, dass die Genauigkeit moderner Webcam‑Tracker (ca. 1–1,5°) nahe an kommerzielle Laborgeräte heranreicht und fixationsorientierte Kernmetriken stabil reproduziert werden. @yang_webcam-based_2021 demonstrieren, dass auch WebGazer‑basierte Systeme bei reduzierten Samplingraten robuste Fixationsmuster erzeugen und verhaltenswissenschaftliche Laborbefunde zuverlässig replizieren. @wisiecka_comparison_2022 bestätigen für RealEye konsistente Ergebnisse bei Standardaufgaben wie Point‑Detection‑ und Visual‑Search‑Tasks. Die technische Dokumentation von @imotions_imotions_2023 unterstreicht ergänzend die Eignung webcam‑basierter Systeme für explorative Studien, Remote‑Settings und UI‑Analysen, bei denen relative Fixationsverteilungen über definierte AOIs im Fokus stehen.

Die Limitationen webcam‑basierter Verfahren – geringere räumliche Präzision, sensitivere Reaktion auf Kopfbewegungen, fehlende Pupillometrie und das Fehlen von Rohdatenexporten – sind für die Beantwortung von FU$_{4b}$ methodisch unproblematisch. Für FU$_{4b}$ steht die Rekonstruktion technisch‑gestalterischer Muster im Vordergrund: Blickanfangszonen, visuelle Orientierung, Pfadtypik, Hot‑ und Coldspots sowie systematisch ignorierte UI‑Zonen. Solche Muster sind gegenüber Samplingratenschwankungen robust. @rodziewicz-cybulska_measuring_2022 zeigen zudem, dass selbst komplexere Fixationsmaße unter geeigneten Bedingungen stabil erfasst werden können, was den Validitätsrahmen für standardisierte Blickbewegungsanalysen stützt.

Damit ist die qualitative, bildbasierte Auswertung der aggregierten Heatmaps, Viewmaps und Fog‑Views wissenschaftlich konsistent und methodisch angemessen [@hanisch-johannsen_wirkgefuge_2025-1]. Die Visualisierungen erlauben eine systematische Identifikation visueller Hotspots, Navigationspfade und unbeachteter Bereiche. Wie in der einschlägigen UX‑ und Eye‑Tracking‑Forschung üblich, werden die Muster relativ interpretiert: als Verteilung über AOIs, nicht als absolute metrische Werte. Durch die Kopplung mit Umfragebefunden (FU$_{1}$/FU$_{2a}$/FU$_{2b}$) [@hanisch-johannsen_wirkgefuge_2025] sowie mit den deduktiv entwickelten Kategorien entsteht eine theoriegeleitete, triangulierte Sicht auf die Wirkmechanismen des LMS [@hanisch-johannsen_wirkgefuge_2025-1; @hanisch-johannsen_wirkgefuge_2025].

##### Ergänzende methodische Absicherung {#sec:EyeTracking-Absicherung}

**Reliabilitätssicherung im Solo-Design**

Auswertung erfolgt im vorliegenden Projekt als Einzelforschung. Reliabilität entsteht über Intra-Coder-Absicherung und konsequente Regelbindung über Stimulusserie. Grundlage bildet versioniertes Entscheidungs- und Zuordnungsraster für AOIs, Mechanismen und Kurzdiagnosen. Pilotphase dient Regelschärfung, danach Freeze mit Datum und Changelog. Driftkontrolle erfolgt über Referenzstimuli mit Wiederholungsauswertung in festen Abständen sowie zeitversetzte Wiederholungsauswertung von Stichprobenanteil. Abweichungen werden als Grenzfallmarker protokolliert und nur bei Regelrelevanz in Form präzisierter Zuordnungsregeln nachgeführt. Konfidenzmarkierung begrenzt Aussagekraft bei ambigen Mustern.
[@kuckartz_qualitative_2018; @mayring_qualitative_2022; @doring_forschungsmethoden_2023]

**Standardisierung und Qualitätsgates bei RealEye**

Webcam-basiertes Tracking unterliegt Geräteheterogenität, Licht, Kopfhaltung und Kalibrierstabilität. Standardisierung wird über dokumentierte Rahmenbedingungen und Qualitätsgates realisiert. Pro Session werden Kalibrierstatus, Trackloss, Artefakte und Ausreißer verpflichtend erfasst. Visualisierungen unter Mindestqualität verbleiben außerhalb Auswertung oder erhalten niedriges Konfidenzniveau. Interpretation verbleibt auf Ebene relativer Muster über AOIs und Funktionszonen. Zeitparameter, Fixationsmetriken und kausale Zuschreibungen liegen außerhalb Geltungsbereich.
[@lewandowska_realeye_2020; @wisiecka_comparison_2022; @kaduk_webcam_2023; @imotions_imotions_2023]

**Setup und Durchführung**

#todo (#56): Flussdiagramm ergänzen

- Remote‑Studie mit Desktop/Laptop und Frontkamera.  
- 9‑Punkt‑Kalibrierung; RealEye‑Validierung unmittelbar vor dem Stimulus.  
- Ausschluss von Sessions mit Warn‑ oder Fehlstatus.  
- Standardisierte Sitzposition, Lichtbedingungen und Displayabstände.  
- Stimulus: statische LMS‑Ansichten; identische Auflösung und AOI‑Koordinaten.
- Sequenzprotokoll: Kalibrierung/Validierung -> Stimulusfolge (F2‑S2, F3‑S3, F10‑S3, F11‑S3, F14‑S3; feste Anzeigezeit von ca. 8–12 s je Stimulus) -> Export der Visualisierungen; kein Reload, Einzel‑Durchlauf pro Person.
- Stichprobe: 24 vollständige Eye‑Tracking‑Datensätze (je 8 Teilnehmende aus dem 1., 2. und 3. Ausbildungsjahr; Grundgesamtheit N\textsubscript{1. Jahr} = 24, N\textsubscript{2. Jahr} = 11, N\textsubscript{3. Jahr} = 10).

**Metriken und Verarbeitung**

#todo (#57): Fließtextüberführung ergänzen

- Export ausschließlich als Heatmap, Viewmap und Fog‑View (keine CSV/Rohdaten).  
- AOI‑Ebene: visuelle Interpretation aggregierter Muster (Hotspots, Pfade, Coldspots).  
- Keine absoluten Fixationskennzahlen; relative Muster stehen im Mittelpunkt.  
- Ausschluss von Sessions mit Trackloss oder instabiler Kalibrierung.
- Technische Angaben: RealEye (Webcam‑Tracker im Browser, Desktop/Laptop); Export als PNG/JPG, keine CSV‑Rohdaten oder AOI‑Metriken verfügbar.
- Nicht genutzte Metriken: keine Pupillometrie, keine millisekundengenaue Sakkadenanalyse, keine Time‑to‑First‑Fixation/TTFF, kein Fixation Count/Dwell‑Time pro AOI (nicht geliefert); ausschließlich Fixationsaggregation aus den Visualisierungen.
- RealEye-Hinweise: Heatmap-Farben kodieren Intensität, nicht Dauer; Viewmap/Fog‑View zeigen Verteilung ohne nummerierte Reihenfolge; central fixation bias (erste ~0,5 s) bei Bedarf ausblenden; Zeitfenster verschieben/verkürzen bei Sequenzfragen; Filter (Qualität/Tags/AOI) nur zur visuellen Sichtung, keine CSV-Downloads.

**Visualisierungstypen und Funktionen**

#todo (#58): Fließtextüberführung ergänzen

- Heatmap: Kernel‑Dichte‑basierte Fixationsdichtekarte; zeigt Hotspots/Coldspots und relative Aufmerksamkeitsverteilung.
- Viewmap/Gaze‑Plot: Sequenzielle Darstellung von Fixationen (Kreise proportional zur Fixationsdauer) und Pfaden; macht Pfadtypik, Orientierungswechsel und Rekursionen sichtbar.
- Fog‑View: Invertierte Fixationsdarstellung; markiert systematisch ignorierte UI‑Zonen (Nebel über nicht fixierten Bereichen).

Table: Stimulusauswahl \label{tab:stimulus-auswahl}

| Stimulus | Inhalt (kurz)            | FU (primär)  | Fokus (kurz)                 |
| :------: | :----------------------- | :----------: | :--------------------------- |
|  F2‑S2   | Navigation, Interaktion  |   FU$_{4b}$/FU$_{3}$   | Salienz Navigation           |
|  F3‑S3   | Aufgabenbereich          |   FU$_{4b}$/FU$_{1}$   | Info-Hierarchie/Blickführung |
|  F10‑S3  | Lernplan, Kompetenzen    | FU$_{4b}$/FU$_{6}$/FU$_{1}$ | Verständlichkeit             |
|  F11‑S3  | Weiterführende Quellen   |  FU$_{4b}$/FU$_{2a}$   | Auffindbarkeit/Link-Salienz  |
|  F14‑S3  | Lernmaterial, Sicherheit |   FU$_{4b}$/FU$_{6}$   | Salienz Sicherheit           |

```{=latex}
\tabsubcaption{Auswahl repräsentativer Eye-Tracking-Stimuli für die qualitative AOI-Analyse. Spalten: Stimulus-ID, inhaltlicher Ausschnitt, primär adressierte FU sowie Analysefokus; Auswertung in Abschnitt \hyperref[sec:EyeTracking-Umfrage-Vergleich]{4.3.9}.}
```

Datengrundlage der Stimulus-Visualisierungen: [@hanisch-johannsen_wirkgefuge_2025-1].

Auswertungsvorgehen (FU‑geführt)

1. Verortung des Stimulus im LMS‑Kontext.  
2. Heatmap‑Analyse (Salienz, Aufmerksamkeitszentren).  
3. Viewmap‑Analyse (Pfadtypik, Orientierungswechsel).  
4. Fog‑View‑Analyse (ignorierte Zonen).  
5. Ableitung technisch‑gestalterischer Wirkmechanismen (Gestaltgesetze, Salienz, Navigierbarkeit).  
6. Verknüpfung mit FU$_{4b}$ sowie, je nach Stimulus, FU$_{1}$/FU$_{2a}$/FU$_{3}$/FU$_{4a}$/FU$_{6}$.  
7. Formulierung einer kurzen, FU‑spezifischen Wirkungsdiagnose je Stimulus.

**Einschränkungen und Bias**

#todo (#59): Flussdiagramm ergänzen

- Webcam‑Tracking liefert geringere Präzision als stationäre Systeme; Genauigkeit sinkt bei Bewegung oder suboptimalen Lichtverhältnissen.  
- Interpretationen basieren auf relativen Mustern, nicht auf punktgenauen Blickpositionen.  
- Fehlende Rohdaten limitieren inferenzstatistische Analysen; qualitative Befundung bleibt jedoch belastbar.  
- Ergebnisse sind indikativ, nicht repräsentativ; die Stichprobengröße wird transparent gemacht und in Abschnitt 4.3.9 mit Konfidenzintervallen ergänzt.
- KI‑gestützte Bildauswertung: Falls KI‑Modelle zur Bildbeschreibung genutzt werden, dienen sie ausschließlich als Assistenz (kein automatisiertes Urteil); Modell/Version wird dokumentiert (#todo (#60)), und alle Interpretationen werden manuell gegengeprüft (COPE/DFG‑konform).

### 4.2.5 Umfrage zum LMS: Instrument, Gewichtungen und Auswertung {#sec:Umfrage-LMS}

Die LMS-Umfrage erfasst subjektive Wahrnehmungen und Bewertungen der Nutzenden und flankiert die Eye-Tracking-Daten [@hanisch-johannsen_wirkgefuge_2025-1] durch Selbstauskünfte zu Akzeptanz, Nutzen und Hemmnissen [@hanisch-johannsen_wirkgefuge_2025]. Sie stützt primär FU$_{1}$ (Akzeptanz und Nützlichkeit) sowie FU$_{2a}$/FU$_{2b}$.

Die Erhebung ist vollständig anonymisiert, freiwillig und unabhängig vom Eye-Tracking-Studienteil [@hanisch-johannsen_wirkgefuge_2025-1]; Abbruch jederzeit ohne Angabe von Gründen. Laufzeit ca. 15 Minuten, Rekrutierung über das LMS-Umfeld. Instruktion und Einwilligung sind vorab bereitgestellt und verschriftlicht.

- **Struktur/Item-Gruppen:** Klarheit/Struktur der Informationen, Diskussion/Austausch, Kollaboration, Flexibilität, Ressourcenzugang, Integration externer Materialien, Lernfortschritt, Rolle multimedialer Inhalte, Anpassung/Personalisierung. Zuordnung und Gewichtungen sind vorab festgelegt (vor/nach Anpassung je Frage).
- **Gewichtung der Dimensionen:** Nach Vortest wurden zentrale Knoten des Wirkungsgefüges höher gewichtet: Klarheit/Struktur stieg auf $0{,}8$, Diskussion/Austausch auf $0{,}6$, Kollaboration auf $0{,}7$, Flexibilität auf $0{,}7$, Ressourcenzugang und Integration externer Materialien auf $0{,}6$. Lernfortschritt wurde auf $0{,}5$ festgesetzt, multimediale Inhalte auf $0{,}5$, Anpassung auf $0{,}6$ und Personalisierung auf $0{,}5$. Damit rücken Verständlichkeit, Interaktion und Kollaboration in den Fokus, ohne periphere Dimensionen auszublenden.

- **Ziel und Konstruktion:** Ableitung der Items aus den Forschungsunterfragen; Kombination aus Akzeptanz-, Nutzungs- und Wirkungsdimensionen; Pretest dokumentiert.
- **Instrument:** Strukturierter Fragebogen mit Informationsblatt und Einwilligung; abgestützte Gewichtungen der Dimensionen.
- **Stichprobe:** Rekrutierung über das LMS-Umfeld; Ein- und Ausschlusskriterien dokumentiert; Dropouts ausgewiesen.
- **Durchführung:** Online-Erhebung über das LMS; identische Instruktionen; pseudonymisierte IDs; technische Checks vor Freigabe.
- **Auswertung:** Deskriptive Kennzahlen pro Dimension, gewichtetes Gesamtmaß gemäß Synopse, Vergleich nach Subgruppen (z.B. Nutzungshäufigkeit, Rolle); fehlende Werte per Listewise/Pairwise je Analyse; Rückbindung an FU$_{1}$/FU$_{2a}$/FU$_{2b}$ und Abgleich mit Eye-Tracking-Befunden [@hanisch-johannsen_wirkgefuge_2025-1].
- **Gütekriterien/Reflexion:** Reliabilität über interne Konsistenz geprüft; Validität über Experten-Review und Pretest; mögliche Bias (Selbstselektion, soziale Erwünschtheit) werden in der Diskussion transparent gemacht.

**Auswertungsvorgehen (Schema, FU‑geführt)**  
Analog zum Eye‑Tracking [@hanisch-johannsen_wirkgefuge_2025-1] werden die Umfragedaten [@hanisch-johannsen_wirkgefuge_2025] in einem einheitlichen, dokumentierten Schema ausgewertet und für die Triangulation vorbereitet:

1. **Datenbasis und Subgruppen:** Auswertung auf Basis der Online‑Exporttabelle (`08 Metaquellen/08-04 Daten/UmfrageOnline-Beantwortungen.csv`) [@hanisch-johannsen_wirkgefuge_2025]. Die Jahrgangszuordnung erfolgt über die Kurskennzeichnung (z.B. `21‑…`, `22‑…`, `23‑…`). Abbrüche/fehlende Werte werden itemweise transparent ausgewiesen (n je Jahrgang und je Item).
2. **Item‑Level statt Blackbox‑Index:** Primäre Auswertung pro Item (statt ausschließlich aggregierter Skalen), um FU‑Bezüge und konkrete Gestaltungsdimensionen nachvollziehbar zu halten.
3. **Deskriptive Kennzahlen pro Item:** Für Likert‑Items (1–5) werden je Jahrgang und Gesamtstichprobe `n`, Mittelwert, Standardabweichung, Median, IQR sowie Zustimmungs-/Ablehnungsanteile (>=4 / <=2) berichtet. Für binäre Items (Ja/Nein) wird der Ja‑Anteil ausgewiesen.
4. **Gewichtungslogik (Transparenz):** Die in der Synopse dokumentierten Vor-/Nach‑Gewichtungen dienen als nachvollziehbarer Übersetzungsschritt von Selbstauskünften in die weitere Modellierungs-/Verdichtungslogik (Zuordnung „Frage → Begriffspaar → Einfluss“).
5. **Freitext als qualitative Ergänzung:** Offene Antworten werden getrennt ausgewiesen und als Ausgangspunkt für eine knappe Kategorienbildung genutzt (Triangulation/Validierung, keine Überinterpretation bei geringer Fallzahl).
6. **Dokumentation/Artefaktspur:** Alle Item‑Auswertungen werden als reproduzierbare Arbeitsartefakte im identischen Berichtschema abgelegt (Index + Itemdateien; `03 Quellenanalyse/03-06 Umfrage/Analysen-Auswertungen/…`) [@hanisch-johannsen_wirkgefuge_2025]. Die verbindliche Vorlage ist in \hyperref[sec:A-10]{Anhang A‑10} dokumentiert; die Ergebnisse werden in Abschnitt \hyperref[sec:EyeTracking-Umfrage-Vergleich]{4.3.9} mit Eye‑Tracking‑Befunden kontrastiert [@hanisch-johannsen_wirkgefuge_2025-1].

Die Konstruktion des Instruments folgt dem Prinzip der Forschungsfragengeleitetheit. Jede Itemgruppe ist einem FU zugeordnet, was eine direkte Rückbindung der Ergebnisse ermöglicht. Die Gewichtungen sind vorab festgelegt, um Skalierungsentscheidungen nachvollziehbar zu machen und Sensitivitätsanalysen (mit/ohne Gewichtung) zu ermöglichen. Pretests und Experten-Review stellen sicher, dass die Items verständlich und inhaltlich valide sind.

Für die spätere Triangulation werden die Umfrageergebnisse so aufbereitet, dass sie in Abschnitt \hyperref[sec:EyeTracking-Umfrage-Vergleich]{4.3.9} mit Eye-Tracking-Befunden kontrastiert werden können (u.a. Jahrgangsvergleiche und Subgruppenanalysen).

## 4.3 Datenanalyse {#sec:Datenanalyse}

### 4.3.1 Grundlogik der Datenanalyse: Analysen erster bis dritter Ordnung {#sec:Datenanalyse-Grundlogik}

Die Datenanalyse folgt einem dreistufigen, systemisch gedachten Beobachtungsmodell, das deduktive Kategorienbildung mit probabilistischer Validierung systemisch ordnet. Damit bleibt jeder Schritt eng an die Forschungsunterfragen gekoppelt und gleichzeitig anschlussfähig an die dokumentarischen Qualitätsanforderungen nach Döring [-@doring_forschungsmethoden_2023].

- **Analysen erster Ordnung (Primäranalysen):** Einzelquellen werden entlang vordefinierter Kategorien (Akzeptanz, Nutzen, Grenzen usw.) ausgewertet. Das Ergebnis ist eine strukturierte, FU-spezifische Inhaltsanalyse pro Dokument.
- **Analysen zweiter Ordnung (Sekundäranalysen):** Die Primäranalysen einer FU werden gespiegelt, verdichtet und theoriebezogen gerankt. Daraus entstehen deduktive Cluster, SWOT-Profile und Korrelationsmatrizen [@hanisch-johannsen_wirkgefuge_2025-2].
- **Analysen dritter Ordnung (P-QIA):** Die probabilistisch-qualitative Inhaltsanalyse überführt den FU-spezifischen Korpus aus Analysen 1. Ordnung in einen semantischen Vektorraum, prüft ihn über k-means-Clustering und bewertet die Kohärenz mittels Silhouette-Scores.

Gemeinsam bilden diese Ordnungen einen iterativen Zyklus. Jede Stufe liefert die Grundlage für die nächste und fließt nach erfolgter Validierung wieder in die Forschungsunterfragen zurück.

Systemtheoretisch folgt die Dreiteilung der Idee von Beobachtungen erster, zweiter und dritter Ordnung: Analysen erster Ordnung beobachten die Quellen direkt und beschreiben, was Akteure über Akzeptanz, Nutzen oder Grenzen des LMS aussagen; Analysen zweiter Ordnung beobachten diese Beobachtungen, identifizieren Muster und Metastrukturen auf FU-Ebene; Analysen dritter Ordnung beobachten schließlich die daraus entstehenden Strukturen im semantischen Raum und prüfen ihre Stabilität und Kohärenz [@luhmann_zwischen_1982; @arnold_rolf_luhmann_1995]. Damit wird das luhmannsche Beobachtungskonzept operativ auf die mehrstufige Literatur- und Datenanalyse übertragen und in eine reproduzierbare Pipeline überführt.

**Korpusdiagnostik (Zeitreihe, Kohärenz, Flüsse)**

Ab 2019 setzt ein exponentieller Wachstumstrend ein, der als Indikator einer massiven thematischen Erweiterung und Verdichtung zu interpretieren ist. Die Jahre 2020 bis 2023 bilden den quantitativen Höhepunkt der Entwicklung; das Jahr 2023 erreicht mit über $900$ Einträgen den Maximalwert des gesamten Korpus. Dieser starke Anstieg kann charakteristisch für Felder sein, in denen digitale Transformation, Technologieintegration und KI-basierte Methoden erhebliche Impulse erzeugen. Zugleich korrespondiert dieses Phänomen mit den Ergebnissen der nachfolgenden Silhouette-Analyse. Hohe Volumina führen nicht automatisch zu höherer Kohärenz, vielmehr können diese in dynamischen Feldern typischerweise eine temporäre Fragmentierung erzeugen.

Der Rückgang im Jahr 2024 kann trotz weiterhin hoher Publikationszahlen als Reorganisationsphase des Diskurses verstanden werden. Themenräume wie Learning Analytics, generative KI oder datenbasierte Didaktik verschieben bestehende epistemische Zentren. Die im Jahr 2025 sichtbare Stabilisierung deutet auf eine Normalisierung nach der Phase beschleunigten Wachstums hin; die bis November erfassten Werte bilden erwartungsgemäß nur einen Teil des Jahres ab.

Methodologisch zeigt die Zeitreihe, weshalb eine Kombination aus volumetrischer Betrachtung, Kohärenzanalysen (Silhouette\label{term:silhouette-score}), Sensitivitätsmaßen ($\Delta SC_n$) und deduktiver Strukturierung notwendig ist. Die reine Publikationszahl erlaubt keine Aussage über die semantische Struktur des Feldes. Erst im Zusammenspiel mit der Clusterkohärenz wird erkennbar, welche Jahre ein belastbares epistemisches Fundament darstellen (2018–2022) und welche Jahre aufgrund struktureller Transformation mit besonderer Sensitivität zu interpretieren sind (2023–2024). Diese Differenzierung ist für die retrospektive Gewichtung der Jahrgänge zentral und legitimiert den Einsatz der P-QIA, der mdaCV sowie der epistemischen Verlustfunktion als integrative Validierungsinstanzen des ausgewerteten Literaturraums.

Die Auswahl folgte einem dokumentierten, algorithmisch gestützten Verfahren auf Basis rekonstruierten Dichtefeldern innerhalb deduktiv-numerischer Vektorräume. Der Einfluss manueller Schwerpunktsetzungen wird über die dokumentierten Screening- und Tagging-Schritte transparent gehalten. Die Aussagen aus diesem Literaturfeld werden damit als konsistente Referenzbasis für die weitere Auswertung geführt. #todo (#82) revision

Die Summenzeile (Tabelle~\ref{tab:cluster_silhouette}) dokumentiert die 3 524 für die Kohärenzberechnung herangezogenen Dokumente. Bis 2016 bleiben die Fallzahlen niedrig, die Silhouette-Scores liegen aber durchgängig bei $\approx 1{,}0$ und weisen auf hochgradig fokussierte Cluster hin. In den Jahren 2018–2022 steigt das Volumen stark an, während die Scores auf hohem Niveau bleiben ($\geq 0{,}985$); diese Phase bildet den stabilen epistemischen Kern des Korpus. Der Einbruch auf $0{,}9208$ im Jahr 2024 markiert die stärkste semantische Drift durch die rasche Ausweitung neuer Themen (z. B. KI-basierte Lernmodelle), bevor 2025 eine moderate Rezentrierung der Cluster sichtbar wird. Insgesamt zeigt die Tabelle, dass hohe Fallzahlen nicht automatisch Kohärenzverlust bedeuten, Wachstumsphasen aber interpretativ besonders sorgfältig eingeordnet werden müssen.

Im Zusammenspiel von Silhouette-Scores und Fallzahlen (Abb.~\ref{fig:silhouette-scores}) wird die semantische Stabilität des recherchierten Literaturfeldes über die Zeit sichtbar. In den Jahren 2010–2016 liegen trotz geringer Fallzahlen sehr hohe Silhouette-Scores vor ($\approx 1.0$). Methodisch interpretiert markiert dies eine Phase, in der die thematische Struktur eng gefasst ist und zusätzliche Dokumente inhaltlich stark ähnlich anschließen. Der Zeitraum 2018–2022 kombiniert hohe Fallzahlen mit durchgängig über dem Median liegenden Werten ($Q_2 \approx 0{,}99$). Diese Jahre bilden einen stabilen Referenzbereich des Korpus (hohe Dichte, hohe Trennschärfe, erkennbare Clusterzentren). #todo (#83) revision

Ab 2023 sinkt der Score trotz weiterhin sehr hoher Fallzahlen. Der Tiefpunkt ($0,9208$ im Jahr 2024) zeigt eine semantische Drift, das heißt eine zunehmende Heterogenität des Feldes, ohne dass die Relevanz oder Qualität des Korpus abnimmt. Vielmehr reorganisieren sich die thematischen Schwerpunkte in einem dynamischen Diskursfeld (z. B. Learning Analytics, KI-basierte Lernsysteme, generative Modelle). Die moderate Erholung 2025 verweist auf eine mögliche Neuordnung der semantischen Zentren. Die quartilsbasierten Referenzlinien ($Q_1 \approx 0{,}9686$, $Q_3 = 1{,}0000$) und die Fatigue-Schwelle von $0,96$ markieren die Übergänge zwischen kohärenten Verdichtungsphasen und beginnender Fragmentierung. Damit lässt sich die Aussagekraft einzelner Jahrgänge systematisch gewichten, belastbare Kohärenzphasen identifizieren und die Qualität der algorithmischen Clusterbildung retrospektiv validieren.

Die ergänzende Darstellung der Abweichung $\Delta SC_n$ (Abb.~\ref{fig:delta-silhouette}) führt eine Sensitivitätsperspektive auf die Clusterkohärenz ein. Während der Silhouette-Score die geometrische Trennschärfe der Cluster bewertet, zeigt $\Delta SC_n$, wie stark die relative Kohärenz eines Jahres unter Berücksichtigung des jeweiligen Volumens ($n/\max(n)$) von einem stabilen Referenzwert abweicht. Positive Werte verweisen auf Jahre, in denen die semantische Kohärenz überproportional höher ausfällt, als es die Fallzahl nahelegt – typischerweise Verdichtungsphasen mit klaren thematischen Zentren. Die Jahre 2010–2017 zeigen hierfür charakteristische Ausschläge: geringe n, aber überdurchschnittlich kohärente semantische Felder, was die zuvor beschriebenen stabilen Kernbereiche der Literatur bestätigt.

Ab 2018 pendelt $\Delta SC_n$ um den Median, was eine weitgehend proportionale Entwicklung von Korpusgröße und thematischer Konsistenz signalisiert. Auffällig sind die negativen Ausschläge der Jahre 2023–2025. Sie markieren nicht Qualitätsverluste, sondern Konstellationen, in denen hohe Publikationsvolumina mit einer strukturellen Reorganisation der thematischen Landschaft einhergehen. Die starke negative Abweichung 2024 ($\Delta SC_n < -0{,}8$) verdeutlicht diese Drift besonders klar: Die semantische Dichte kann mit dem Wachstum des Feldes nicht im gleichen Maße Schritt halten. Methodisch weist dies auf Übergangszonen hin, in denen bestehende Clusterzentren an Stabilität verlieren und neue semantische Schwerpunkte entstehen.

Als Sensitivitätsmaß ergänzt $\Delta SC_n$ den Silhouette-Score um eine volumengewichtete Perspektive und dient damit der retrospektiven Bewertung der Robustheit einzelner Jahrgänge. Die Kennwerte machen sichtbar, in welchen Phasen die Daten kohärent strukturiert sind und in welchen die semantische Landschaft in Bewegung gerät. Für die Literaturauswahl bedeutet dies, dass Jahre mit hohen negativen $\Delta SC_n$-Werten keinesfalls ausgeschlossen, sondern kontextsensitiv interpretiert werden müssen: Sie geben Hinweise auf thematische Umbrüche, nicht auf Instabilität des Verfahrens.

Im Korpusfluss (Abb.~\ref{fig:path-diagram}) markieren die Pfade von FU$_{3}$/FU$_{4a}$ über Kerngedanke/Argumentation in Richtung Technologieintegration sowie Lehr-/Lerneffektivität die dominanten Ströme. Randströme (z.B. Datenschutz, Krisenreaktion) bleiben schmal und markieren Ergänzungsfelder; für die weitere Auswertung ist insbesondere die Verdichtung entlang Technologieintegration und Lehr-/Lerneffektivität relevant.

Das Suchbegriffsnetz (Abb.~\ref{fig:network-suchergebnisse}) spannt eine technologische und eine pädagogische Achse auf. Primärbegriffe wie „learning:management:system“, „digital:learning“ und „digital:lernen“ liegen zentral und verbinden technische mit didaktischen Dimensionen. Sekundärbegriffe (z.B. „mooc“, „blended:learning“, „digital:medien“) verdichten den pädagogischen Pol und zeigen Anschluss an Formate und Inhalte. Tertiärbegriffe („online:lernen“, „online:learning“) sind randständig und öffnen den Suchraum, ohne die Kernstruktur zu verschieben. Die Knotengröße spiegelt die Suchgewichtung, die Kanten die semantische Nähe. Insgesamt bestätigt das Netz eine doppelte Zentrierung: technologiegetriebene Kernbegriffe halten den Raum zusammen, didaktische und periphere Online-Begriffe erweitern ihn kontrolliert.

### 4.3.2 Primäranalysen: Analyse 1. Ordnung {#sec:Primaranalysen}

Die Primäranalysen bilden das Fundament der weiteren Verdichtungen. Jede wissenschaftliche Quelle wird mit einem dedizierten Prompt ausgewertet, der aus der jeweiligen Forschungsunterfrage abgeleitet ist (Anhang A.2, Prompt zur Analyse einer Quelle, {#sec:A-2}). Die Prompts stellen sicher, dass alle Analysen identische Bausteine enthalten (Kontext, Argument, Limitationen, Implikationen).

1. **Quellenimport und Tagging:** Aus Zotero exportierte Einträge werden über ihre Tags den FUs zugeordnet.
2. **Promptbasierte Auswertung:** Ein KI-gestütztes Textanalysewerkzeug erzeugt strukturierte Markdown-Analysen, die deduktiv definierte Kategorien ausfüllen und mit Originalzitaten aus der Quelle verknüpfen.
3. **Dokumentation:** Jede Analyse erhält einen Header mit Metadaten (Quelle, Datum, Prompt-Version). Die Ergebnisse liegen versioniert in Obsidian vor und können jederzeit erneut validiert werden.
4. **Qualitätssicherung:** Quellen, die inhaltlich nicht in den digitalen Bildungsraum passen, werden bereits auf dieser Ebene identifiziert und als „irrelevant" markiert. So bleiben nur überprüfte Texte im weiteren Prozess.
5. **Zotero-Export inkl. Notizen:** Die Primäranalysen werden über einen laufend aktualisierten Export aus Zotero in das Literaturverzeichnis der Arbeit überführt und bilden so die maschinenlesbare Grundlage für die anschließenden Netzwerk-, Cluster- und Pfadanalysen.

Insgesamt wurden 786 Analysen erster Ordnung durchgeführt. Die Verteilung auf die Forschungsunterfragen zeigt einen deutlichen Schwerpunkt bei FU$_{4a}$ und FU$_{5}$ (Didaktik, Mechanismen, Möglichkeiten/Grenzen), gefolgt von FU$_{3}$ und den nutzungsbezogenen FU$_{2a}$/FU$_{4b}$. FU$_{1}$ und FU$_{6}$ liegen im mittleren einstelligen Prozentbereich, FU$_{2b}$ und FU$_{7}$ bilden kleinere, aber inhaltlich zentrale Vertiefungsfelder. Abbildung \ref{fig:primaranalysen-verteilung} visualisiert diese Gewichtung.

```{=latex}
\input{08 Metaquellen/08-01 Abbildungen/statistik/primaranalysen-verteilung.tex}
```

Für die Analysen zweiter Ordnung wird je Forschungsunterfrage ein FU-spezifischer Korpus aus dem Literaturverzeichnis gebildet: Alle Einträge, die den FU-Tag (`Promotion:FUx`) tragen und eine Analyse 1. Ordnung im Feld `annote` enthalten, werden extrahiert und in einer FU-spezifischen Arbeitsdatei zusammengeführt, wobei der jeweilige BibTeX-Key als Referenzanker mitgeführt wird. Diese Arbeitsdateien dienen der Reproduzierbarkeit und Nachvollziehbarkeit der FU-Korpora, sind jedoch nicht Bestandteil des Anhangs. Die FU-Korpora bilden die direkte Eingabe der P‑QIA-Metaanalyse (vgl. \hyperref[sec:P-QIA]{Abschnitt 4.3.4} sowie \hyperref[sec:A-3]{Anhang A.3}) und sichern, dass Ankerbeispiele und Zuordnungen reproduzierbar auf konkrete Quellen zurückverweisen.

### 4.3.3 Sekundäranalysen: Analyse 2. Ordnung {#sec:Sekundaranalysen}

Die zweite Ordnung synthetisiert alle Primäranalysen einer Forschungsunterfrage. Die entsprechenden Prompts (z.B. `FU1 Prompt Sekundäranalyse.md`) führen mehrere Einzelanalysen zusammen, spiegeln sie an theoretischen Bezugsrahmen und erzeugen daraus erste Metastrukturen:

- **Vergleich und Ranking:** Wiederkehrende Aussagen werden identifiziert, divergierende Befunde kontrastiert und entlang der FU priorisiert.
- **Theoriebasierte Spiegelung:** Konzepte wie TAM, SDT oder TPACK dienen als Referenz, um die Primäranalysen in bestehende Modelle einzubetten.
- **Manuelle Clusterlogik:** Vor der probabilistischen Verdichtung entstehen deduktive Cluster (z.B. „Akzeptanzmuster" oder „Risiko-Faktoren"), SWOT-Profile oder Korrelationsmatrizen [@hanisch-johannsen_wirkgefuge_2025-2].

Damit liefert die zweite Ordnung den semantischen Rahmen, in dem die probabilistische Verdichtung der dritten Ordnung operiert: Sie stellt die deduktiven Referenzen bereit, mit denen die P‑QIA‑Cluster (Benennung, Abgrenzung, Theoriebezug) interpretiert und mit weiteren Befundlinien (z.B. SWOT/Korrelationen) zusammengeführt werden. Operativ ist die zweite Ordnung jedoch **kein zwingender technischer Input** der P‑QIA, sondern ein nachgelagerter Bezugsrahmen zur inhaltlichen Einordnung der probabilistisch erzeugten Kategorien.

### 4.3.4 Probabilistisch-Qualitative Inhaltsanalyse (P-QIA): Analyse 3. Ordnung {#sec:P-QIA}

\label{term:p-qia}

Die P-QIA ergänzt die klassischen Methoden um eine reproduzierbare, embedding-basierte Strukturierung. Sie versteht sich als semantische Analyse im Sinne einer regelgeleiteten Erschließung, Verdichtung und relationalen Zuordnung bedeutungstragender Einheiten.

Operativ arbeitet die P‑QIA auf dem FU‑spezifischen Korpus aus Analysen 1. Ordnung (Zotero-`annote`, gebündelt in Arbeitsdateien je FU) und erzeugt daraus probabilistisch validierte Kategorien. Die Einbettung in die Gesamtargumentation erfolgt anschließend über die Sekundäranalysen (2. Ordnung) als deduktiven Bezugsrahmen sowie über die Triangulation mit empirischen Befunden.

In ihrer Grundlogik knüpft die P‑QIA an die qualitative Inhaltsanalyse nach @baur_qualitative_2022 an, indem Kategorien das zentrale Instrumentarium darstellen. Dieses macht große Textmengen bearbeitbar, ohne die interpretative Dimension zu verlassen. Zugleich wird der Prozess über Regeln so gefasst, dass er intersubjektiv überprüfbar bleibt. Der Übergang zwischen theoriegeleiteter Deduktion und materialnaher Induktion bleibt dabei dauerhaft anschlussfähig, ebenso die Möglichkeit, kategoriale Verdichtungen in einem zweiten Schritt auch über Häufigkeiten und Relationen auszuwerten. Die P‑QIA übersetzt diese Kategoriengeleitetheit in eine embedding-basierte Strukturierungslogik, führt die interpretative Kontrolle jedoch konsequent über Kodiermanuale, Ankerbeispiele und FU‑Rückbindungen zurück in den theoriegeleiteten Bezugsrahmen. Dabei wird die embedding-basierte Strukturierungslogik als probabilistische Verdichtungsstufe geführt. Embeddings erzeugen nach @dominici_causal_2024 einen leistungsfähigen latenten Ordnungsraum, können gleichzeitg eine Beschattung der modellinternen Struktur erzeugen. Diese Opazität kann ohne explizite Prüf- und Dokumentationslogiken nicht verlässlich verifiziert werden. [@baur_qualitative_2022, Seite 691-693; @dominici_causal_2024, Seite 1-2]

**Konzept und Abgrenzung**

- Deduktive Rahmung durch die Forschungsunterfragen (FU$_{1}$–FU$_{7}$).
- Segmentierung aller Texte in Sinnabschnitte (1–3 Sätze; bei FU$_{7}$ 1–2 Sätze).
- Transformation der Segmente in hochdimensionale Embeddings\label{term:embedding}.
- k-means\label{term:k-means}-Clustering und Gütebewertung via Silhouette-Koeffizient.
- KI-gestützte Label-Vorschläge, die durch die Forschende überprüft und theoretisch validiert werden.
- Ableitung konsistenter Kodiermanuale mitsamt Ankerbeispielen.

Die eingesetzten KI-basierten Textmodelle wirken als strukturierende Werkzeuge; Steuerung und Interpretation liegen vollständig bei der Forschenden.

**Algorithmische Umsetzung**

Der Workflow wurde in Anlehnung an Mayring gestaltet und verbindet klassische Schritte mit probabilistischen Erweiterungen:

1. **Forschungsunterfrage und Materialfestlegung (Mayring)** – Definition der FU und Auswahl des Materials (Primäranalysen, Notizen, Quellen).
2. **Festlegung der Analyseeinheiten (Mayring)** – Definition von Kodiereinheit/Kontexteinheit/Auswertungseinheit, Pilotphase und Regelkonstanz im finalen Durchgang [@baur_qualitative_2022, Seite 694].
3. **Segmentierung (P-QIA)** – Automatische Zerlegung der Texte in 1–3 Sätze (bei FU$_{7}$ 1–2 Sätze) inklusive Dokumentation der Regeln.
4. **Embedding und probabilistische Strukturierung (P-QIA)** – vektorbasiert berechnete Textrepräsentationen und k-means-Clustering mit FU-spezifischem *k*.
5. **Qualitätssicherung der Cluster (P-QIA)** – Berechnung des Silhouette-Koeffizienten und Bereinigung instabiler Cluster.
6. **Ableitung und Revision der Kategorien (Mayring + P-QIA)** – KI-gestützte Label, theoretische Validierung, Kodierleitfaden (Definitionen, Ankerbeispiele, Kodierregeln), Kodiermanual [@baur_qualitative_2022, Seite 696].
7. **Kodierung des Materials (Mayring)** – Anwendung des Manuals, Dokumentation von Grenzfällen und Abgrenzungsentscheidungen.
8. **Synthese, Metamodellierung und Theoriebildung (Mayring + P-QIA)** – Rückbindung an die FU und Dokumentation der Kennwerte.

```{=latex}
\input{08 Metaquellen/08-01 Abbildungen/prozesse/p-qia-flow.tex}
```

**Validierung und empirische Kennwerte**

Die Datei [[P-QIA Statistik]] dokumentiert Segmentierungsregeln, Embedding-Modelle, gewählte *k*-Werte und Silhouette-Mittelwerte für alle FUs. Über alle Forschungsunterfragen hinweg liegt *k* zwischen 8 und 15, die Silhouette-Werte bewegen sich zwischen 0.87 und 0.93 (Mittelwert ca. 0.89).

Als zusätzliche Absicherung wird – analog zu den inhaltsanalytischen Gütekriterien (Intra-/Intercoder-Übereinstimmung) – die Stabilität zentraler Zuordnungen über wiederholte Läufe, Stichproben-Gegenlesungen und dokumentierte Grenzfallentscheidungen geprüft; Ziel ist nicht Scheingenauigkeit, sondern nachvollziehbare Regelbindung bei verbleibendem Interpretationsspielraum [@baur_qualitative_2022, Seite 695].

|FU|k|Silhouette|Interpretation nach @rousseeuw_silhouettes_1987|
|---|---|---|---|
|FU$_{1}$|8|0.91|sehr starke Clustertrennung|
|FU$_{2a}$|12|0.88|starke Clusterstruktur|
|FU$_{2b}$|14|0.89|starke Clusterstruktur|
|FU$_{3}$|15|0.87|starke Clusterstruktur|
|FU$_{4a}$|12|0.90|sehr starke Clustertrennung|
|FU$_{4b}$|12|0.92|sehr starke Clustertrennung|
|FU$_{5}$|14|0.88|starke Clusterstruktur|
|FU$_{6}$|12|0.89|starke Clusterstruktur|
|FU$_{7}$|10|0.93|sehr starke Clustertrennung|

In Anlehnung an @rousseeuw_silhouettes_1987 lässt sich der mittlere Silhouette‑Wert als Maß für die **geometrische Trennschärfe** einer Clusterlösung lesen: Werte nahe 1 deuten darauf hin, dass Segmente im Embedding‑Raum im Mittel deutlich näher an ihrem eigenen Cluster liegen als am nächstgelegenen Alternativ‑Cluster. Als pragmatische **Faustregel** werden Werte über 0,70 häufig als „stark“ und Werte über 0,90 als „sehr stark“ interpretiert; in diesem Sinne zeigen die Kennwerte für die Analysen 2. Ordnung eine durchgängig hohe Separierbarkeit der FU‑spezifischen Cluster.

Wichtig ist die methodische Einordnung der Aussagekraft: Der Silhouette‑Wert validiert **nicht** die inhaltliche „Richtigkeit“ der Kategorien, sondern ausschließlich die Separierbarkeit der Segmente im verwendeten Repräsentationsraum. Sehr hohe Werte können zudem durch homogene Textbausteine oder stark formatierte/standardisierte Notizen begünstigt werden. Deshalb wird die Silhouette‑Prüfung hier als **Qualitätssicherungs‑ und Plausibilitätsindikator** eingesetzt und konsequent mit inhaltlicher Validierung (Codierschema, Ankerbeispiele, theoretische Einbettung) trianguliert. Ergänzend verweisen @low_data_2023 auf die Reproduzierbarkeit deterministischer Pipelines.

**Qualitätssicherung und Beispiele**

Die KI-gestützte Analyse dient auch der Plausibilitätsprüfung. So wurde der Artikel von @westlake_international_2023 – trotz korrekter Schlagwortzuordnung – als thematisch irrelevant markiert, weil er BDSM-Praktiken untersucht und somit keinen Bezug zum digitalen Bildungsraum aufweist. Diese Prüfung geht über eine reine Stichwortsuche hinaus und verhindert, dass fachfremde Texte in die Auswertung gelangen.

Zur Überprüfung der Trennschärfe wurde die P-QIA auf die klassisch kodierte Studie von @kerman_online_2024 angewendet. Die KI-gestützte Analyse erzielte einen Silhouette-Score von 0,92, die menschliche Kodierung lediglich 0,62. Damit wird sichtbar, dass die probabilistische Validierung methodische Schwächen in manuellen Kodierungen offenlegt und als Ergänzung zur klassischen Inhaltsanalyse fungiert.

**Test- und Diskursbeiträge**

Die Validierung umfasst automatische Kodierungstests, erneute Clusterbildungen mit $k$-means sowie Mehrfachberechnungen des Silhouette-Scores, um die Stabilität über verschiedene Läufe hinweg zu belegen. Zudem wurde geprüft, ob klassische Tools wie ATLAS.ti oder NVivo die gleichen Prüfungen leisten können. Da diese Werkzeuge primär der Unterstützung menschlicher Kodierung dienen, liefern sie keine belastbaren Kennwerte zur objektiven Clustervalidierung. Die P-QIA adressiert damit eine Lücke in der aktuellen Diskussion (z.B. [@biswas_chatgpt_2023; @van_niekerk_addressing_2025; @storey_ai_2023; @parker_negotiating_2024]), indem sie ein überprüfbares Verfahren zur Qualitätsbewertung KI-gestützter Analysen bereitstellt.

**Rolle des Menschen und Grenzen**

Trotz der probabilistischen Komponente bleibt die interpretative Verantwortung grundsätzlich menschlich. Grenzen ergeben sich aus:

- **Parameter- und Modellvariabilität:** Embedding-Modelle und Clusterparameter beeinflussen die Ergebnisse; Entscheidungen müssen dokumentiert und begründet werden.
- **Black-Box-Charakter der Modelle:** Interne Repräsentationen sind nur begrenzt interpretierbar. Transparente Protokolle mildern, aber eliminieren das Problem nicht.
- **Gefahr der Scheinobjektivität:** Statistische Kennwerte ersetzen keine inhaltliche Reflexion. Sie fungieren als Unterstützungs-, nicht als Entscheidungsinstanz.
- **Ethik und Bias:** Fragen nach Datensouveränität, Verzerrungen und Verantwortung müssen explizit adressiert werden.

### 4.3.5 Mehrdimensional-analytische Clustervalidierung (mdaCV) {#sec:mdaCV}

\label{term:mdacv}

Im Zuge der systematischen Literaturarbeit wurde die statistische Clusteranalyse zunächst als Ergänzung zur P-QIA ausprobiert. Die Anwendung des $k$-Means-Algorithmus auf einen bereits deduktiv strukturierten Quellenkorpus bestätigte die bestehenden semantischen Erkenntnisse. Diese Stabilität wurde zur Grundlage eines eigenständigen Validierungsverfahrens, der mehrdimensional-analytischen Clustervalidierung (mdaCV). Sie spannt einen semantischen Raum entlang theoretisch begründeter Achsen (Kategorien, Forschungsfragen, Schlagworte) auf, positioniert die Datenpunkte darin und bewertet deren Trennschärfe über Silhouette-Scores [-@rousseeuw_silhouettes_1987].

Die Methode wird mit zwei modularen Skripten umgesetzt: `analyse_netzwerk.py` erzeugt das semantische Netz samt multidimensionaler Visualisierungen; `analyse_korrelation.py` führt die deduktive k-means-Clusterung und bivariate Korrelationen aus. Beide Module sind versioniert publiziert [@hanisch-johannsen_systematische_2025; @hanisch-johannsen_systematische_2025-1] und im Repository \url{https://github.com/jochen-hanisch/charite-promotion} dokumentiert. Die Operationalisierung der Analysen ist zusätzlich über die Promptvorlagen im Anhang referenziert (Anhänge \hyperref[sec:A-2]{A‑2}, \hyperref[sec:A-3]{A‑3}, \hyperref[sec:A-8]{A‑8} und \hyperref[sec:A-10]{A‑10}). Ihre theoretische Herleitung fußt auf drei Komponenten:

1. **Deduktive Strukturierung des semantischen Raums:** Theoriegeleitete Dimensionen ([@baur_datenaufbereitung_2022; @baur_qualitative_2022]) definieren die Achsen und ermöglichen eine geordnete Positionierung der Daten.
2. **Geometrische Modellierung:** Begriffliche Relationen werden in numerische Vektoren überführt. Konzepte wie CBOW/Skip-gram [@mikolov_efficient_2013] zeigen, dass sich so hochdimensionale, semantisch präzise Repräsentationen erzeugen lassen.
3. **Statistische Validierung:** Die vorstrukturierten Daten werden mittels $k$-Means analysiert. Die Anzahl der Cluster $k$ wird theoriegeleitet festgelegt oder durch Silhouette-Kennwerte feinjustiert [@sud_k-means_2020; @rakhlin_stability_nodate].

Die Pipeline (analyse_netzwerk/analyse_korrelation) überführt die Dimensionen (Forschungsfragen, Kategorien, Suchbegriffe) in Vektoren, berechnet k-means mit Random Starts und liefert Silhouette-Scores sowie Korrelationsmatrizen [@hanisch-johannsen_wirkgefuge_2025-2]; dieselben Parameter ($k = 4$, Euklidische Distanz, Lloyd-Iteration) liegen den Visualisierungen in Abschnitt 4.3.8 zugrunde.

Im Verlauf der Dissertation wurde die mdaCV als dauerhafte Feedback-Schleife eingesetzt. Beispielhaft stieg nach der Bereinigung eines Korpus auf $n = 3502$ Quellen der Silhouette-Score von $0,964$ auf $0,9751$, was als Hinweis auf semantische Schärfung bewertet werden kann. Ein ergänzender methodischer Hinweis betrifft die Interpretation der ab 2023 sichtbar werdenden semantischen Drift im Literaturkorpus. Die Kombination aus steigenden Publikationszahlen bei gleichzeitig sinkenden Silhouette-Scores weist auf eine strukturelle Reorganisation der thematischen Landschaft hin. Dieses Muster ist in datenintensiven Diskursfeldern nicht ungewöhnlich und gilt als typischer Indikator dafür, dass sich die Begriffs- und Themenräume eines Forschungsfeldes verändern, ohne dass dies zwingend mit einer qualitativen Abwertung einhergeht. Vielmehr entstehen in solchen Phasen neue semantische Ankerpunkte, die die bisherigen Strukturzentren überlagern oder ergänzen.

Für die methodische Einordnung signalisiert der Rückgang der Clusterkohärenz verschobene epistemische Schwerpunkte, keine Schwäche der Datenbasis. In von technischer Innovation geprägten Feldern, etwa durch generative KI, die breitere Etablierung von Learning Analytics oder automatisierte Analyseverfahren, treten kurzfristige Fragmentierungen auf, die sich in den Kennwerten von mdaCV und Silhouette zeigen. Die Dynamik lässt sich als temporäre Reorganisation lesen: alte Strukturkerne verlieren an Stabilität, neue Cluster bilden sich aus. Methodisch folgt daraus, Übergänge als systemisch-epistemischen Beobachtungsgegenstand zu behandeln, statt sie als bloße Unschärfe abzutun. Die Drift verweist auf erhöhte Variabilität im Diskurs und macht sichtbar, dass sich die semantische Struktur des Feldes erweitert oder neu justiert. Eine interpretative Dimension ergänzt die empirische Bewertung der Clusterkohärenz und erlaubt eine präzisere Einordnung der Kennwerte. Nach erneuter Einbindung ausgeschlossener Konferenzbände ($n = 3572$) blieb der Score mit 0,9754 stabil. Selbst minimale Änderungen (ein entfernter Buchteil, $n = 3571$) führten zu messbaren Differenzen von 0,001 und machten mikrostrukturelle Effekte sichtbar.

Die mdaCV fungiert damit als seismografisches Instrument. Sie verbindet deduktive Kategorienstrukturen mit quantitativ validierbaren Kennwerten und eröffnet Analysepfade für mikrostrukturelle Dynamiken in semantisch strukturierten Räumen.

### 4.3.6 Epistemische Verlustfunktion ($\epsilon$) als Integritätsmaß {#sec:Epistemische-Verlustfunktion}

Allein der Silhouette-Score erfasst nur die geometrische Separierbarkeit von Clustern. Um zusätzlich die Datenvollständigkeit zu berücksichtigen, wurde eine epistemische Verlustfunktion\label{term:epistemische-verlustfunktion} $\epsilon$ eingeführt. Sie kombiniert die Clusterdifferenzierungsleistung mit dem Verhältnis aus intendierter und tatsächlich verarbeiteter Quellenzahl und fungiert als Monitoring-Größe für datenintensive Prozesse.

**Formel zur Definition der Verlustfunktion:**

$$
\epsilon = (1 - S) + \frac{n_{\text{Soll}} - n_{\text{Ist}}}{n_{\text{Soll}}}
$$ {#eq:verlust}

Ein Beispiel mit $S = 0{,}9754$, $n_{\text{Soll}} = 3585$ und $n_{\text{Ist}} = 3583$ ergibt $\epsilon \approx 0{,}0252$. Der Wert zeigt, dass trotz kleiner Datenlücken eine hohe Integrität erreicht wird. Die Verlustfunktion eignet sich insbesondere als Frühwarnsystem (Verlust von Quellen, unplausible Score-Sprünge) und als zusätzlicher Qualitätsindikator in reproduzierbaren Pipelines.

### 4.3.7 Synthese: Methodische Bedeutung für die Gesamtanalyse {#sec:Datenanalyse-Synthese}

#todo (#61): ist das hier an der richtigen Stelle? Prüfen, $k$-meas n ggf. in 4.3.5 integrieren

Die strukturierte Abfolge aus Analysen erster bis dritter Ordnung, P-QIA, mdaCV und epistemischer Verlustfunktion verbindet deduktive Theorietreue mit datenbasierter Validierungslogik. Damit entsteht ein geschlossenes, aber transparentes System, das qualitative Tiefenanalyse, probabilistische Robustheit und kontinuierliche Selbstüberwachung vereint. Diese Methodik bereitet den Boden für die simulationsgestützten Modellierungen des folgenden Abschnitts.

**k-means-Verfahren (Kurzüberblick):** Für die Clusterbildung wird das klassische $k$-means genutzt (Euklidische Distanz, Lloyd-Iteration), mit $k$ aus Silhouette/Elbow und theoriegeleiteter Justierung sowie Initialisierung per mehrfachem Random Start zur Vermeidung lokaler Minima [@litzel_was_2018; @sud_k-means_2020]. Stabilität und Feature-Selektion werden über Wiederholungen/Stability-Checks reflektiert [@mavroeidis_novel_2011; @rakhlin_stability_nodate], die beschriebenen Limitationen (Sensitivität auf Ausreißer, sphärische Clusterannahme) werden berücksichtigt [@noauthor_drawbacks_2023; @noauthor_what_2024]. Die Zielfunktion lautet:

$$
\arg\min_{\{\mu_j\}, \{C_j\}} \sum_{j=1}^{k} \sum_{x_i \in C_j} \lVert x_i - \mu_j \rVert_2^2
$$ {#eq:kmeans}

Beispielhaft wurde für den Literaturkorpus ($n = 3733$) k = 4 gewählt, mit 20 Random Starts und Standard-Lloyd-Iteration (Konvergenz < 30 Iterationen); der Silhouette-Score lag bei $S \approx 0{,}9884$.

### 4.3.8 Visualisierte Korrelations- und Clusteranalysen {#sec:Korrelations-Cluster}

Zur Absicherung der deduktiven Clusterlogik wurden die zentralen Korrelations- und Clusterauswertungen in der Reihenfolge der Pipeline visualisiert: erst k-means, danach die FU-basierten Matrizen, anschließend Index- und Kategorienebene.

![Deduktive k-means-Clusteranalyse des Quellenkorpus.](<08 Metaquellen/08-01 Abbildungen/methodik/clusteranalyse-kmeans-deduktiv-02-01-suchergebnisse.png>){#fig:clusteranalyse-kmeans}

```{=latex}
\figsubcaption{3D-Projektion der deduktiven $k$-means-Clusterlösung (Quelle: 02-01 Suchergebnisse; $n=3733$, $k=4$, Silhouette-Score: $0{,}9884$). Achsen: Suchbegriffe, Kategorien, Forschungsunterfragen; Farbe: Clusterzugehörigkeit; Punktgröße: Clusterumfang; Labels: dominante Tag- und Eintragstyp-Kombinationen je Cluster.}
```

Die deduktive 3D-Clusterlösung wird in Abb.~\ref{fig:clusteranalyse-kmeans} als semantischer Raum entlang der Achsen Suchbegriffe, Kategorien sowie Forschungsfragen dokumentiert und dient als abschließender Plausibilitätscheck der theoriebasierten Vorstrukturierung.

Die dreidimensionale, deduktiv angelegte Clusteranalyse des Literaturkorpus ($n = 3733$) basiert auf dem $k$-Means-Algorithmus mit vier Clustern. Die Visualisierung projiziert die Datenpunkte entlang der drei deduktiv definierten Achsen Suchbegriffe, Kategorien und Forschungsfragen. Die Größe der Punkte repräsentiert die relative Clustergröße, während die farbliche Kodierung die thematische Zusammensetzung gemäß der zugrunde liegenden Tag-Struktur auswählt. Der hohe Silhouette-Score ($S = 0{,}9884$) spricht für eine ausgeprägte Trennschärfe in der gewählten Repräsentation und wird hier als Hinweis gelesen, dass die deduktive Vorstrukturierung im Korpus konsistent greift. #todo (#84) revision

**Analyse der Achsendimensionen**

Die drei Achsen bilden die theoretischen Dimensionen ab, die zuvor in Kapitel 4.2.3 und 4.3.1 bis 4.3.4 hergeleitet wurden:

- Suchbegriffe beschreiben die diskursiven Zugriffspunkte (z.B. „digital learning“, „online learning“, „learning management system“).
- Kategorien repräsentieren die deduktiv erstellten Inhaltsfelder (z.B. technologische Integration, Lehr- und Lerneffektivität, bildungswissenschaftliche Mechanismen).
- Forschungsfragen (FU$_{1}$–FU$_{7}$) bilden die oberste Deduktionsschicht, aus der die weiteren Analyseschritte abgeleitet wurden.

Durch diese Kombination entsteht ein semantischer, dreidimensionaler Raum, der die Struktur des Literaturkorpus entlang der zentralen Analyseachsen darstellt und eine geometrische Überprüfung der deduktiven Logik ermöglicht.

Die vier identifizierten Cluster sind deutlich voneinander abgegrenzt und bilden somit semantisch-logisch konsistente Themenräume:

1. Cluster 1 (hellblau): Schwerpunkt im Schnittfeld digitale Medien, Buchtitel, Lernumgebung. Hoher Bezug zu FU$_{3}$ (didaktische und technologische Merkmale).
2. Cluster 2 (dunkelblau): Fokus auf Online-Learning, Learning Analytics, bildwissenschaftlichen Theorien. Dominante Bezugspunkte zu FU$_{4a}$ und FU$_{6}$.
3. Cluster 3 (grau): Bereich der technologiegestützten Lehr-Lern-Effektivität, oft verknüpft mit FU$_{2a}$/FU$_{2b}$. Enthält Quellen, die empirische Wirkmechanismen, Vergleichsstudien und Evaluationsdesigns behandeln.
4. Cluster 4 (braun): Theoretische Kernliteratur (Kerngedanke der Promotion), mit starker Anbindung an Technologieintegration, Forschungsansätze und FU$_{7}$. Auffällige Dichte an Basismodellen (TPACK, SDT, Systemtheorie).

#todo (#62) TPACK, SDT, Systemtheorie erklären bzw. referenzieren

Die Dreidimensionalität verdeutlicht, dass die deduktiven Achsen diskriminierende Kraft besitzen und spricht gegen eine rein zufällige Gruppierung; zugleich lassen sich strukturelle Kohärenzen im Diskurs als Raumstruktur darstellen. #todo (#85) revision

Methodologische Einordnung

Die Visualisierung erfüllt folgende Funktionen innerhalb der mdaCV:

- Plausibilisierung der Deduktionslogik: Die drei Achsen sind theoriebasiert definiert. Ihre Trennung im Raum unterstützt die Einordnung, wie sich inhaltliche und methodische Ebenen der Literatur im Korpus verhalten. #todo (#86) revision
- Erkennung diskursiver Schwerpunktfelder: Die Cluster bilden unterschiedlich konzentrierte semantische Regionen ab (z.B. online learning $\to$ FU$_{4a}$/FU$_{6}$ vs. technologische Integration $\to$ FU$_{3}$/FU$_{7}$).
- Überprüfung der Segmentierungs- und Kategorisierungsentscheidungen: Die hohen Silhouette-Werte deuten darauf hin, dass Tags, Kategorien und FU-Zuordnungen im gewählten Raum trennscharf greifen; Überlappungen erscheinen in dieser Projektion begrenzt. #todo (#87) revision

Epistemische Funktion im Forschungsdesign

Die hohe Trennschärfe legt nahe, dass das Literaturfeld im gewählten Raum strukturell differenziert abgebildet wird. Gleichzeitig ermöglichen die geometrischen Abstände eine Abschätzung, wie stark einzelne FU durch bestimmte Themenbereiche getragen werden. #todo (#88) revision

Bedeutung für die Gesamtanalyse

Die 3D-Clusteranalyse fungiert als abschließender, visuell-analytischer Plausibilitätscheck im Zusammenspiel von P-QIA und mdaCV. Im Zusammenspiel mit der systematisch-forschungsfragengeleiteten Literaturpipeline ergibt sich damit ein methodischer Zugang, der etablierte Formen systematischer Reviews mit zusätzlichen Analyseschritten verbindet: Transparente Suchpfade, dokumentierte Screening- und Tagging-Schritte sowie standardisierte, GPT-unterstützte Inhaltsanalysen werden mit Netzwerk-, Pfad- und Korrelationsanalysen verknüpft. Die KI-Unterstützung fungiert dabei als strukturierende Assistenz; eine Ersetzung menschlicher Kontrolle ist nicht intendiert, und alle Zuordnungen (Kategorien, FU, Relevanz) werden in einem zweiten Tagging-Schritt kontrolliert, konsolidiert und stichprobenartig manuell überprüft. #todo (#89) revision

- Sie macht sichtbar, dass die Literaturbasis volumetrisch erfasst ist und im gewählten Raum eine semantische Ausbalancierung erkennbar wird. #todo (#90) revision
- Sie zeigt, welche Themenräume dicht besetzt sind und welche die deduktiven Kategorien besonders stark stützen.
- Sie unterstützt die Begründung der methodischen Kohärenz, indem sie die getrennten Analyseebenen (Suchbegriffe, Kategorien, FU) in einem geometrischen Modell zusammenführt. #todo (#91) revision

Die 3D-Clusteranalyse stützt die theoretisch-probabilistische Struktur des Forschungsdesigns als visuell-analytische Evidenzspur, dass deduktive Kodierung, P-QIA und mdaCV konsistent ineinandergreifen. Zudem kann sie als Kohärenzmaß der probabilistischen Analyse dienen, indem sie die semantische Struktur und Differenzierung des Literaturkorpus entlang der zentralen Analyseachsen verdeutlicht. So entsteht eine Kartierung des Forschungsfeldes, die den Anschluss zwischen deduktiver Theoriearbeit und datenbasierter Plausibilisierung nachvollziehbar herstellt. #todo (#92) revision

Die korrelativen Visualisierungen stellen die semantischen Beziehungen zwischen den zentralen Analyseebenen des Literaturkorpus dar: Forschungsunterfragen (FU$_{1}$–FU$_{7}$), Kategorien, Indizes und Suchbegriffe. Sie ergänzen die dreidimensionale Clusteranalyse, indem sie die Stärke, Richtung und Verteilung der Beziehungen zwischen den deduktiv definierten Dimensionen sichtbar machen. Methodisch handelt es sich um eine quasi-multivariate Strukturanalyse, die die deduktive Architektur der mdaCV mit einer fein granulierten Beziehungssicht verbindet. Der Schwerpunkt liegt auf Mustererkennung, semantischen Relationen und der Plausibilisierung der deduktiven Struktur; hohe absolute Korrelationswerte stehen dabei nicht im Vordergrund. Die vollständigen Korrelationsmatrizen sind im \hyperref[sec:A-4]{Korrelationsatlas (Anhang A-4)} dokumentiert [@hanisch-johannsen_wirkgefuge_2025-2]. #todo (#93) revision

**Forschungsunterfragen × Forschungsunterfragen**

Die Korrelationsstruktur zwischen den Forschungsunterfragen dient der Validierung der deduktiven Logik und zeigt die Muster der Beziehungen, ohne dass hohe absolute Korrelationswerte im Vordergrund stehen. Entscheidend sind Verteilung, Richtung und relative Stärke der Zusammenhänge (vgl. \hyperref[fig:A-kor-fu]{Abb.~A.4.1}).

Analyse: Werte bleiben fast durchgängig im schwach negativen Bereich; punktuell leichte positive Ausreißer (z.B. FU$_{4a}$/FU$_{3}$). Es gibt keine dominanten Achsen, sondern ein fein gestreutes Muster mit einzelnen Verdichtungen bei FU$_{4a}$.

Interpretation: Die FU sind inhaltlich sauber getrennt; die geringe Koppelung zeigt, dass die deduktive Struktur trägt und keine unbeabsichtigten Überschneidungen entstehen. Die wenigen positiven Paare markieren Anschlussstellen (z.B. FU$_{4a}$ $\leftrightarrow$ FU$_{3}$) und bleiben methodisch tolerabel.

**Forschungsunterfragen × Suchbegriffe**

Die Korrelationsstruktur zwischen Forschungsunterfragen und Suchbegriffen dient der Validierung der deduktiven Logik und zeigt die Muster der Beziehungen, ohne dass hohe absolute Korrelationswerte im Vordergrund stehen. Entscheidend sind Verteilung, Richtung und relative Stärke der Zusammenhänge (vgl. \hyperref[fig:A-kor-fu-suchbegriffe]{Abb.~A.4.2}).

Analyse: Positiv verdichtet bei FU$_{4a}$/FU$_{4b}$ in Kombination mit digital learning/medien und E‑Learning; geringe, vereinzelt negative Bezüge bei FU$_{1}$/FU$_{7}$ auf klassische Lernplattform-Begriffe. Werte bleiben insgesamt moderat.

Interpretation: Die Suchbegriffe spiegeln die thematische Fokussierung der FU wider (insb. FU$_{4a}$/FU$_{4b}$), ohne Querbezüge zu dominieren. Das stützt die semantische Passung der Suchstring-Logik zu den FU-Schwerpunkten.

**Forschungsunterfragen × Kategorien**

Die Korrelationsstruktur zwischen Forschungsunterfragen und Kategorien dient der Validierung der deduktiven Logik und zeigt die Muster der Beziehungen, ohne dass hohe absolute Korrelationswerte im Vordergrund stehen. Entscheidend sind Verteilung, Richtung und relative Stärke der Zusammenhänge (vgl. \hyperref[fig:A-kor-fu-kategorien]{Abb.~A.4.3}).

Analyse: Schwerpunkte liegen bei „kerngedanke“ und „weiterführung“, jeweils mit moderaten positiven Bezügen zu FU$_{4a}$, FU$_{4b}$ und FU$_{5}$. „Argumentation“ koppelt erwartungsgemäß leicht an FU$_{3}$/FU$_{4a}$. Negative Werte bleiben marginal.

Interpretation: Die Kategorien greifen an den inhaltlich zugehörigen FU an und bleiben ansonsten entkoppelt. Die moderate Stärke stützt die deduktive Zuordnung und zeigt, dass Kategorien eher als Linsen denn als harte Cluster wirken.

**Forschungsunterfragen × Indizes**

Die Korrelationsstruktur zwischen Forschungsunterfragen und Indizes dient der Validierung der deduktiven Logik und zeigt die Muster der Beziehungen, ohne dass hohe absolute Korrelationswerte im Vordergrund stehen. Entscheidend sind Verteilung, Richtung und relative Stärke der Zusammenhänge (vgl. \hyperref[fig:A-kor-fu-indizes]{Abb.~A.4.4}).

Analyse: Stärkere positive Kopplungen bei technologische Integration, kollaboratives Lernen und Lehr-/Lerneffektivität, vor allem mit FU$_{4a}$/FU$_{4b}$ und FU$_{6}$. Schwache oder neutrale Werte bei FU$_{1}$/FU$_{7}$; negative Ausreißer fehlen praktisch.

Interpretation: Die Index-Logik greift dort, wo die FU inhaltlich tief in Technologie- und Didaktikfragen eintauchen. Die gleichmäßige Verteilung ohne starke Negative zeigt, dass die Indizes die FU-Struktur stützen, nicht überlagern.

**Suchbegriffe × Suchbegriffe**

Die Korrelationsstruktur der Suchbegriffe dient der Validierung der deduktiven Logik und zeigt die Muster der Beziehungen, ohne dass hohe absolute Korrelationswerte im Vordergrund stehen. Entscheidend sind Verteilung, Richtung und relative Stärke der Zusammenhänge (vgl. \hyperref[fig:A-kor-suchbegriffe]{Abb.~A.4.5}).

Analyse: Schwach negative, punktuell positive Knoten entlang digital/blended learning; keine dominanten Hauptachsen. Querbezüge bleiben gering und verteilen sich auf wenige Suchwortpaare.

Interpretation: Die Suchbegriffe sind hinreichend fein granuliert, um Überschneidungen zu vermeiden. Das unterstreicht die Selektivität der Suchordner und verhindert semantische Überlappungen.

**Suchbegriffe × Kategorien**

Die Korrelationsstruktur zwischen Suchbegriffen und Kategorien dient der Validierung der deduktiven Logik und zeigt die Muster der Beziehungen, ohne dass hohe absolute Korrelationswerte im Vordergrund stehen. Entscheidend sind Verteilung, Richtung und relative Stärke der Zusammenhänge (vgl. \hyperref[fig:A-kor-suchbegriffe-kategorien]{Abb.~A.4.6}).

Analyse: Deutliche positive Bezüge zwischen digital/blended learning und den Kategorien „kerngedanke“/„weiterführung“; punktuell negative Werte bei einzelnen Medientiteln. Insgesamt bleibt das Niveau moderat.

Interpretation: Die Kategorien ziehen die Suchbegriffe an, die inhaltlich am Forschungsgegenstand anliegen; periphere Begriffe bleiben schwach oder negativ korreliert. Das bestätigt die Stringenz der dreistufigen Suchordner-Logik.

**Kategorien × Kategorien**

Die Korrelationsstruktur der Kategorien dient der Validierung der deduktiven Logik und zeigt die Muster der Beziehungen, ohne dass hohe absolute Korrelationswerte im Vordergrund stehen. Entscheidend sind Verteilung, Richtung und relative Stärke der Zusammenhänge (vgl. \hyperref[fig:A-kor-kategorien]{Abb.~A.4.7}).

Analyse: Vereinzelte, schwach positive Beziehungen zwischen „argumentation“/„kerngedanke“ und „weiterführung“; ansonsten überwiegend neutrale Felder und nur minimale Negativa.

Interpretation: Die Kategorien sind weitgehend orthogonal. Das stützt die Annahme, dass sie unterschiedliche argumentative Rollen adressieren und nicht kollabieren.

**Indizes × Indizes**

Die Korrelationsstruktur der Indizes dient der Validierung der deduktiven Logik und zeigt die Muster der Beziehungen, ohne dass hohe absolute Korrelationswerte im Vordergrund stehen. Entscheidend sind Verteilung, Richtung und relative Stärke der Zusammenhänge (vgl. \hyperref[fig:A-kor-indizes]{Abb.~A.4.8}) [@hanisch-johannsen_wirkgefuge_2025-2].

Analyse: Deutliche positive Cluster bei technologische Integration, Datenschutz/IT-Sicherheit, kollaboratives Lernen und Lehr-/Lerneffektivität. Kaum negative Werte; neutrale Felder dominieren am Rand.

Interpretation: Die Indizes bilden ein konsistentes, technologie- und didaktikzentriertes Rückgrat. Die hohen Positiva zeigen, dass die deduktiven Achsen auch in der Index-Ebene kohärent wirken und sich gegenseitig verstärken.

**Indizes × Kategorien**

Die Korrelationsstruktur zwischen Indizes und Kategorien dient der Validierung der deduktiven Logik und zeigt die Muster der Beziehungen, ohne dass hohe absolute Korrelationswerte im Vordergrund stehen. Entscheidend sind Verteilung, Richtung und relative Stärke der Zusammenhänge (vgl. \hyperref[fig:A-kor-indizes-kategorien]{Abb.~A.4.9}).

Analyse: Positive Schwerpunkte zwischen „kerngedanke“/„weiterführung“ und Indizes zu technologische Integration, kollaboratives Lernen und Datenschutz/IT-Sicherheit; „argumentation“ koppelt moderat an Lehr-/Lerneffektivität. Negative Werte fehlen praktisch.

Interpretation: Kategorien greifen erwartungsgemäß an den technologie- und didaktiknahen Indizes an. Das Muster zeigt, dass die inhaltlichen Kategorien nicht diffundieren, sondern entlang der deduktiv gesetzten Indexachsen andocken.

**Indizes × Suchbegriffe**

Die Korrelationsstruktur zwischen Indizes und Suchbegriffen dient der Validierung der deduktiven Logik und zeigt die Muster der Beziehungen, ohne dass hohe absolute Korrelationswerte im Vordergrund stehen. Entscheidend sind Verteilung, Richtung und relative Stärke der Zusammenhänge (vgl. \hyperref[fig:A-kor-indizes-suchbegriffe]{Abb.~A.4.10}).

Analyse: Klar positive Paare bei technologische Integration, Bewertungsmethoden und kollaboratives Lernen mit Suchbegriffen zu digital learning, E‑Learning und blended learning. Negative Werte tauchen v.a. bei spezifischen Medientiteln auf, bleiben aber schwach.

Interpretation: Die Suchbegriffe folgen den indexbasierten Schwerpunkten und differenzieren sauber zwischen technologie-/didaktiknahen und peripheren Termfeldern. Das bestätigt die semantische Passung der Suchstrings zur Indexlogik.

### 4.3.9 Auswertung: Eye-Tracking und Umfrage im Vergleich [@hanisch-johannsen_wirkgefuge_2025-1; @hanisch-johannsen_wirkgefuge_2025] {#sec:EyeTracking-Umfrage-Vergleich}

Die Auswertung koppelt Eye-Tracking-Befunde mit den Selbstauskünften der LMS-Umfrage, um Wahrnehmung und tatsächliche Aufmerksamkeit auf UI-Elemente zusammenzuführen [@hanisch-johannsen_wirkgefuge_2025-1; @hanisch-johannsen_wirkgefuge_2025].

- **Stichprobe/Repräsentativität (Eye-Tracking):** Kurs 21-NFS-09: $80\,\%$ ($95\,\%$-KI: $56{,}15$–$103{,}85\,\%$), Kurs 22-NFS-09: $72{,}73\,\%$ ($49{,}73$–$95{,}73\,\%$), Kurs 23-NFS-09: $33{,}33\,\%$ ($17{,}77$–$48{,}89\,\%$), Gesamt: $53{,}33\,\%$ ($44{,}51$–$62{,}15\,\%$). Identische Teilnehmendenzahl je Jahrgang ermöglicht vergleichbare AOI-Analysen; breite KIs in kleinen Kursen werden in der Interpretation berücksichtigt [@hanisch-johannsen_wirkgefuge_2025-1].
- **Eye-Tracking-Befunde (Beispiele):** Heatmaps/Viewmaps/Fog‑Views pro Stimulus zeigen Aufmerksamkeitszentren, Blickpfadtypiken und unbeachtete Zonen [@hanisch-johannsen_wirkgefuge_2025-1]. Auffällige Muster werden als technisch‑gestalterische Mechanismen (FU$_{4b}$) beschrieben und für den Abgleich mit Selbstauskünften operationalisiert.
- **Umfrage-Befunde (Struktur):** Itemweise deskriptive Kennzahlen (Likert/binar) je Jahrgang und Gesamtstichprobe; Freitext separat [@hanisch-johannsen_wirkgefuge_2025]. Die Zuordnung „Frage → Begriffspaar → Einfluss“ (Synopse) dient als Brücke zur weiteren Verdichtung/Modellierung.
- **Triangulation:** Kongruenzen (z.B. hohe berichtete Nützlichkeit + hohe Dwell Time auf relevanten AOIs) stützen die Wirksamkeit der UI; Divergenzen (z.B. berichtet hoher Nutzen, aber geringe AOI-Aufmerksamkeit) markieren Interface-/Passungsbrüche und fließen in die Diskussion ein [@hanisch-johannsen_wirkgefuge_2025-1; @hanisch-johannsen_wirkgefuge_2025]. Subgruppenanalysen (v.a. Jahrgänge sowie Teilnahme am Eye‑Tracking: Ja/Nein) liefern Kontext für differenzierte Einordnung.
- **Limitierungen:** Ökologische Validität des Labors, potenzielle Reaktivität, breite KIs in kleinen Kursen, Selbstselektion in der Umfrage [@hanisch-johannsen_wirkgefuge_2025]. Diese Punkte werden in Kapitel 4.2.4/4.2.5 adressiert und in der Ergebnisinterpretation transparent gemacht.

#todo (#63) Eye-Tracking-Stichprobe und Stimulusreferenzen (F10-S3, F11-S3, F14-S3, Gesamt-Visuals) hier knapp einfügen; Triangulation mit Umfragezahlen benennen.

Eine systematische Reflexion der Eye-Tracking-Daten [@hanisch-johannsen_wirkgefuge_2025-1] erfolgt im Rahmen der methodenkritischen SWOT-Analyse (vgl. Abschnitt 4.5.1), um Potenziale und Limitationen der empirischen Erhebung im Zusammenspiel mit generativer KI zu analysieren.

## 4.4 Simulationsgestützte Modellierung der Kompetenzentwicklung {#sec:Simulation-Kompetenzentwicklung}

Die simulationsgestützte Modellierung dient in dieser Arbeit als formalisierte Verdichtung des in Kapitel \hyperref[sec:SystemischeDynamik]{2.5} entwickelten Dynamikverständnisses und als Brücke zur systemischen Einordnung des LMS als Kompetenzerwerbssystem (FU$_{6}$). Sie wird als Gedankenmodell eingesetzt, um die in der Arbeit rekonstruierten Koppelungen (Rückkopplung, Störung, Regeneration, Entkopplungsrisiken) in eine explizite Zeitlogik zu überführen und dadurch prüfbar zu machen, welche Dynamikformen aus plausiblen Kombinationen von Einflussgrößen entstehen können.

### 4.4.1 Zielstellung und Rolle im Gesamtdesign {#sec:Simulation-Ziel}

Die Simulation adressiert zwei Zwecke:

1. **Dynamische Plausibilisierung**: Kompetenzentwicklung wird als zeitlicher Verlauf modelliert, der aus gekoppelten Einflussgrößen entsteht und dadurch nicht linear und nicht stabil verläuft. Damit wird der Anspruch, den digitalen Bildungsraum als Wirkgefüge zu fassen, in eine formal beschreibbare Dynamik übersetzt.
2. **Indikatorik für Wirkungsdynamik**: Aus den simulierten Verläufen werden Unsicherheits- und Änderungsmaße abgeleitet, die im weiteren Verlauf als heuristische Indikatoren für Regeneration, Störung und Interventionsbedarfe dienen.

Die Simulation ist damit kein Messinstrument; sie ist eine strukturierte Modellierung, die die in der Arbeit verwendeten Begriffe (Kompetenzentwicklung, Rückkopplung, Interdependenz) operativ macht und als zusätzliche Sicht auf die Dynamik des Kompetenzsystems bereitstellt (vgl. \hyperref[sec:Methodologie]{Kapitel 4}; zur Einordnung von FU$_{6}$ vgl. \hyperref[sec:Ergebnisse-FU6]{Abschnitt 5.3.7}).

Im Gesamtdesign wird diese Strukturspur mit dem Training Evaluation Inventory (TEI) verschränkt: TEI liefert eine evaluative Urteilsspur zu Wirkung und Designmerkmalen der Handlungssituationen, während die Simulation die zeitliche Kopplungslogik formal sichtbar macht. Der Abgleich dient als Kohärenz- und Anschlussprüfung (passen Begrifflichkeit, Verlaufstypik und Indikatorik zusammen?).

Perspektivisch ist genau diese Verschränkung als Weiterentwicklung vorgesehen: Simulationsläufe werden mit je konkretem Eingangsparameterstand geführt, und die TEI‑Urteilsspur sowie ergänzende Analytiken aus dem LMS liefern heuristische Ableitungen und Rückkopplungssignale, um Parametrierungen iterativ zu schärfen und Folge‑Läufe gezielt zu variieren.

Der zugehörige Quellcode wird als referenzierbares Artefakt geführt; Reproduktionshinweise und Reproduzierbarkeitsgrenzen sind im Anhang \hyperref[sec:A-15]{A‑15} dokumentiert. [@hanisch-johannsen_simulation_2025; @hanisch-johannsen_tei-bildungswirkgefuge_2025]

### 4.4.2 Modelllogik: gekoppelter Kompetenzverlauf in Quartalen {#sec:Simulation-Logik}

Die Simulation arbeitet quartalsweise über eine definierte Zeitachse und nutzt Monte‑Carlo‑Durchläufe, um nicht einen einzelnen Verlauf, sondern eine Verteilungsfamilie plausibler Verläufe zu erzeugen. [@theis_grundlagen_2002, S. 2; @binder_monte_2017, S. 2–3; @uskov_teaching_2024, S. 49] Pro Durchlauf wird Kompetenz als Zustandsvariable fortgeschrieben; die Quartalsänderung koppelt mehrere Komponenten:

- eine **phasenabhängige Bereitschaftssteigerung** (Anpassung, Verfestigung, Wachstum, Plateau) als Lernort‑/Zeitlogik,
- **Motivations- und Neugieranteile** als dynamische Trägervariablen,
- **persönliche Ereignisse** als Stör- bzw. Verstärkerkomponenten,
- sowie einen Streuungsparameter, der die Unsicherheit in der Entwicklung modelliert.

Diese Kopplung wird als probabilistischer Schritt modelliert: Die Quartalsänderung entsteht als Zufallszug aus einer Normalverteilung, deren Erwartungswert aus der Summe der gekoppelten Komponenten gebildet wird; die Kompetenz wird anschließend in einem plausiblen Wertebereich begrenzt. Durch die Wiederholung vieler Durchläufe entsteht eine Verteilung von Kompetenzverläufen, aus der robuste Lage- und Streuungsmaße abgeleitet werden können (Median/Mittelwert/Standardabweichung pro Quartal). [@theis_grundlagen_2002, S. 4–7; @earl_monte_nodate, S. 3–4; @uskov_teaching_2024, S. 49–50]

Die Logik wird in der Simulation als Familie von Verläufen sichtbar (vgl. \hyperref[fig:sim-montecarlo]{Abb.~\ref{fig:sim-montecarlo}}).

![Kompetenzniveau in quartalsweiser Monte‑Carlo‑Simulation (Beispiel: konstruktivistischer „Standardlernender“, $n=25$ Durchläufe).](<08 Metaquellen/08-01 Abbildungen/didaktik/monte-carlo-simulation_konstruktivistisch-standardlernender.png>){#fig:sim-montecarlo}

```{=latex}
\figsubcaption{Dargestellt sind einzelne Simulationsverläufe über die Quartale. Die Streuung bildet die Bandbreite plausibler Entwicklungsdynamiken im Modell ab.}
```

### 4.4.3 Unsicherheitsrelationen und Wirkungsindikatoren {#sec:Simulation-Indikatoren}

Für die Auswertung werden zwei Unsicherheitsmaße als Grundgrößen geführt:

- $\Delta K$\label{term:delta-k}: kognitive Unsicherheit innerhalb der Kompetenzentwicklung; in der Simulation operationalisiert als Streuung der Kompetenzwerte pro Zeitschritt (z.B. Standardabweichung der simulierten Kompetenzwerte pro Quartal über alle Durchläufe).
- $\Delta E$\label{term:delta-e}: emotionale Unsicherheit innerhalb der Kompetenzentwicklung; in der Simulation operationalisiert über die Streuung emotionaler bzw. bereitschaftsbezogener Dynamikkomponenten (z.B. Streuungsparameter der Quartalsänderung) und ergänzend über die Änderungsrate des mittleren Kompetenzverlaufs als Dynamikspur.

Auf dieser Basis wird der Bildungswirkfaktor\label{term:bildungswirkfaktor} als zeitabhängiges Aggregatmaß gefasst:

$$
\nu(t) = \Delta E(t) \cdot \Delta K(t)
$$ {#eq:bildungswirkfaktor}

Der Bildungswirkindikator\label{term:bildungswirkindikator} beschreibt die Veränderungsrate dieses Faktors:

$$
\iota(t) = \frac{d\nu(t)}{dt}
$$ {#eq:bildungswirkindikator}

Für die Koppelungsprüfung zwischen Dynamikspur und Streuung wird ergänzend ein dynamischer Unsicherheitswert $C$\label{term:unsicherheitswert-c} verwendet, der die Korrelationsstärke mit der Streuung verknüpft:

$$
C = \lvert r(\Delta E, \Delta K) \rvert \cdot \sigma(\Delta E) \cdot \sigma(\Delta K)
$$ {#eq:bildungswirk_c}

Die Auswertung von $\nu(t)$ und $\iota(t)$ erfolgt über Glättung, Ableitungen sowie die Identifikation von Minima, Maxima und Wendepunkten. Damit wird sichtbar, an welchen Stellen die Dynamik in Regenerations‑ oder Störungslogiken kippt und wo in einem formalen Sinn Interventionspunkte markiert werden können. Diese Indikatorik wird in Kapitel \hyperref[sec:Simulation-Kompetenzentwicklung]{4.4} als heuristische Ergänzung genutzt und in Kapitel \hyperref[sec:Ergebnisse-FU6]{5.3.7} in die Systemperspektive auf Kompetenzentwicklung rückgebunden.

#todo (#94) revision: Begriffliche Zuordnung der markierten Zeitfenster systematisieren (4.4.3)
Die Markierungen in den Abbildungen werden im Folgenden als benannte Zeitfenster geführt, um die Interpretation konsistent an die Indikatorik zu binden. Die Bezeichnungen sind als modellinterne Kategorien zu verstehen. Sie strukturieren, welche Form von Dynamikspur im jeweiligen Quartalabschnitt sichtbar wird und welche Art von Beobachtungs- bzw. Gestaltungsfrage daraus folgt. [@hanisch-johannsen_simulation_2025]

- **Stabilisierungspunkt**\label{term:stabilisierungspunkt}: Zeitfenster, in dem $\iota(t)$ in Richtung Abnahme der Unsicherheitsdynamik tendiert und der geglättete Verlauf von $\nu(t)$ eine abflachende Entwicklung aufweist; das Zeitfenster wird für Monitoring und Konsolidierung genutzt.
- **Präventionspunkt**\label{term:praeventionspunkt}: Zeitfenster, in dem $\iota(t)$ eine Zunahme der Unsicherheitsdynamik anzeigt; das Zeitfenster wird für frühzeitige Anpassungen und eine Prüfung von Unterstützungsbedingungen genutzt.
- **Interventionspunkt**\label{term:interventionspunkt}: Zeitfenster um ein lokales Minimum von $\nu(t)$; das Zeitfenster dient der Prüfung, welche Kopplungen (z.B. Feedback, Strukturierung, Ressourcen) die Folgedynamik tragen.
- **Regenerationspunkt**\label{term:regenerationspunkt}: Zeitfenster um ein lokales Maximum von $\nu(t)$; das Zeitfenster dient der Prüfung, welche Stabilisierungspfade (z.B. Rückkopplungsqualität, Entlastung, Anschlussfähigkeit) im Modell sichtbar werden.

Table: Zuordnung von Zeitfenstern zu $\nu(t)$ und $\iota(t)$ \label{tab:sim-zuordnung-nu-iota}

| Begriff | formales Kriterium (heuristisch) | Beobachtungsfokus | Anschluss im Text |
| --- | --- | --- | --- |
| Stabilisierungspunkt | $\iota(t)$ mit stabilisierender Tendenz; geglättetes $\nu(t)$ mit abnehmender Steigung | Stabilisierung/Monitoring | Abschnitt \hyperref[sec:Diskussion-Kopplungsindikatorik]{6.3.1.1} |
| Präventionspunkt | $\iota(t)$ mit ansteigender Tendenz; geglättetes $\nu(t)$ mit zunehmender Steigung | frühe Anpassung/Supportprüfung | Abschnitt \hyperref[sec:Diskussion-Kopplungsindikatorik]{6.3.1.1} |
| Interventionspunkt | lokales Minimum in $\nu(t)$ | Kopplungsträger identifizieren | Abschnitt \hyperref[sec:Simulation-Indikatoren]{4.4.3} |
| Regenerationspunkt | lokales Maximum in $\nu(t)$ | Stabilisierungspfade identifizieren | Abschnitt \hyperref[sec:Simulation-Indikatoren]{4.4.3} |

Die Indikatorik lässt sich als Verlaufsspur illustrieren (vgl. \hyperref[fig:sim-bildungswirkdynamik]{Abb.~\ref{fig:sim-bildungswirkdynamik}}). Zur Einordnung der verwendeten Grundgrößen werden ergänzend die im Beispiel angesetzten Unsicherheitskomponenten und die Unsicherheitsrelation dokumentiert (vgl. \hyperref[fig:sim-unsicherheiten]{Abb.~\ref{fig:sim-unsicherheiten}} und \hyperref[fig:sim-unsicherheitsrelation]{Abb.~\ref{fig:sim-unsicherheitsrelation}}).

![Modellinterne Kopplungsindikatorik: Bildungswirkfaktor $\nu(t)$ und Bildungswirkindikator $\iota(t)$ (Beispiel: konstruktivistischer „Standardlernender“).](<08 Metaquellen/08-01 Abbildungen/didaktik/bildungswirkdynamik_konstruktivistisch-standardlernender.png>){#fig:sim-bildungswirkdynamik}

```{=latex}
\figsubcaption{Dargestellt sind $\nu(t)$ als Aggregatmaß aus $\Delta E(t)$ und $\Delta K(t)$ (Gl.~\eqref{eq:bildungswirkfaktor}) sowie $\iota(t)$ als Veränderungsrate (Gl.~\eqref{eq:bildungswirkindikator}) über die Quartale. Markierungen weisen exemplarisch auf Zeitfenster hin, in denen im Modell Stabilisierung oder Kippdynamiken auftreten.}
```

![Nebenabbildung: Unsicherheitskomponenten im Modellbeispiel (konstruktivistischer „Standardlernender“).](<08 Metaquellen/08-01 Abbildungen/didaktik/unsicherheiten_konstruktivistisch-standardlernender.png>){#fig:sim-unsicherheiten}

```{=latex}
\figsubcaption{Gezeigt sind exemplarische Komponenten (Parameter-/Streuungsanteile), die als Bausteine der modellinternen Unsicherheitsgrößen $\Delta K(t)$ und $\Delta E(t)$ geführt werden (vgl. \hyperref[sec:Simulation-Indikatoren]{Abschnitt 4.4.3}).}
```

![Nebenabbildung: Dynamische Unsicherheitsrelation im Modellbeispiel (konstruktivistischer „Standardlernender“).](<08 Metaquellen/08-01 Abbildungen/didaktik/unsicherheitsrelation_konstruktivistisch-standardlernender.png>){#fig:sim-unsicherheitsrelation}

```{=latex}
\figsubcaption{Gegenübergestellt werden das Produkt der Unsicherheitsgrößen und der dynamische Unsicherheitswert $C$ als Hilfsgröße zur Abschätzung der Kopplungsnähe zwischen $\Delta E$ und $\Delta K$ (Gl.~\eqref{eq:bildungswirk_c}).}
```

### 4.4.4 Passung zum Wirkgefüge-Konzept {#sec:Simulation-Passung}

Die Simulation passt in die Logik dieser Dissertation, weil sie dieselbe Grundannahme formalisiert, die auch die empirische und literaturbasierte Rekonstruktion trägt: Wirkung entsteht aus Koppelungen. Während Kapitel \hyperref[sec:Ergebnisse]{5} Koppelungen als Muster im Literaturkorpus, im Nutzungsvollzug (Eye‑Tracking [@hanisch-johannsen_wirkgefuge_2025-1]) und in Akteur*innenurteilen (Umfrage [@hanisch-johannsen_wirkgefuge_2025]) sichtbar macht, überführt die Simulation diese Koppelungsidee in eine Dynamikform, die Regeneration, Störung und Entkopplungsrisiken als zeitliche Muster darstellbar macht. Damit ergänzt sie den argumentativen Bogen von der systemischen Theorie (Kapitel 2) über die Methodologie (Kapitel 4) bis zur manifestartigen Verdichtung (Kapitel \hyperref[sec:Conclusio-Manifest]{7.0}).

### 4.4.5 Grenzen und methodische Einordnung {#sec:Simulation-Grenzen}

Die Simulation ist als Modellierung sensibel gegenüber Parameterwahl, Verteilungsannahmen und den definierten Koppelungsfunktionen. Ihre Aussagen haben daher den Status einer plausibilisierenden Strukturprüfung: Sie zeigt, welche Dynamiken aus den gewählten Kopplungen folgen können, sie ersetzt keine empirische Kompetenzmessung. Konsequenterweise wird sie in dieser Arbeit als Ergänzung geführt, die die Dynamikbegriffe präzisiert und als Reflexionsfolie für die Interpretation der Kompetenzperspektive (FU$_{6}$) dient.

## 4.5 Reflexion der Methode {#sec:Methoden-Reflexion}

Die kritische Methodenreflexion hat den Zweck, die eigene Arbeitsweise transparent, nachvollziehbar und anhand des wissenschaftlichen Qualitätskriteriums „Methodische Strenge“ [@doring_forschungsmethoden_2023, Seite 89-90] beurteilbar zu machen. Inwiefern diese Arbeit die Anforderungen an eine methodisch saubere, nachvollziehbare und theoriegeleitete Forschung erfüllt, ist in diesem Kapitel zu klären.

Als Herleitungsgrundlage wird ein systemisch-konstruktivistisches Verständnis von Erkenntnis angesetzt, das bewährte Evaluationsmodelle (z.B. das CIPP-Modell) mit analytischen Verfahren wie Korrelations- und deduktiven Clusteranalysen koppelt. Diese Kombination ist strukturell aufeinander bezogen und damit theoriekompatibel. Die Auswahl der Methoden folgt der Forschungsfragengeleitetheit und einem systemisch-funktionalen Verständnis von Methodeneinsatz: Qualitative und quantitative Verfahren werden entlang der FU dort eingesetzt, wo sie zur Bearbeitung beitragen. Theoretische Begriffe (z.B. Kompetenz, Selbstorganisation, Nachhaltigkeit) werden auf konkrete Analyseebenen übertragen, etwa über Prädiktorvariablen (z.B. $PV_{1a}\\text{–}PV_3$) oder KI-gestützte Analysen. Sämtliche Analyseprozesse, von der Auswahl der Quellen über die Generierung und Anwendung der Prompts bis zur Auswertung und Rückführung in die FU, sind dokumentiert, versioniert und theoretisch hergeleitet; die Änderungshistorie ist über eine Versionsverwaltung (GitHub) als fortlaufende Protokollspur nachvollziehbar. Als kuratierende Hilfsmittel unterstützen digitale Werkzeuge dieses Vorgehen operativ (Zotero für Literatur- und Notizmanagement, Python für Berechnungen und Visualisierungen), wodurch Reproduzierbarkeit und interne Konsistenz als Leitkriterien mitgeführt werden. Die Dokumentation der KI-Nutzung (genutzte Systeme, Funktionen, Prompt-Stand, Revisionen) wird dabei als epistemische Validierungsstrategie geführt, um Nachvollziehbarkeit trotz begrenzter Detektierbarkeit KI-generierter Textanteile zu sichern. [@hanisch_nachhaltiges_2017, Kapitel 3.1; Kapitel 3.4; @hebbel-seeger_wissenschaftliches_2025, Seite 438-439]

Bereits in der Zusammenstellung der Analyseeinheiten erfolgen bewusste Entscheidungen, zum Beispiel zur Nichtberücksichtigung von Masterarbeiten und reiner „grauer Literatur“ in bestimmten Clusteranalysen. Diese Schritte werden transparent dokumentiert und theoriebezogen begründet, wodurch Nachvollziehbarkeit und Plausibilisierung der Aussagen gestärkt werden. #todo (#95) revision

Ein wesentlicher Bestandteil des methodischen Vorgehens ist die fortlaufende Selbstprüfung und Justierung. Dazu gehören die Prüfung der Wirksamkeit der Prompts, die Diskussion der Silhouette-Werte zur Clustertrennschärfe, aber auch die bewusste Unterscheidung zwischen Analysen 1. Ordnung (einzelne Quelle) und Analysen 2. Ordnung (übergreifende Auswertung, Rückführung auf die FU).
Dieses methodische Vorgehen ist, trotz seiner systemisch-flexiblen Struktur, darauf ausgerichtet, zentrale Anforderungen wissenschaftlicher Strenge nachvollziehbar zu adressieren. Die Methoden sind theoriebasiert, transparent dargestellt, funktional gewählt und entlang der FU systematisch eingesetzt. Zugleich werden klassische Evaluationslogiken als Ordnungsrahmen mitgeführt und in ein komplexitätssensibles Design übersetzt. #todo (#96) revision

Infolgedessen liegt die wissenschaftliche Eigenleistung in der Strukturierung des Analyseprozesses, der Definition und Trennung der Ordnungsebenen (1. Ordnung: Analyse, 2. Ordnung: Bewertung), der methodologischen Fundierung (deduktiv und theoriebasiert) sowie in der reflexiven Kontrolle des Systems. Dieses Vorgehen ist eigenständig angelegt und transparent dokumentiert. #todo (#97) revision

### 4.5.1 Methodenkritische SWOT-Analyse zum KI-gestützten Vorgehen {#sec:SWOT-KI-Methodik}

Die SWOT-Analyse wird im Rahmen dieser Arbeit als methodisches Reflexionsinstrument eingesetzt, um die Anwendung generativer KI in der literatur- und datengestützten Analyse systematisch zu bewerten. Sie dient neben der Auflistung von Aspekten, weiterhin strukturiert die Auseinandersetzung mit methodischer Robustheit, epistemologischen Potenzialen und Grenzen des gewählten Vorgehens. Damit werden die systemtheoretisch motivierte Forschungsperspektive und eine strategische Betrachtung der methodischen Güte miteinander verknüpft. Hierbei finden interne Faktoren (Stärken, Schwächen) und externe Rahmenbedingungen (Chancen, Risiken) Berücksichtigung. Orientierung bieten die Leitlinien zur SWOT-Analyse im wissenschaftlichen Kontext bei @niederberger_swot-analyse_2015, Seite 35–38 und @hogan_swot-analyse_2009, Seite 258–259.

Table: SWOT-Analyse des KI-gestützten methodischen Vorgehens \label{tab:swot_ki_methodik}

| Kategorie | Inhalt | Maßnahme |
|----------|--------|----------|
| **Stärken** | Analysegeschwindigkeit; transparente Analysepfade; skalierbare Reproduktion (Prompts/Skripte); hohe Clustertrennschärfe; Verbindung qualitativer und quantitativer Auswertung. | Versionierung aller Schritte; reproduzierbare Dokumentation; Sensitivitätsanalysen (Variation von *k*, erneute Clusterläufe). |
| **Schwächen** | Interpretationsspielräume (Black-Box); mögliche algorithmische Verzerrungen; Gefahr, dass Kennwerte Reflexion überlagern; hoher Initialaufwand für Kategorien, Prompts und Pipelines. | Protokollierung aller Parameter; Abgleich der Clusterstruktur mit theoriegeleiteten Kategorien; iterative Prompt-Revision; Voranstellen inhaltlicher Interpretation vor Kennwerten. |
| **Chancen** | Ergänzung klassischer Verfahren um Prüfgrößen (Silhouette, mdaCV); methodische Innovation (P-QIA, mdaCV); Erschließung großer Literaturkorpora; Förderung kollaborativer, versionierter Erkenntnissysteme. | Anwendung auf alle relevanten FU; Vergleich unterschiedlicher Modellläufe; Veröffentlichung von Skripten und Dokumentation; Einbettung in eine datenbasierte Curriculumsforschung. |
| **Risiken** | Scheinobjektivität der Kennwerte; ethische Fragen (Delegation von Bewertung, Datenumgang); Abhängigkeit von Modellarchitekturen/Infrastruktur; Replikationsrisiken; Unterschätzung manueller Kontextkenntnis; sprachliche Homogenisierung und epistemische Verflachung [@hebbel-seeger_wissenschaftliches_2025, Seite 439-440]. | Reflexionspassagen im Methodikteil; Benennung von Grenzen und Annahmen; manuelle Stichproben-Codierungen; Auswahl datenschutzkonformer Umgebungen; Replikationsstrategien bei Modellaktualisierungen; Stil-/Begriffs-Constraints; menschliche Endredaktion; Vergleich mehrerer Prompt-Läufe. |

```{=latex}
\tabsubcaption{SWOT-Analyse des KI-gestützten Vorgehens als methodisches Reflexionsinstrument. Gegenübergestellt werden interne Faktoren (Stärken/Schwächen) und externe Rahmenbedingungen (Chancen/Risiken) sowie jeweils mitgeführte Maßnahmen zur Absicherung von Transparenz, Reproduzierbarkeit und epistemischer Vorsicht.}
```

Die Tabelle bündelt damit die zentralen Befunde und zeigt, welche Maßnahmen unmittelbar mitgeführt werden. Die Stärken (Transparenz, Reproduzierbarkeit und Trennschärfe) werden neben den abstrakten Zuschreibungen in Sensitivitätsanalysen, Versionierungen und reproduzierbaren Dokumentationsketten aktiv genutzt.

Die SWOT-Analyse zeigt Schwächen und Risiken als kontinuierliche Arbeitsaufträge. Interpretationsspielräume, algorithmische Verzerrungen oder Modellabhängigkeiten bleiben nicht unbenannt; sie werden durch theoriegeleitete Gegenlesungen, manuelle Plausibilitätsprüfungen und die bewusste Begrenzung einzelner Kennwerte adressiert. Chancen und Risiken greifen ineinander, und erst in einem verantwortungsbewussten, theorieorientierten und transparent dokumentierten Methodendesign entfalten KI-gestützte Analysen ihren Mehrwert als Ergänzung klassischer Verfahren.

### 4.5.2 Kritische Einordnung und methodische Absicherung {#sec:Methodenkritik-Absicherung}

Methodenkritik ist in dieser Arbeit eine Strukturbedingung des gewählten Vorgehens. Sobald generative KI in Literaturarbeit und Analyseprozess eingebunden wird, sobald embedding-basierte Verdichtungen kategoriale Ordnungen prägen und sobald webcam-basierte Eye-Tracking-Spuren als Aufmerksamkeitssurrogat genutzt werden, verschiebt sich die Beweislast. Die in dieser Arbeit verwendete Methode muss sich an ihrer Prüf- und Dokumentationslogik gemessen lassen, ob die Ergebnisse wissenschaftlich tragfähig bleiben. [@van_niekerk_addressing_2025, Seite 2; @parker_negotiating_2024, Seite 2; @giannakos_promise_2024, Seite 22]

Generative KI: Halluzinationen, Referenzrisiken und Integritätsverschiebung

Die zentrale Kritik lautet, dass GenAI plausibel klingende, aber falsche oder fabrizierte Informationen erzeugen kann und damit die Evidenzlogik wissenschaftlicher Argumentation unterläuft – insbesondere dort, wo Referenzen als Belegfunktion missverstanden werden. Zudem wird beschrieben, dass hybride Human‑KI‑Schreibprozesse neue Integritätskonflikte („postplagiarism“) erzeugen und ohne klare Leitplanken eine unklare Zuschreibung von Autor*innenschaft, Verantwortlichkeit und Prüfpflichten entsteht. [@van_niekerk_addressing_2025, Seite 2; Seite 4; @biswas_chatgpt_2023, Seite 1; Seite 7; @parker_negotiating_2024, Seite 2; @storey_ai_2023, Seite 2]

Genau deshalb wird KI im Workflow als kognitives Assistenzsystem geführt; ihre Outputs gelten grundsätzlich als vorläufige Verdichtung. Das Vorgehen bindet jede KI-Ausgabe an eine menschliche Validierungsverantwortung zurück (Kontrolllesen, Korrektur, Abgleich mit eigener Einschätzung) und sichert Reproduzierbarkeit über Audit-Trails\label{term:audit-trail}: standardisierte Prompts, Versionierung, Parameterprotokolle und dokumentierte Revisionen (Abschnitte \hyperref[sec:Systematische-Literaturrecherche]{4.2.1}, \hyperref[sec:Sekundaranalysen]{4.3.3} und \hyperref[sec:SWOT-KI-Methodik]{4.5.1}). Der in der Literatur geforderte Nachweisweg wird damit über transparente Prozessdokumentation als epistemische Validierungsstrategie erbracht; Detektion KI-generierter Anteile bleibt nachrangig, da sie als begrenzt verlässlich beschrieben wird. [@hebbel-seeger_wissenschaftliches_2025, Seite 434-436; Seite 438-440; @storey_ai_2023, Seite 4]

Embeddings/Clustering: Opazität, Scheinobjektivität und Stabilität

Für embedding-basierte Strukturierungen ist der kritische Punkt weniger die Rechenleistung als die epistemische Übersetzung. Embeddings erzeugen einen leistungsfähigen latenten Ordnungsraum, zugleich können sie die modellinterne Struktur beschatten und damit Verifikation erschweren. In der Clusterlogik wird diese Problematik durch Stabilitätsfragen verschärft: K‑Means kann, abhängig von Minimizer-Geometrie und Stichprobenvariation, zwischen stabilen und instabilen Lösungen kippen, sodass Kennwerte eine trügerische Objektivität suggerieren können, wenn sie nicht als heuristische Prüfgrößen begriffen werden. [@dominici_causal_2024, Seite 1; @rakhlin_stability_nodate, Seite 1-2]

Die P‑QIA führt embedding-basierte Strukturierung explizit als probabilistische Verdichtungsstufe; eine Erklärungsebene wird damit nicht beansprucht. Die interpretative Kontrolle wird über theoriebasierte Deduktion, FU‑Rückbindungen sowie regelgeleitete Kategorienarbeit gesichert (Ankerbeispiele, Benennung/Abgrenzung, Bezug zu Sekundäranalysen; Abschnitte \hyperref[sec:Sekundaranalysen]{4.3.3} und \hyperref[sec:P-QIA]{4.3.4}). In der technischen Verdichtung wird K‑Means als heuristisches Verfahren geführt und über wiederholte Läufe, Random-Starts und Sensitivitätsanalysen (u.a. Variation von *k*) gegen lokale Minima und scheinbare Stabilität abgesichert; Kennwerte (Silhouette/mdaCV) dienen als Prüf- und Monitoringgrößen und bleiben an inhaltliche Gegenlesung gebunden (Abschnitte \hyperref[sec:mdaCV]{4.3.5}, \hyperref[sec:Datenanalyse-Synthese]{4.3.7} und \hyperref[sec:SWOT-KI-Methodik]{4.5.1}). [@baur_qualitative_2022, Seite 691-693; @dominici_causal_2024, Seite 1; @rakhlin_stability_nodate, Seite 1-2]

Webcam-basiertes Eye‑Tracking: Messfehler, Selektions-/Ausschlusslogiken und Interpretationsgrenzen

Die methodische Kritik betrifft hier nicht, ob Eye‑Tracking „spannend“ ist, sondern welche Aussagekraft webcam-basierte Verfahren tatsächlich haben. Sie sind auf Kalibrier-/Validierungslogiken angewiesen, produzieren im Online-Setting hohe Ausschlussraten (mit potenziellen Selektions- und Generalisierbarkeitseffekten) und liefern im Kern eine Approximation des Blickortes, die über Pixel-Fehlergrößen und Annahmen (z.B. gaze‑cursor alignment) begrenzt bleibt. Daraus folgt, dass mikrogranulare Blickpfadinterpretationen epistemisch überziehen, wenn die Daten nicht konsequent als grobe AOI‑Spuren und als triangulative Zusatzlinie geführt werden. [@yang_webcam-based_2021, Seite 1; Seite 17; @wisiecka_comparison_2022, Seite 1; Seite 5; @papoutsaki_webgazer_nodate-1, Seite 1; Seite 5-6]

Die Eye‑Tracking-Daten werden daher als beobachtungsbasierte Indizspur zur Rekonstruktion technisch‑gestalterischer Mechanismen (FU$_{4b}$) geführt; eine kausale Erklärungsebene wird nicht beansprucht. Ihre Interpretation bleibt an das Zusammenspiel mit Selbstauskünften (UM1) und literaturbasierten Tendenzen gebunden (Triangulation; Abschnitte \hyperref[sec:EyeTracking]{4.2.4}, \hyperref[sec:Umfrage-LMS]{4.2.5} und \hyperref[sec:EyeTracking-Umfrage-Vergleich]{4.3.9}). Ausschluss- und Qualitätslogiken werden als Teil der Methode ausgewiesen, nicht als „technisches Rauschen“ entfernt, und die Ergebnisinterpretation wird entlang der Messgrenzen (AOI‑Aggregation, robuste Muster statt feiner Blickpfade) begrenzt. Damit wird die Skalierungschance webcam-basierter Verfahren genutzt, ohne die Validitätsgrenze zu verschweigen. [@hanisch-johannsen_wirkgefuge_2025-1; @yang_webcam-based_2021, Seite 17]

Simulation/Quellcode: Parametrisierung, Reproduzierbarkeit und Interpretationsgrenzen

Die simulationsgestützte Modellierung ist als Softwareartefakt in besonderer Weise von Parametrierungen, Verteilungsannahmen und Implementierungsdetails abhängig. In Monte‑Carlo‑Konstellationen sind Verläufe und Kennwerte zusätzlich sensibel gegenüber Random-States, Laufzahl und Glättungsentscheidungen. [@theis_grundlagen_2002, S. 7, 9 und 20; @earl_monte_nodate, S. 8 und 10; @binder_monte_2017, S. 2–3 und 10; @uskov_teaching_2024, S. 49–50; @rakhlin_stability_nodate, Seite 1-2] Eine plausible Ergebnisform kann dadurch in verschiedenen Varianten auftreten, wobei die interpretative Reichweite an die in Abschnitt \hyperref[sec:Simulation-Kompetenzentwicklung]{4.4} definierte Rolle als Modellspur gebunden bleibt. Die Simulation trägt zur Nachvollziehbarkeit bei, wenn Versionen, Parameterstände, Seeds und Outputartefakte explizit dokumentiert werden; diese Dokumentationslogik wird in Anhang \hyperref[sec:A-15]{A‑15} als Reproduzierbarkeitsspur ausgewiesen. [@hanisch-johannsen_simulation_2025; @hanisch-johannsen_tei-bildungswirkgefuge_2025; @low_data_2023]

Als methodische Begrenzung bleibt dabei relevant, dass die Simulation als Modellspur geführt wird und im Arbeitszusammenhang keine empirische Kompetenzmessung und keine kausale Identifikation trägt. Ihre Funktion liegt in der konsistenten Übersetzung von Koppelungsannahmen in Verläufe, in der Sichtbarmachung von Dynamikformen und in der Reflexionsunterstützung für FU$_{6}$. Eine kritische Prüfung betrifft daher die Passung zwischen Modellannahmen und den in der Arbeit rekonstruierten Befundlinien sowie die Transparenz darüber, welche Setzungen im Code vorgenommen wurden und welche Alternativen plausibel geblieben sind. [@hanisch-johannsen_simulation_2025]

Methodische Stärken

- Forschungsfragengeleiteter Ansatz mit systemischer Perspektive.
- Kombination klassischer Methoden (Literatur, Simulation, Eye-Tracking [@hanisch-johannsen_wirkgefuge_2025-1]) mit innovativen Ansätzen (KI, Python).

Methodische Herausforderungen und Limitationen

- Herausforderungen:
  - Retrospektive Integration einiger Methoden.
  - Entwicklung eines eigenen Paradigmas zur Bearbeitung der Forschungsfragen.
- Limitationen:
  - Komplexität der Datenintegration.
  - Abhängigkeit von KI-Tools und Simulationen.
