\newpage

# 4 Methodologie {#sec:Methodologie}

Kapitel 4 stellt die in dieser Arbeit entwickelte, eigenständige Methodologie dar und spiegelt sie an den wissenschaftlichen Gütekriterien. Das methodische Vorgehen folgt nicht einem klassischen Mixed‑Methods‑Design, sondern einem selbst entwickelten, systemisch‑forschungsfragengeleiteten Paradigma. Dieses Paradigma orientiert sich an systemtheoretischen Prinzipien, koppelt qualitative, quantitative und simulationsbasierte Verfahren über die Forschungsunterfragen und bindet sowohl die in \hyperref[sec:Theorieteil]{Kapitel 2} entwickelte Theorie als auch die in Kapitel \@ref(sec:Forschungsgegenstand) dargestellte Architektur des digitalen Bildungsraums ein. Ziel ist es, die zirkuläre Komplexität des Forschungsgegenstandes abzubilden und methodisch zu strukturieren. Die Auswahl der Verfahren – darunter Literaturanalysen, Eye‑Tracking\label{term:eye-tracking}, simulationsgestützte Modellierungen und quantitative Evaluationsansätze – folgt ausschließlich der Logik der Forschungsunterfragen und dient nicht der Umsetzung eines etablierten Methodendesigns, sondern der Realisierung eines kohärenten, interdependenten und emergenzsensiblen Forschungsansatzes.

Die methodische Kopplung liefert die empirische Basis für die interdependente Argumentation in \hyperref[sec:Diskussion-Interdependenz]{Kapitel 6.3.1} und die manifestartige Zuspitzung in \hyperref[sec:Conclusio-Manifest]{Kapitel 7}.

## 4.1 Forschungsparadigma und methodologischer Ansatz {#sec:Forschungsparadigma}

\label{term:systemisch-forschungsfragengeleitet}

Methodenkompetenz in den Human- und Sozialwissenschaften meint die Fähigkeit, empirische Studien zu lesen, zu interpretieren und eigenständig durchzuführen, um systematische und nachvollziehbare Erkenntnisse zu gewinnen. In der empirischen Sozialforschung werden traditionell drei methodologische Paradigmen unterschieden: (a) quantitative Ansätze im kritischen Realismus, (b) qualitative Ansätze im Sozialkonstruktivismus und (c) pragmatische Integrationsansätze, die beide Logiken situativ verbinden [@doring_forschungsmethoden_2023, Seite 4–5; Seite 32–33]. Für das vorliegende Forschungsvorhaben wird jedoch kein dieser Paradigmen übernommen. Stattdessen wird ein eigenständiger, systemisch‑forschungsfragengeleiteter Ansatz entwickelt, der nicht im Mixed‑Methods‑Paradigma verortet ist, sondern eine eigene Logik entfaltet.

Das quantitative Paradigma folgt einem linear‑strukturierten Forschungsprozess mit vorab formulierten Hypothesen [@doring_forschungsmethoden_2023, Kapitel 2.2], während das qualitative Paradigma einen zirkulären, offen strukturierten Prozess mit explorativen Fragestellungen abbildet [@doring_forschungsmethoden_2023, Kapitel 2.3]. Ausschlaggebend ist weniger die Datenform als die Frage, welches Vorgehen die Forschungsfragen angemessen bearbeitet. Dieses Begründungsgebot strukturiert auch den hier entwickelten systemischen Ansatz.

Der Übergang zur methodologischen Konkretisierung erfolgt entlang der Frage, wie das entwickelte Paradigma praktisch umgesetzt wird. Während Abschnitt 4.1 den erkenntnistheoretischen Rahmen beschreibt, entfaltet Abschnitt 4.1.1 die methodischen Vorüberlegungen und zeigt, wie die Forschungsfragen die Auswahl und Kombination der Verfahren steuern. Abschnitt 4.1.2 konkretisiert diese Logik anschließend systemisch und bildet die Grundlage für die in 4.2 beschriebenen Datenerhebungsverfahren.

### 4.1.1 Vorüberlegungen zur Methodologie {#sec:Voruberlegungen-Methodologie}

Methodisch herausfordernd ist die Verbindung der unterschiedlichen Facetten dieses bildungstheoretischen Forschungsvorhabens. Die unterschiedlichen Datenformen – aus Eye‑Tracking, Umfrage, systematischer Literaturarbeit und simulationsgestützten Modellierungen – werden nicht im Sinne eines Mixed‑Methods‑Designs zusammengeführt, sondern entlang der Forschungsfragen koordiniert. Die Integration folgt keinem etablierten Kombinationsschema, sondern dem eigenen Paradigma der Forschungsfragengeleitetheit. Die Hauptforschungsfrage legitimiert den Einsatz beider Paradigmen, da sie Muster und Regelmäßigkeiten im Learning Management System (LMS) sichtbar machen soll. Das Spannungsfeld zwischen Subjektivität (Wahrnehmung der Akteur*innen) und Objektivität (Kompetenzentwicklungssimulation) verlangt eine präzise methodische Betrachtung. Die strikt getrennte Zuschreibung „quantitativ = deduktiv“ und „qualitativ = induktiv“ greift dabei zu kurz, weil sie die Komplexität des Gegenstands nicht abbildet [@reinders_uberblick_2022, Seite 157].

Forschung in Gesundheitskontexten muss divergierende methodische Strömungen mehrerer Disziplinen integrieren. Komplexität, Vielfalt der Disziplinen und unterschiedliche Ressourcen sind auszubalancieren; deshalb werden hier die Stärken bestehender Methoden in einen neuen, interdisziplinären und generativen Kontext gestellt [@niederberger_qualitative_2021, Seite 4-5].


Der hier entwickelte Ansatz verzichtet bewusst auf die Einordnung in Mixed‑Methods‑Traditionen. Stattdessen werden qualitative, quantitative und simulationsbasierte Verfahren so gekoppelt, dass sie die zirkuläre Komplexität des Forschungsgegenstandes systemisch abbilden. Die Methoden stehen nicht nebeneinander, sondern werden über Interdependenz, Emergenz und Rückkopplung verbunden.

Das Forschungsvorhaben verlangt aufgrund seiner zirkulären Komplexität einen mehrdimensionalen Ansatz, der die Ebenen systematisch koppelt. Wie Rosenthal und Witte ausführen, stützt sich die Methodik auf die Anerkennung unterschiedlicher Zugänge zur Erforschung sozialer Phänomene und auf die grundlagentheoretische Differenzierung zwischen quantitativen und qualitativen bzw. interpretativen Ansätzen [@mays_quanti_2020, Seite 198-199]. Die Arbeit positioniert sich als abstrakt-theoretische Grundlagenforschung und will methodische Vielfalt anerkennen sowie systematisch integrieren.


Das forschungsparadigmatische Spannungsfeld wird aufgelöst, indem die Methoden konsequent aus den Forschungsfragen abgeleitet werden. Dadurch entsteht eine zielgerichtete Auswahl, die Komplexität reduziert, der Mehrdimensionalität gerecht wird und die Stärken etablierter Methoden bündelt.

Die dargestellten Vorüberlegungen verdeutlichen, dass die Methodologie nicht durch bestehende Designs vorstrukturiert ist, sondern ihre Logik unmittelbar aus den Forschungsunterfragen ableitet. Darauf aufbauend entwickelt Abschnitt 4.1.2 die systemische Ausgestaltung dieses Ansatzes und präzisiert die operative Verbindung zwischen Paradigma, Forschungslogik und Methodenwahl.

### 4.1.2 Systemisch-forschungsfragengeleiteter Ansatz {#sec:Systemisch-Forschungsfragengeleitet}

Der systemische, forschungsfragengeleitete Ansatz fußt auf den Forschungsfragen FU1 bis FU7 (Kapitel [@sec:FU-Herleitung]), abgeleitet aus Erkenntnisinteresse (Kapitel [@sec:Erkenntnisinteresse]) und LMS-Produkt (Kapitel [@sec:Forschungsgegenstand]). Diese Fragen strukturieren sämtliche Entscheidungen und Analysen. Diese Methodik verschränkt qualitative, quantitative und simulationsbasierte Zugänge über die Logik der Forschungsunterfragen, ohne sie einem übergeordneten Mixed‑Methods‑Schema zu unterstellen. Die Verbindung entsteht ausschließlich über die Forschungsfragen und ihre systemische Logik.

Interdependenz meint die enge Verknüpfung der Forschungsfragen und die Wechselwirkungen zwischen qualitativen und quantitativen Daten, die die Mehrdimensionalität erfassen. Emergenz beschreibt die Entstehung neuer Erkenntnisse [@bertalanffy_general_1968, Seite 16, 103], wenn Ergebnisse aus Literaturanalysen, Simulationen und empirischen Untersuchungen wie Eye-Tracking und Befragungen verbunden werden. Rückkopplung heißt, dass Analyseergebnisse iterativ in die Methodik zurückfließen und weitere Schritte steuern, sodass der Prozess dynamisch bleibt.


Konkret werden Methoden aus den Forschungsfragen abgeleitet; jede Frage bestimmt die Auswahl. Qualitative Literaturanalysen werden mit Eye-Tracking-Analysen (z.B. Heatmaps) und quantitativen Befragungen systematisch in Beziehung gesetzt, um subjektive Wahrnehmungen und objektive Muster zugleich abzubilden. Die passgenaue Methodenkombination reduziert Komplexität auf ein analytisch erfassbares Maß, ohne wesentliche Wirkungsmechanismen zu verlieren. Iterative Rückkopplung und systemische Verknüpfung erzeugen Einsichten, die isoliert verborgen blieben, und erweitern bestehende Ansätze um einen Rahmen, der Offenheit und strukturelle Präzision verbindet.

Auf dieser Grundlage beschreibt Abschnitt 4.2 die konkrete Umsetzung der Datenerhebungsverfahren. Die dort erläuterten Schritte – von der systematischen Literaturrecherche über das Eye-Tracking bis zur LMS‑Umfrage – sind direkt aus der hier beschriebenen Paradigma‑Logik abgeleitet und folgen der systemischen Kopplung der Forschungsunterfragen.

Table: Zuordnung der Bearbeitungsmethoden zu den Forschungsunterfragen {#tab:methoden_FU}

| Forschungsunterfrage | Bearbeitungsmethode | Erfüllungskriterien |
| --- | --- | --- |
| **FU1: Akzeptanz und Nützlichkeit** | Qualitative Metaanalyse zur Darstellung des aktuellen Forschungsstandes im Kontext digitaler Bildungsräume [@doring_forschungsmethoden_2023, Seite 194]. | Darstellung und Einordnung der Akzeptanz- und Nutzenargumente in das Gesamtgefüge. |
| **FU2a: Effekt auf Lernende** | Evaluationsframework nach Kirkpatrick sowie Training Evaluation Inventory zur Wirksamkeitsanalyse der Lernprozesse [@kirkpatrick_evaluating_1998; @ritzmann_training_2014; @ritzmann_tei_2020]. | Quantitative Evaluation der Kompetenzentwicklung und ihrer Unsicherheiten. |
| **FU2b: Effekt auf Lehrende** | Halbstrukturiertes Gruppeninterview im Face-to-Face-Kontakt mit Lernenden und Lehrenden [@doring_forschungsmethoden_2023, Kapitel 3.2; @doring_forschungsmethoden_2023, Kapitel 10.2]. | Ableitung generalisierbarer Aussagen zu wahrgenommenen Effekten und Einflussfaktoren. |
| **FU3: Didaktische und technologische Merkmale** | Theoriearbeit zur systemisch-konstruktivistischen Gestaltung des LMS und zur Beschreibung seiner Architektur [@doring_forschungsmethoden_2023, Kapitel 6.3.1]. | Herleitung, Beschreibung und Absicherung der relevanten Merkmale des LMS. |
| **FU4a: Bildungswissenschaftliche Mechanismen** | Qualitative Inhaltsanalyse nach Mayring sowie deren Weiterentwicklungen [@mey_qualitative_2010; @mayring_neuere_2008]. | Herleitung, Beschreibung und Absicherung der bildungswissenschaftlichen Wirkmechanismen. |
| **FU4b: Technisch-gestalterische Mechanismen** | Quantitative Beobachtung (inkl. Eye-Tracking) und simulationsgestützte Theorieprüfung [@doring_forschungsmethoden_2023, Kapitel 10.1.3; @doring_forschungsmethoden_2023, Kapitel 6.3.1]. | Datenerhebung, Auswertung sowie Rückbindung an die theoretische Modellierung. |
| **FU5: Möglichkeiten und Grenzen** | Kombination aus Qualitativer Inhaltsanalyse und SWOT-Analyse zur systemischen Bewertung [@mey_qualitative_2010; @niederberger_swot-analyse_2015]. | Strukturierte Darstellung der Potenziale und Limitationen des Trainingsmodells. |
| **FU6: LMS als Kompetenzerwerbssystem** | Systemische Theoriearbeit zur Verschränkung von Kompetenzforschung und LMS-Architektur [@doring_forschungsmethoden_2023, Kapitel 5]. | Transfer und Einordnung der Ergebnisse in ein konsistentes Kompetenzentwicklungsmodell. |
| **FU7: Erweiterung von Kausalgesetzen** | Grounded-Theory-basierte „Einfall und Theorieentwicklung“ sowie Analyse des Technologiedefizits [@pentzold_praxis_2018, Einleitung; @luhmann_technologiedefizit_1982]. | Entwicklung und Ableitung eines kausalen Ursachen-Wirkungstheoriemodells. |

Die Tabelle fasst die Forschungsunterfragen zusammen und verknüpft sie mit den jeweils eingesetzten Methoden sowie ihren Erfüllungskriterien. Auf diese Weise wird nachvollziehbar, wie qualitative Literaturarbeit, empirische Erhebungen (Eye-Tracking, Interviews, Umfragen) und simulationsbasierte Verfahren im Zusammenspiel verwendet wurden, um die unterschiedlichen Facetten des Lernmanagementsystems abzubilden.

Methodische Konsequenzen der Forschungsfragen

- Die Forschungsfragen bestimmten:
  - Auswahl und Strukturierung der Literatur.
  - Entwicklung von Kategorien und Schlagworten zur thematischen Verknüpfung.
  - Kombination und Anpassung klassischer Methoden.
- **Begründung**:
  - Die Komplexität des digitalen Bildungsraums erforderte eine Methodenkombination, um die Forschungsfragen adäquat zu beantworten.

## 4.2 Datenerhebung {#sec:Datenerhebung}

### 4.2.1 Systematische Literaturrecherche {#sec:Systematische-Literaturrecherche}

Die systematische Literaturrecherche bildet die Grundlage für die Beantwortung der Forschungsfragen FU1, FU3, FU4a und FU6. Ziel ist hierbei, ein umfassendes Verständnis der bestehenden wissenschaftlichen Diskussionen und Erkenntnisse im Bereich digitaler Bildungsräume zu erlangen. Die Analyse umfasst insgesamt 3 733 wissenschaftliche Arbeiten, die algorithmisch aus verschiedenen Datenbanken extrahiert und thematisch kategorisiert wurden (Datenstand: 13.12.2025).

Die systematische Literaturrecherche folgt einem klar definierten, mehrstufigen Workflow (vgl. Abbildung X). Ausgangspunkt sind zwei kontinuierliche Zuführungen von Quellen: (1) automatisierte Google-Alerts, die einschlägige Veröffentlichungen zu vordefinierten Stichworten melden, und (2) zufällige Quellenfunde, die im Rahmen der laufenden Forschungs- und Praxistätigkeit auftreten. Beide Zuführungen werden zunächst als „Einzelne Quelle“ in das Literaturmanagementsystem überführt und mit den notwendigen Metadaten (Titel, Autor*in, Jahr, Publikationstyp) versehen.

In einem ersten Entscheidungsschritt wird die Verfügbarkeit der Quelle geprüft (Zugriff auf Volltext, Abstract, bibliografische Angaben). Ist der Volltext nicht zugänglich, kann die Quelle dennoch als Impulsgeber für die Suchstrategie dienen, wird aber nicht in die inhaltliche Hauptanalyse übernommen. Verfügbare Quellen durchlaufen eine Prüfung, ob sich aus ihnen konkrete Suchbegriffe ableiten lassen. Ergibt sich ein inhaltlicher Mehrwert, werden sie im Sinne einer „Erweiterung“ genutzt, um das Suchvokabular zu verfeinern und zusätzliche, thematisch angrenzende Begriffskombinationen zu identifizieren.

Kern der Suchstrategie ist ein Set aus zwölf priorisierten Schlagwortclustern, die jeweils als Suchpfad in unterschiedlichen Datenbanken (z. B. Google Scholar, BASE, FIS Bildung, PubMed) umgesetzt wurden: #1 Learning Management System, #2 Online Lernplattform, #3 Online Lernumgebung, #4 MOOCs, #5 E-Learning, #6 Bildung, #7 Digitale Medien, #8 Blended Learning, #9 Digitales Lernen, #10 Online Lernen, #11 Online Learning und #12 Digital Learning. Jede Quelle wird einem oder mehreren dieser Suchpfade zugeordnet und im Literaturmanagement als „Eintrag DB“ dokumentiert. Die technische Umsetzung der Ordner- und Tag-Struktur wird in \hyperref[sec:Systematisches-Literaturmanagement]{Abschnitt 4.2.2} detailliert beschrieben.

Die Treffer aus allen Suchpfaden werden einem dreistufigen Screening unterzogen, das zugleich die Ein- und Ausschlusskriterien operationalisiert. In der Titel-Suche werden auf Basis von Titel, Jahr, Sprache und Publikationstyp offensichtlich irrelevante oder außerhalb des Forschungsfeldes liegende Arbeiten ausgeschlossen („Ausschluss“). In der nachfolgenden Abstract-Suche erfolgt eine inhaltlich feinere Prüfung, ob die Quelle tatsächlich einen Beitrag zum Verständnis digitaler Bildungsräume, von Learning-Management-Systemen oder angrenzender Formate leistet. Erst wenn die Relevanz auf Abstract-Ebene bestätigt ist, schließt sich – falls erforderlich – eine Inhaltsuche im Volltext an, in der Kontext, Methode und theoretische Verortung geprüft werden. Quellen, die diesen dreistufigen Filter durchlaufen, bilden den Kernkorpus der Analyse.

Für alle übernommenen Quellen wird anschließend ein erstes, manuelles 1. Tagging vorgenommen. Dabei werden unter anderem Suchpfad, Dokumententyp, thematischer Schwerpunkt, Bezug zu Learning-Management-Systemen sowie eine vorläufige Zuordnung zu den Forschungsunterfragen erfasst. Dieses erste Tagging strukturiert das Korpus und legt die Grundlage für die KI-gestützte Inhaltsanalyse. In einem nächsten Schritt wird jede Quelle in einem standardisierten Prompt-Format mit GPT verarbeitet. Die KI erstellt eine strukturierte Zusammenfassung, extrahiert Kernaussagen, rekonstruiert die Argumentation, schlägt eine Indexierung zentraler Begriffe vor, ordnet die Quelle thematischen Kategorien zu, nimmt eine explizite Zuordnung (FU) zu den Forschungsunterfragen vor und formuliert eine graduelle Relevanzbewertung. Die KI-Ausgaben werden nicht ungeprüft übernommen, sondern im Lektüreprozess kontrolliert, gegebenenfalls korrigiert und mit den eigenen Einschätzungen abgeglichen.

Auf Basis dieser aufbereiteten Informationen erfolgt ein zweites, vertiefendes 2. Tagging. Hier werden die automatisiert vorgeschlagenen Kategorien konsolidiert, die Zuordnung zu den Forschungsunterfragen geschärft und die Relevanzstufen final festgelegt. Gleichzeitig werden zusätzliche Tags vergeben, die für spätere Netzwerk- und Pfadanalysen erforderlich sind (z. B. didaktische Mechanismen, technologische Funktionen, Kompetenzdimensionen). Das Ergebnis ist ein dicht codierter Literaturkorpus, in dem jede Quelle mehrfach – über Suchpfade, Kategorien, Forschungsunterfragen und Relevanzgrade – verknüpft ist.

Im Anschluss werden die kodierten Daten exportiert und in einer statistischen und graphischen Auswertungsumgebung weiterverarbeitet. Dort entstehen unter anderem Netzwerkvisualisierungen der Tag-Struktur sowie Netzwerk-Plotanalysen, die Co-Vorkommen von Kategorien, Forschungsunterfragen und zentralen Konzepten sichtbar machen. Auf dieser Basis wird ein Pfaddiagramm der Datenflüsse im Korpus rekonstruiert, das die Hauptströme von den Suchpfaden über Kerngedanke und Argumentation hin zu Technologieintegration, Lehr-/Lerneffektivität und weiteren Kategorien nachzeichnet. Die so gewonnenen Pfade dienen der Synthese: Sie markieren jene Segmente des Diskurses, in denen sich theoretische und empirische Verdichtungen zeigen, und bilden die Grundlage für die abschließende Modellbildung und theoretische Strukturierung des digitalen Bildungsraums.

Der gesamte Prozess – von Beginn (Google-Alert beziehungsweise zufällige Quelle) über Screening, doppeltes Tagging und KI-Unterstützung bis hin zu Netzwerk- und Pfadanalysen – ist damit als zirkulärer, transparent dokumentierter Recherche- und Analysepfad angelegt. Er stellt sicher, dass die in dieser Arbeit entwickelten Aussagen zu digitalen Bildungsräumen nicht auf Einzelstudien, sondern auf einem systematisch erschlossenen und strukturell ausgewerteten Literaturfeld beruhen.

Die folgende Abbildung fasst diesen Workflow schematisch zusammen und dient als Referenzrahmen für die in Abschnitt 4.3 beschriebenen Auswertungen; für das Verständnis der weiteren Darstellung sind vor allem die Übergänge zwischen Suche, Tagging und Export relevant.

\begin{figure}[ht]
  \centering
  \input{08 Metaquellen/08-01 Abbildungen/prozesse/lit_workflow.tex}
  \caption{Ablaufschema der systematischen Literaturrecherche und -analyse.}
  \label{fig:lit-workflow}
\end{figure}

![Zeitreihe der Publikationszahlen im Korpus; Grundlage für die Auswahl und Gewichtung der Jahrgänge in der Analyse.](08 Metaquellen/08-01 Abbildungen/methodik/visualize_time_series_02-01_suchergebnisse.png){#fig:time-series width=90%}

Die Zeitreihe der jährlichen Veröffentlichungszahlen dokumentiert die volumetrische Entwicklung des untersuchten Literaturkorpus seit den späten 1970er-Jahren. Bis etwa 2005 bleibt das Publikationsaufkommen marginal und bewegt sich durchgehend im einstelligen Bereich. Diese Phase stellt kein eigenständiges Diskursfeld dar, sondern ein vereinzeltes Auftreten thematisch verwandter Arbeiten ohne strukturbildende Wirkung. Ab 2010 ist ein moderater Anstieg sichtbar, der jedoch erst ab 2016 in eine klare Konsolidierungsphase übergeht: Die jährlichen Fallzahlen steigen kontinuierlich, erreichen 2018 erstmals einen dreistelligen Bereich und markieren damit den Beginn eines systematisch etablierten Forschungsfeldes.

Ab 2019 setzt ein exponentieller Wachstumstrend ein, der als Indikator einer massiven thematischen Erweiterung und Verdichtung zu interpretieren ist. Die Jahre 2020 bis 2023 bilden den quantitativen Höhepunkt der Entwicklung; das Jahr 2023 erreicht mit über $900$ Einträgen den Maximalwert des gesamten Korpus. Dieser starke Anstieg kann charakteristisch für Felder sein, in denen digitale Transformation, Technologieintegration und KI-basierte Methoden erhebliche Impulse erzeugen. Zugleich korrespondiert dieses Phänomen mit den Ergebnissen der nachfolgenden Silhouette-Analyse. Hohe Volumina führen nicht automatisch zu höherer Kohärenz, vielmehr können diese in dynamischen Feldern typischerweise eine temporäre Fragmentierung erzeugen.

Der Rückgang im Jahr 2024 kann trotz weiterhin hoher Publikationszahlen als Reorganisationsphase des Diskurses verstanden werden. Themenräume wie Learning Analytics, generative KI oder datenbasierte Didaktik verschieben bestehende epistemische Zentren. Die im Jahr 2025 sichtbare Stabilisierung deutet auf eine Normalisierung nach der Phase beschleunigten Wachstums hin; die bis November erfassten Werte bilden erwartungsgemäß nur einen Teil des Jahres ab.

Methodologisch zeigt die Zeitreihe, weshalb eine Kombination aus volumetrischer Betrachtung, Kohärenzanalysen (Silhouette), Sensitivitätsmaßen ($\Delta SC_n$) und deduktiver Strukturierung notwendig ist. Die reine Publikationszahl erlaubt keine Aussage über die semantische Struktur des Feldes. Erst im Zusammenspiel mit der Clusterkohärenz wird erkennbar, welche Jahre ein belastbares epistemisches Fundament darstellen (2018–2022) und welche Jahre aufgrund struktureller Transformation mit besonderer Sensitivität zu interpretieren sind (2023–2024). Diese Differenzierung ist für die retrospektive Gewichtung der Jahrgänge zentral und legitimiert den Einsatz der P-QIA, der mdaCV sowie der epistemischen Verlustfunktion als integrative Validierungsinstanzen des ausgewerteten Literaturraums.

Bemerkenswert ist, dass die Auswahl frei von subjektivem Eingreifen, thematischen Vorannahmen oder bewussten Schwerpunktsetzungen erfolgte und ausschließlich auf algorithmisch rekonstruierten Dichtefeldern innerhalb deduktiv-numerischer Vektorräume basiert. Die Aussagen aus diesem Literaturfeld können damit als stabil, kohärent und epistemisch tragfähig gelten; sie bilden gewissermaßen den empirischen Kern des aktuellen Diskurses.

Table: Jährliche Entwicklung der Clusterbildung und Silhouette-Scores \label{tab:cluster_silhouette}

| Jahr | $n$ | Cluster | Silhouette-Score |
| --- | --- | --- | --- |
| 2010 | 7 | 2 | 1.0000 |
| 2011 | 29 | 4 | 0.9655 |
| 2012 | 7 | 3 | 0.8571 |
| 2013 | 28 | 4 | 1.0000 |
| 2014 | 24 | 4 | 0.9583 |
| 2015 | 28 | 3 | 1.0000 |
| 2016 | 25 | 3 | 1.0000 |
| 2017 | 98 | 3 | 1.0000 |
| 2018 | 95 | 4 | 0.9895 |
| 2019 | 202 | 3 | 1.0000 |
| 2020 | 303 | 4 | 0.9968 |
| 2021 | 377 | 4 | 0.9854 |
| 2022 | 430 | 4 | 0.9916 |
| 2023 | 899 | 4 | 0.9702 |
| 2024 | 780 | 4 | 0.9208 |
| 2025 | 192 | 4 | 0.9696 |
| **Summe** | 3524 | — | — |

Die Summenzeile dokumentiert die 3 524 für die Kohärenzberechnung herangezogenen Dokumente. Bis 2016 bleiben die Fallzahlen niedrig, die Silhouette-Scores liegen aber durchgängig bei $\approx 1{,}0$ und weisen auf hochgradig fokussierte Cluster hin. In den Jahren 2018–2022 steigt das Volumen stark an, während die Scores auf hohem Niveau bleiben ($\geq 0{,}985$); diese Phase bildet den stabilen epistemischen Kern des Korpus. Der Einbruch auf $0{,}9208$ im Jahr 2024 markiert die stärkste semantische Drift durch die rasche Ausweitung neuer Themen (z. B. KI-basierte Lernmodelle), bevor 2025 eine moderate Rezentrierung der Cluster sichtbar wird. Insgesamt zeigt die Tabelle, dass hohe Fallzahlen nicht automatisch Kohärenzverlust bedeuten, Wachstumsphasen aber interpretativ besonders sorgfältig eingeordnet werden müssen.

![Silhouette-Scores und Fallzahlen pro Jahr; linke Achse zeigt die Clustertrennschärfe, rechte Achse die Fallzahlen.](08 Metaquellen/08-01 Abbildungen/methodik/silhouette-scores-und-fallzahlen.png){#fig:silhouette-scores width=90%}

Die Abbildung zeigt die gemeinsame Entwicklung von Silhouette-Scores und Fallzahlen und verdeutlicht damit die semantische Stabilität des recherchierten Literaturfeldes über die Zeit. In den Jahren 2010–2016 liegen trotz geringer Fallzahlen nahezu perfekte Silhouette-Scores vor ($\approx 1.0$). Methodisch interpretiert markiert dies eine Phase, in der die thematische Struktur so eng gefasst ist, dass jedes zusätzliche Dokument inhaltlich nahezu identisch anschließt. Der Zeitraum 2018–2022 kombiniert dann hohe Fallzahlen mit durchgängig über dem Median liegenden Werten ($Q_2 \approx 0{,}99$). Diese Jahre bilden das robuste epistemische Fundament des Korpus d.h. hohe Dichte, hohe Trennschärfe und deutliche Clusterzentren.

Ab 2023 sinkt der Score trotz weiterhin sehr hoher Fallzahlen. Der Tiefpunkt ($0,9208$ im Jahr 2024) zeigt eine semantische Drift, das heißt eine zunehmende Heterogenität des Feldes, ohne dass die Relevanz oder Qualität des Korpus abnimmt. Vielmehr reorganisieren sich die thematischen Schwerpunkte in einem dynamischen Diskursfeld (z. B. Learning Analytics, KI-basierte Lernsysteme, generative Modelle). Die moderate Erholung 2025 verweist auf eine mögliche Neuordnung der semantischen Zentren. Die quartilsbasierten Referenzlinien ($Q_1 \approx 0{,}9686$, $Q_3 = 1{,}0000$) und die Fatigue-Schwelle von $0,96$ markieren die Übergänge zwischen kohärenten Verdichtungsphasen und beginnender Fragmentierung. Damit lässt sich die Aussagekraft einzelner Jahrgänge systematisch gewichten, belastbare Kohärenzphasen identifizieren und die Qualität der algorithmischen Clusterbildung retrospektiv validieren.

![Delta von Silhouette-Scores und Fallzahlen pro Jahr als ergänzende Sensitivitätsanzeige zur Stabilität der Clusterkohärenz.](08 Metaquellen/08-01 Abbildungen/methodik/delta-sc-n-pro-jahr.png){#fig:delta-silhouette width=90%}

Die ergänzende Darstellung der Abweichung $\Delta SC_n$ führt eine Sensitivitätsperspektive auf die Clusterkohärenz ein. Während der Silhouette-Score die geometrische Trennschärfe der Cluster bewertet, zeigt $\Delta SC_n$, wie stark die relative Kohärenz eines Jahres unter Berücksichtigung des jeweiligen Volumens ($n/\max(n)$) vom stabilen Erwartungswert abweicht. Positive Werte verweisen auf Jahre, in denen die semantische Kohärenz überproportional höher ausfällt, als es die Fallzahl erwarten ließe – typischerweise Verdichtungsphasen mit klaren thematischen Zentren. Die Jahre 2010–2017 zeigen hierfür charakteristische Ausschläge: geringe n, aber überdurchschnittlich kohärente semantische Felder, was die zuvor beschriebenen stabilen Kernbereiche der Literatur bestätigt.

Ab 2018 pendelt $\Delta SC_n$ um den Median, was eine weitgehend proportionale Entwicklung von Korpusgröße und thematischer Konsistenz signalisiert. Auffällig sind die negativen Ausschläge der Jahre 2023–2025. Sie markieren nicht Qualitätsverluste, sondern Konstellationen, in denen hohe Publikationsvolumina mit einer strukturellen Reorganisation der thematischen Landschaft einhergehen. Die starke negative Abweichung 2024 ($\Delta SC_n < -0{,}8$) verdeutlicht diese Drift besonders klar: Die semantische Dichte kann mit dem Wachstum des Feldes nicht im gleichen Maße Schritt halten. Methodisch weist dies auf Übergangszonen hin, in denen bestehende Clusterzentren an Stabilität verlieren und neue semantische Schwerpunkte entstehen.

Als Sensitivitätsmaß ergänzt $\Delta SC_n$ den Silhouette-Score um eine volumengewichtete Perspektive und dient damit der retrospektiven Bewertung der Robustheit einzelner Jahrgänge. Die Kennwerte machen sichtbar, in welchen Phasen die Daten kohärent strukturiert sind und in welchen die semantische Landschaft in Bewegung gerät. Für die Literaturauswahl bedeutet dies, dass Jahre mit hohen negativen $\Delta SC_n$-Werten keinesfalls ausgeschlossen, sondern kontextsensitiv interpretiert werden müssen: Sie geben Hinweise auf thematische Umbrüche, nicht auf Instabilität des Verfahrens.

### 4.2.2 Systematisches Literaturmanagement {#sec:Systematisches-Literaturmanagement}

Zur Vorbereitung der Datenanalyse wurden in Zotero 12 priorisierte Suchordner (0 bis b) angelegt. Jeder Ordner enthält eine Kombination aus Eintragstyp und Schlagwortkette. Die Titel wurden in der festgelegten Reihenfolge geprüft und beim ersten Treffer mit dem entsprechenden Tag versehen. Die folgende Tabelle zeigt die vollständige Struktur der Suchordner:

Anhang X: Struktur der Suchordner in Zotero nach semantischen Ebenen

Die folgende Tabelle dokumentiert die finale Systematik der Zotero-Suchordner. Diese ist entlang primärer, sekundärer und tertiärer Suchbegriffe gegliedert. Jeder Ordner beinhaltet strukturierte Suchen nach Eintragstypen und thematischen Schlagwörtern. Die ID der Ordner (z. B. `S:01`) korrespondiert mit der Ordnerstruktur in Zotero und wurde zur Tag-Kodierung verwendet.

**Primäre Suchbegriffe**

Table: Übersicht Primäre Suchbegriffe \label{tab:primaere_suchbegriffe}

| **Ordner-ID** | **Begriff**                | **Synonyme / Varianten**                  |
| ------------- | -------------------------- | ----------------------------------------- |
| `S:01`        | Learning Management System | LMS, Lernmanagementsystem, Kursplattform  |
| `S:02`        | Online-Lernplattform       | Lernplattform, Digitale Plattform         |
| `S:03`        | Online-Lernumgebung        | Virtuelle Lernumgebung, Digitale Umgebung |
| `S:05`        | E-Learning                 | Elektronisches Lernen, Digitales Lernen   |

Die primären Suchbegriffe adressieren den unmittelbaren Forschungsgegenstand. Sie bündeln alle Kombinationen, in denen das LMS oder der digitale Bildungsraum direkt benannt ist. Für diese Cluster gilt eine hohe Sichtungsquote (mindestens 80 %), weil sie die Kernbefunde zur Wirkweise des eingesetzten Systems liefern und den Ausgangspunkt für die Ableitung der Forschungsunterfragen bilden.

**Sekundäre Suchbegriffe**

Table: Übersicht Sekundäre Suchbegriffe \label{tab:sekundaere_suchbegriffe}

| **Ordner-ID** | **Begriff**         | **Synonyme / Varianten**                             |
| ------------- | ------------------- | ---------------------------------------------------- |
| `S:04`        | MOOC                | Massive Open Online Course                           |
| `S:06`        | Bildungstechnologie | EdTech, Technologie im Bildungssektor                |
| `S:07`        | Digitale Medien     | Medienkompetenz, Medientechnologie                   |
| `S:08`        | Blended Learning    | Integriertes Lernen, Hybridunterricht                |
| `S:09`        | Digitales Lernen    | Digital Learning (dt.), technologiegestütztes Lernen |
| `S:12`        | Digital Learning    | Digitales Lernen (engl.), tech-enhanced learning     |

Sekundäre Begriffe erweitern den Blick auf didaktische und organisatorische Kontexte. Sie erfassen hybride Arrangements, mediale Settings und bildungstechnologische Konzepte, die das LMS funktional einbetten. Die Sichtungsquote liegt hier bei 50 %, weil diese Ebene vor allem der Kontextualisierung und der Identifikation flankierender Mechanismen dient.

**Tertiäre Suchbegriffe**

Table: Übersicht Tertiäre Suchbegriffe \label{tab:tertiäre_suchbegriffe}

| **Ordner-ID** | **Begriff**     | **Synonyme / Varianten**                |
| ------------- | --------------- | --------------------------------------- |
| `S:10`        | Online Lernen   | Lernen im Netz, Web-basiertes Lernen    |
| `S:11`        | Online Learning | Online-based education, remote learning |

Tertiäre Begriffe erschließen angrenzende Innovations- und Technologiefelder, die Impulse für zukünftige Erweiterungen liefern. Sie besitzen die niedrigste Sichtungsquote (15 %), werden jedoch zur Validierung neuer Trends genutzt und helfen, emergente Muster in der Literatur frühzeitig zu erkennen.

Die Bool’sche Logik der Suchordner folgt einem konsistenten Ablauf, der von der Auswahl eines Begriffs (primär, sekundär, tertiär) über die Datenbankabfrage, die quotierte Sichtung der Trefferlisten und das Tagging in Zotero bis zur erneuten Suche oder der anschließenden Analyse reicht.

![Bool’sche Logik der Suchordner und Quotensteuerung.](08 Metaquellen/08-01 Abbildungen/methodik/Boolsche-Logik Suchordner.png){#fig:bool-logik width=85%}

Diese Abbildung verdeutlicht die Suchorderstrategie innerhalb des Literaturmanagementprogramms. Das zugehörige Zotero-Suchordner-Fenster dokumentiert eine beispielhafte Bool’sche Suchdefinition für Zeitschriftenartikel im Schnittfeld von learning, management und system, ergänzt um die deutschsprachige Variante „Lernmanagementsystem“ und flankiert von negativen Tags (z.B. `Promotion:Ausschluss`, `#2–#b`) sowie dem Ausschluss übergeordneter Sammlungen (z.B. `S:01`). Damit werden nur begutachtete Fachbeiträge selektiert, die thematisch zum Kernfeld gehören, während redundante oder bereits als irrelevant bewertete Einträge ausgenommen bleiben. Methodisch verortet sich diese Definition in der qualitativ-kriterialen Dokumentenselektion nach @doring_forschungsmethoden_2023, Kapitel 10.6 und konkretisiert das dreistufige Suchmodell aus primären, sekundären und tertiären Begriffen: transparent, replizierbar und über die Tag-Struktur skalierbar.

#todo Suchordnerstrategie weiter ausführen und anpassen

### 4.2.3 Visualisierungen der Literaturbasis {#sec:Visualisierungen-Literaturbasis}

Zur Orientierung innerhalb der Auswertungsschritte strukturiert dieser Abschnitt die Visualisierungen entlang eines konsistenten analytischen Aufbaus. Die Abbildungen bilden die visuelle Grundlage der in Abschnitt \hyperref[sec:Datenanalyse]{4.3} beschriebenen Datenanalyse und ordnen den Quellenkorpus systematisch entlang zentraler Dimensionen: Überblick, Korpusstruktur, FU‑Mapping und Relevanz, Qualitäts- und Statusinformationen, Autor:innenverteilung, Sprachmuster sowie Pfad‑/Sankey‑ und Netzwerksichten. Sie dienen damit der transparenten Rekonstruktion der Datenbasis und der Vorbereitung der späteren Cluster- und Korrelationsanalysen.

Inhaltlich gehören in diesen Abschnitt alle Visualisierungen, die die Relevanz, Struktur und thematische Zuordnung des Korpus abbilden (z. B. Kategorien-, FU‑ und Suchbegriffzuordnungen) sowie Sprach‑ und Kategoriedistributionen. Nicht enthalten sind reine Fortschrittsübersichten der Suchordner; diese gehören als Arbeitsdokumentation in den Anhang.

Aufbau der Visualisierungen:

- Überblick: Gesamtplot mit Kernkennzahlen (Relevanz, Sprachen, Typen).
- Korpusstruktur: Verteilungen der Kategorien und Indizes.
- FU‑Mapping/Relevanz: Zuordnung zu Forschungsunterfragen sowie Relevanz je FU, Kategorie und Suchbegriff.
- Qualität/Status/Autoren: Status der Quellen und Verteilung der Top‑Autor:innen.
- Sprachen: Gesamtverteilung und Differenzierung nach Dokumententypen.
- Flüsse/Netze: Pfaddiagramm, Suchbegriff‑Sankey‑Darstellung und das semantische Netzwerk.

![Gesamtüberblick der Suchergebnisse mit verdichteten Kenngrößen zu Relevanz, Sprachen, Quellenarten und Tags.](08 Metaquellen/08-01 Abbildungen/methodik/summary-plot-02-01-suchergebnisse.png){#fig:summary-suchergebnisse width=90%}

Der Überblick bündelt den Korpus ($\approx 3{,}5\text{k}$ Quellen): hohe Relevanzstufen dominieren, Deutsch/Englisch tragen den Hauptanteil, Artikel und Bücher sind die wichtigsten Dokumententypen. Damit ist die Datengrundlage formal solide, sprachlich fokussiert und nur gering durch Randsprachen oder Grauliteratur verzerrt.

![Verteilung der Kategorien innerhalb des Quellenkorpus.](08 Metaquellen/08-01 Abbildungen/methodik/visualize_categories_02-01_suchergebnisse.png){#fig:categories-suchergebnisse width=90%}

Die Textsortenzuordnung der analysierten Quellen (n = 1 109, Stand: 13.12.2025) zeigt eine deutliche Konzentration auf „Kerngedanke“ und „Argumentation“ (vgl. Abb.~\ref{fig:categories-suchergebnisse}). Weiterführungen und Schlussfolgerungen sind deutlich seltener vertreten. Das Korpus stützt sich damit primär auf zentrale Thesen und Begründungslinien, während synthese- und transferorientierte Passagen unterrepräsentiert sind. Für die spätere Synthese bedeutet dies, dass Schlussfolgerungen gezielt ergänzt und verdichtet werden müssen, um die breit dokumentierte Argumentationsbasis konsistent zu bündeln.

### 4.2.4 Webcam-basiertes Eye-Tracking und KI-gestützte Codierung {#sec:EyeTracking}

Das Eye-Tracking wurde webbasiert mit RealEye\label{term:realeye} durchgeführt [@lewandowska_realeye_2020]. Die Wahl fiel aus Kostengründen auf ein Webcam-System, dessen Präzision (ca. 110 px) für AOI-Ebene\label{term:aoi} und Layoutanalyse hinreichend ist, jedoch keine millisekundengenaue Fixationsmetriken zulässt; aktuelle Vergleichsstudien stützen den AOI-Einsatz von Webcam-Tracking [@kaduk_webcam_2023; @wisiecka_comparison_2022]. Die Datenbasis umfasst aggregierte Visualisierungen (Heatmaps\label{term:heatmap}, Fog-Views\label{term:fog-view}, Scanpaths); Videorohdaten stehen nicht zur Verfügung. Damit wird das Verfahren ausdrücklich als explorativ-qualitative Methode deklariert, die Wahrnehmungs- und Orientierungsprozesse sichtbar macht, ohne inferenzstatistische Ansprüche zu erheben. Dieser Zugriff ist für FU4b angemessen, da großflächige Interface-Zonen (Navigation, Inhalt, Interaktion, Störflächen) im Fokus stehen.

Die Auswertung folgt einer visuellen AOI-Analyse: (1) Definition weniger, funktionaler AOIs pro Stimulus; (2) Beschreibung der Blickverteilung pro AOI (Hot/Cold-Spots, Reihenfolge, Schleifen im Scanpath); (3) Ableitung technisch-gestalterischer Mechanismen wie Salienz, Auffindbarkeit von Navigation oder Konkurrenz zwischen Dekoration und Funktion. Expertisegradienten werden durch den Vergleich der Jahrgänge sichtbar (breite Explorationsmuster bei Novices, ökonomische Fixationen im dritten Jahrgang). Die Ergebnisse werden mit Umfragedaten trianguliert, um subjektive Wahrnehmung (Struktur/Interaktion) gegen beobachtete Blickmuster zu spiegeln.

KI dient als Codierhilfe, nicht als Messinstrument: Heatmaps und Fog-Views wurden mit GPT sprachlich beschrieben (z. B. „drei stärkste Aufmerksamkeitszonen markieren“, „Blickpfad A vs. B vergleichen“). Die modellgestützte Beschreibung wird mit der menschlichen AOI-Analyse abgeglichen und in Kategorien („Navigation zuerst“, „Content zuerst“, „Ablenkungszone prominent“) überführt. Damit bleibt die interpretative Verantwortung beim Forschungsteam, während die KI für Konsistenz in der qualitativen Codierung sorgt. Die sequentielle Darstellung erfolgt in Viewmaps\label{term:viewmap}.

Limitationen: geringere räumliche Präzision als Laborsysteme; Sensitivität für Kopfhaltung und Licht; keine Berechnung klassischer Fixationsmetriken; geringe Stichprobe. Die gewählte Granularität und die triangulative Einbindung (Eye-Tracking × Umfrage × Theorie) sichern dennoch eine robuste, kontextangemessene Evidenzbasis. Die vollständigen Bildreihen (Heatmap/Viewmap/Fog-View je Stimulus und Jahrgang) sind in \hyperref[sec:A-7]{Anhang A-7} dokumentiert.

![Stichprobenverteilung der Eye-Tracking-Teilnehmenden nach Ausbildungsjahr mit 95 %-Konfidenzintervallen im Vergleich zur Grundgesamtheit.](08 Metaquellen/08-01 Abbildungen/eye-traking/eye_tracking_verteilung_konfidenz.png){#fig:eyetracking-verteilung width=90%}

Die Stichprobenverteilung (vgl. Abb.~\ref{fig:eyetracking-verteilung}) zeigt, dass in jedem Ausbildungsjahrgang acht Personen in die Eye-Tracking-Analyse einbezogen wurden ($n_\text{pro Jahrgang} = 8$) und damit jeweils ein Drittel der Kohorte im ersten Jahr (N = 24) sowie einen substantiellen Anteil in den kleineren Jahrgängen (zweites Jahr N = 11, drittes Jahr N = 10) abbilden. Die 95 %-Konfidenzintervalle verdeutlichen die erwarteten Unsicherheiten bei kleinen Grundgesamtheiten, bestätigen aber zugleich, dass die Stichprobe im Rahmen der vorhandenen Kohortengrößen breit gestreut ist. Für die qualitativen, bildbasierten Analysen genügt diese Verteilung, um typische Muster pro Jahrgang sichtbar zu machen, ohne einen Anspruch auf inferenzstatistische Repräsentativität zu erheben.

![Kumulative Zahl der potenziell generierten Eye-Tracking-Bilder (Heatmaps, Viewmaps, Fog-Views und Recording-Screenshots) über Stimuli, Jahrgänge und Visualisierungstypen.](08 Metaquellen/08-01 Abbildungen/eye-traking/eye_tracking_bildanzahl.png){#fig:eyetracking-bildanzahl width=90%}

Die kumulative Bildanzahl (Abb.~\ref{fig:eyetracking-bildanzahl}) illustriert den Umfang der generierten Visualisierungen: Pro Jahrgang entstehen aus den elf Stimuli und drei Visualisierungstypen (Heatmap, Viewmap, Fog-View) bereits mehrere Hundert potenzielle Bilder; hochgerechnet auf alle Jahrgänge ergibt sich ein vierstelliger Bildkorpus. Vor diesem Hintergrund wird die Entscheidung für eine selektive, qualitativ-interpretative Auswertung nachvollziehbar: Statt alle Visualisierungen metrisch auszuwerten, werden zentrale Stimuli und Jahrgänge exemplarisch vertieft analysiert und mit den Umfragebefunden trianguliert. Die Kosten-Nutzen-Abwägung fällt damit zugunsten eines theoriegeleiteten, fokussierten Vorgehens aus, das die bildbasierte Stärke des Materials nutzt, ohne in eine unbegründete Quantifizierung zu kippen.

Die Textsortenzuordnung der analysierten Quellen (n = 1 109, Stand: 13.12.2025) zeigt eine deutliche Konzentration auf „Kerngedanke“ (457) und „Argumentation“ (454). Weiterführungen (160) und Schlussfolgerungen (38) sind deutlich seltener. Das Korpus stützt sich damit primär auf zentrale Thesen und Begründungslinien, während synthese- und transferorientierte Passagen unterrepräsentiert sind. Für die spätere Synthese bedeutet das, dass Schlussfolgerungen gezielt ergänzt werden müssen, um die breite Argumentationsbasis konsistent zu bündeln.

![Verteilung zentraler Indizes im Quellenkorpus.](08 Metaquellen/08-01 Abbildungen/methodik/visualize_index_02-01_suchergebnisse.png){#fig:index-suchergebnisse width=90%}

Die Indexverteilung (n = 4 102, Stand: 13.12.2025) fokussiert klar auf „Technologieintegration“ (945) und „Lehr- und Lerneffektivität“ (918). „Forschungsansätze“ (491) und „Systemanpassung“ (487) bilden den methodischen Unterbau. Bewertungsmethoden (291) und Bildungstheorien (277) liefern die theoretische Rahmung, während kollaboratives Lernen (274), Krisenreaktion (157), Lernsystemarchitektur (155) sowie Datenschutz/IT-Sicherheit (107) nachgelagert sind. Die Verteilung zeigt einen starken Wirkungs- und Implementierungsfokus; Governance- und Sicherheitsaspekte bleiben randständig und sollten in der Diskussion gezielt gewichtet werden.

#todo Kurzabschnitt zur Entstehung, theoretischen Fundierung und möglichen Blindstellen des Schlagwort- und Indexsystems (z.B. Technologieintegration, Bildungstheorien, Lehr-/Lerneffektivität) ergänzen und explizit im Theorieteil sowie in 4.3 verankern.

![Tag-Struktur der verarbeiteten Quellen.](08 Metaquellen/08-01 Abbildungen/methodik/visualize_tags_02-01_suchergebnisse.png){#fig:tags-suchergebnisse width=90%}

Die Tag-Verteilung konzentriert sich auf wenige Kernbegriffe (LMS, digital learning, blended learning) mit langen, dünnen Rändern. Das bestätigt die enge Such- und Tagging-Strategie: zentrale Tags erschließen den Großteil des Korpus, Spezialtags decken nur kleine Segmente ab.

![Zuordnung der Quellen zu den Forschungsunterfragen.](08 Metaquellen/08-01 Abbildungen/methodik/visualize_research_questions_02-01_suchergebnisse.png){#fig:research-questions-suchergebnisse width=90%}

Schwerpunkte liegen bei FU4a (bildungswissenschaftliche Mechanismen), FU3 (Konzeption/Merkmale) und FU5 (Möglichkeiten/Grenzen). FU1, FU2b und FU7 sind deutlich dünner besetzt. Damit stützen die dichtesten Segmente die Kernmechanismen, während Akzeptanz- und Lehrenden-Perspektiven gezielt ergänzt werden sollten.

![Relevanzverteilung je Forschungsunterfrage.](08 Metaquellen/08-01 Abbildungen/methodik/visualize_relevance_fu_02-01_suchergebnisse.png){#fig:relevance-fu width=90%}

Die gestapelten Balken zeigen, dass hohe Relevanzstufen (4/5) den Großteil der Nennungen für FU4a, FU3 und FU5 ausmachen; niedrige Stufen (2/3) sind randständig. Das unterstreicht die solide Basis der Kernfragen und markiert zugleich Ergänzungsbedarf bei schmal besetzten FUs.

![Relevanzverteilung je Kategorie.](08 Metaquellen/08-01 Abbildungen/methodik/visualize_relevance_categories_02-01_suchergebnisse.png){#fig:relevance-categories width=90%}

Kerngedanke und Argumentation tragen die meisten hochrelevanten Nennungen; Weiterführung und Schlussfolgerung sind dünner und enthalten teils niedrigere Stufen. Schlussfolgerungen sollten daher gezielt verdichtet werden, um die starke Argumentationsbasis sauber abzuschließen.

![Relevanzverteilung je Suchbegriff.](08 Metaquellen/08-01 Abbildungen/methodik/visualize_relevance_search_terms_02-01_suchergebnisse.png){#fig:relevance-search width=90%}

„Digital learning“ und „learning management system“ liefern die meisten hochrelevanten Treffer; „blended learning“ und „digital media“ folgen. Periphere Begriffe (online learning/lernen) steuern nur wenige Quellen bei. Die Kernbegriffe erschließen damit den relevanten Korpus, Randbegriffe dienen als Ergänzung.

![Statusübersicht der Quellen (z. B. akzeptiert, ausgeschlossen, in Prüfung).](08 Metaquellen/08-01 Abbildungen/methodik/visualize_sources_status_02-01_suchergebnisse.png){#fig:sources-status width=90%}

Die Statusübersicht zeigt, dass der Großteil der Quellen nach Screening, Qualitäts- und Relevanzprüfung übernommen wurde; nur ein kleiner Anteil ist ausgeschlossen oder in Prüfung. Die Arbeitsbasis ist damit weitgehend gesichert.

![Top-Autor*innen nach Häufigkeit im Korpus.](08 Metaquellen/08-01 Abbildungen/methodik/visualize_top_authors_02-01_suchergebnisse.png){#fig:top-authors width=90%}

Die Top-25-Autor*innen liegen dicht beieinander (ca. 7–13 Werke; Spitze Kerres, Ebner, Tudor, Iken-Allen). Kein Name dominiert, der Diskurs ist breit und multiperspektivisch.

![Sprachenverteilung der Quellen.](08 Metaquellen/08-01 Abbildungen/methodik/visualize_languages_02-01_suchergebnisse.png){#fig:languages width=90%}

Die Sprachverteilung (n = 3 533, Stand: 13.12.2025) ist zweipolig: Deutsch dominiert mit de-DE (2 326) und de-A (5), gefolgt von Englisch (en-GB 1 191; en-US 6). Einzelne Beiträge stammen aus indonesischen (id-id 3), malaysischen (ms-my 1) und spanischen (es 1) Quellen. Damit prägen deutsch- und englischsprachige Texte den Diskurs; Beiträge anderer Sprachen sind marginal und vor allem als Kontext- oder Fallstudienimpulse zu interpretieren.

![Sprachenverteilung nach Dokumententyp.](08 Metaquellen/08-01 Abbildungen/methodik/visualize_language_entrytypes_02-01_suchergebnisse.png){#fig:language-entrytypes width=90%}

Die Verteilung nach Dokumententyp pro Sprache (n = 3 533) unterstreicht die Quellenbasis: Deutsch (de-DE) vereint die meisten artikel- und buchbasierten Einträge (insgesamt 1 571) plus kleinere Anteile grauer Literatur; Englisch (en-GB) folgt mit 845 artikelbasierten und 299 buchbasierten Quellen sowie wenig grauer Literatur. Andere Sprachen treten nur in sehr kleinen, artikelbasierten Kontingenten auf. Damit liegen die Hauptbefunde auf begutachteten Artikeln in Deutsch und Englisch, während Buchanteile vor allem den deutschsprachigen Teil theoretisch vertiefen.

Im nächsten Schritt wird der kodierte Korpus nicht mehr auf Einzelquellenebene, sondern als Gesamtsystem betrachtet. Die folgende Abbildung bündelt die wichtigsten Datenströme und dient als Orientierungsfolie für die Interpretation der später berichteten Cluster- und Korrelationsanalysen; für die laufende Argumentation sind vor allem die Hauptpfade und ihre Abzweigungen relevant.

![Pfaddiagramm der Datenflüsse und Kategorien im Quellenkorpus.](08 Metaquellen/08-01 Abbildungen/methodik/create_path_diagram_02-01_suchergebnisse.png){#fig:path-diagram width=90%}

Das Pfaddiagramm zeigt die Hauptströme von FU3/FU4a in Kerngedanke/Argumentation und weiter zu Technologieintegration sowie Lehr-/Lerneffektivität, dominiert von Artikeln. Randströme (z.B. Datenschutz, Krisenreaktion) bleiben schmal und markieren Ergänzungsfelder; für die folgende Auswertung ist insbesondere die Verdichtung entlang Technologieintegration und Lehr-/Lerneffektivität relevant.

Die anschließende Netzwerkdarstellung fokussiert auf die Suchbegriffe und ihre Verknüpfung mit Tags und Kategorien. Sie macht weniger die zeitliche Abfolge als die semantischen Nachbarschaften sichtbar.

![Netzwerkdarstellung der Beziehungen zwischen Suchbegriffen, Tags und Kategorien.](08 Metaquellen/08-01 Abbildungen/methodik/visualize_network_02-01_suchergebnisse.png){#fig:network-suchergebnisse width=90%}

Das Suchbegriffsnetz spannt eine technologische und eine pädagogische Achse auf. Primärbegriffe wie „learning:management:system“, „digital:learning“ und „digital:lernen“ liegen zentral und verbinden technische mit didaktischen Dimensionen. Sekundärbegriffe (z.B. „mooc“, „blended:learning“, „digital:medien“) verdichten den pädagogischen Pol und zeigen Anschluss an Formate und Inhalte. Tertiärbegriffe („online:lernen“, „online:learning“) sind randständig und öffnen den Suchraum, ohne die Kernstruktur zu verschieben. Die Knotengröße spiegelt die Suchgewichtung, die Kanten die semantische Nähe. Insgesamt bestätigt das Netz eine doppelte Zentrierung: technologiegetriebene Kernbegriffe halten den Raum zusammen, didaktische und periphere Online-Begriffe erweitern ihn kontrolliert. Eine hochauflösende Darstellung des Netzwerks sowie ergänzende strukturbezogene Visualisierungen (Sankey-Diagramm) finden sich im \hyperref[sec:A-4]{Korrelationsatlas (Anhang A-4)}.

\FloatBarrier

#### Eye-Tracking (RealEye): Design, Durchführung und Qualitätssicherung {#sec:EyeTracking-Design}

Die Entscheidung für ein webcam-basiertes Eye-Tracking mit RealEye folgt unmittelbar aus der Forschungsunterfrage FU4b, die die technisch‑gestalterischen Wirkmechanismen des LMS untersucht. Für diese Fragestellung sind primär großflächige Aufmerksamkeitszonen, visuelle Hierarchien, Blickpfade und Navigationseffekte relevant. Diese Parameter lassen sich mit webcam‑basierten Verfahren zuverlässig erfassen, ohne dass millimetergenaue Rohdaten oder hochfrequente Sakkadenanalysen erforderlich wären.

Aktuelle Validierungsstudien belegen, dass moderne webcam‑basierte Eye‑Tracking‑Systeme für AOI‑basierte Analysen, UI‑Evaluationen und explorative Aufmerksamkeitstests ausreichend präzise sind. @kaduk_webcam_2023 zeigen, dass die Genauigkeit moderner Webcam‑Tracker (ca. 1–1,5°) nahe an kommerzielle Laborgeräte heranreicht und fixationsorientierte Kernmetriken stabil reproduziert werden. @yang_webcam-based_2021 demonstrieren, dass auch WebGazer‑basierte Systeme bei reduzierten Samplingraten robuste Fixationsmuster erzeugen und verhaltenswissenschaftliche Laborbefunde zuverlässig replizieren. @wisiecka_comparison_2022 bestätigen für RealEye konsistente Ergebnisse bei Standardaufgaben wie Point‑Detection‑ und Visual‑Search‑Tasks. Die technische Dokumentation von @imotions_imotions_2023 unterstreicht ergänzend die Eignung webcam‑basierter Systeme für explorative Studien, Remote‑Settings und UI‑Analysen, bei denen relative Fixationsverteilungen über definierte AOIs im Fokus stehen.

Die Limitationen webcam‑basierter Verfahren – geringere räumliche Präzision, sensitivere Reaktion auf Kopfbewegungen, fehlende Pupillometrie und das Fehlen von Rohdatenexporten – sind für die Beantwortung von FU4b methodisch unproblematisch. Für FU4b steht die Rekonstruktion technisch‑gestalterischer Muster im Vordergrund: Blickanfangszonen, visuelle Orientierung, Pfadtypik, Hot‑ und Coldspots sowie systematisch ignorierte UI‑Zonen. Solche Muster sind gegenüber Samplingratenschwankungen robust. @rodziewicz-cybulska_measuring_2022 zeigen zudem, dass selbst komplexere Fixationsmaße unter geeigneten Bedingungen stabil erfasst werden können, was den Validitätsrahmen für standardisierte Blickbewegungsanalysen stützt.

Damit ist die qualitative, bildbasierte Auswertung der aggregierten Heatmaps, Viewmaps und Fog‑Views wissenschaftlich konsistent und methodisch angemessen. Die Visualisierungen erlauben eine systematische Identifikation visueller Hotspots, Navigationspfade und unbeachteter Bereiche. Wie in der einschlägigen UX‑ und Eye‑Tracking‑Forschung üblich, werden die Muster relativ interpretiert: als Verteilung über AOIs, nicht als absolute metrische Werte. Durch die Kopplung mit Umfragebefunden (FU1/FU2) sowie mit den deduktiv entwickelten Kategorien entsteht eine theoriegeleitete, triangulierte Sicht auf die Wirkmechanismen des LMS.

##### Ergänzende methodische Absicherung {#sec:EyeTracking-Absicherung}

**Reliabilitätssicherung im Solo-Design**

Auswertung erfolgt im vorliegenden Projekt als Einzelforschung. Reliabilität entsteht über Intra-Coder-Absicherung und konsequente Regelbindung über Stimulusserie. Grundlage bildet versioniertes Entscheidungs- und Zuordnungsraster für AOIs, Mechanismen und Kurzdiagnosen. Pilotphase dient Regelschärfung, danach Freeze mit Datum und Changelog. Driftkontrolle erfolgt über Referenzstimuli mit Wiederholungsauswertung in festen Abständen sowie zeitversetzte Wiederholungsauswertung von Stichprobenanteil. Abweichungen werden als Grenzfallmarker protokolliert und nur bei Regelrelevanz in Form präzisierter Zuordnungsregeln nachgeführt. Konfidenzmarkierung begrenzt Aussagekraft bei ambigen Mustern.
[@kuckartz_qualitative_2018; @mayring_qualitative_2022; @doring_forschungsmethoden_2023]

**Standardisierung und Qualitätsgates bei RealEye**

Webcam-basiertes Tracking unterliegt Geräteheterogenität, Licht, Kopfhaltung und Kalibrierstabilität. Standardisierung wird über dokumentierte Rahmenbedingungen und Qualitätsgates realisiert. Pro Session werden Kalibrierstatus, Trackloss, Artefakte und Ausreißer verpflichtend erfasst. Visualisierungen unter Mindestqualität verbleiben außerhalb Auswertung oder erhalten niedriges Konfidenzniveau. Interpretation verbleibt auf Ebene relativer Muster über AOIs und Funktionszonen. Zeitparameter, Fixationsmetriken und kausale Zuschreibungen liegen außerhalb Geltungsbereich.
[@lewandowska_realeye_2020; @wisiecka_comparison_2022; @kaduk_webcam_2023; @imotions_imotions_2023]

**Setup und Durchführung**

#todo: Flussdiagramm ergänzen

- Remote‑Studie mit Desktop/Laptop und Frontkamera.  
- 9‑Punkt‑Kalibrierung; RealEye‑Validierung unmittelbar vor dem Stimulus.  
- Ausschluss von Sessions mit Warn‑ oder Fehlstatus.  
- Standardisierte Sitzposition, Lichtbedingungen und Displayabstände.  
- Stimulus: statische LMS‑Ansichten; identische Auflösung und AOI‑Koordinaten.
- Sequenzprotokoll: Kalibrierung/Validierung -> Stimulusfolge (F2‑S2, F3‑S3, F10‑S3, F11‑S3, F14‑S3; feste Anzeigezeit von ca. 8–12 s je Stimulus) -> Export der Visualisierungen; kein Reload, Einzel‑Durchlauf pro Person.
- Stichprobe: 24 vollständige Eye‑Tracking‑Datensätze (je 8 Teilnehmende aus dem 1., 2. und 3. Ausbildungsjahr; Grundgesamtheit N\textsubscript{1. Jahr} = 24, N\textsubscript{2. Jahr} = 11, N\textsubscript{3. Jahr} = 10).

**Metriken und Verarbeitung**

#todo: Fließtextüberführung ergänzen

- Export ausschließlich als Heatmap, Viewmap und Fog‑View (keine CSV/Rohdaten).  
- AOI‑Ebene: visuelle Interpretation aggregierter Muster (Hotspots, Pfade, Coldspots).  
- Keine absoluten Fixationskennzahlen; relative Muster stehen im Mittelpunkt.  
- Ausschluss von Sessions mit Trackloss oder instabiler Kalibrierung.
- Technische Angaben: RealEye (Webcam‑Tracker im Browser, Desktop/Laptop); Export als PNG/JPG, keine CSV‑Rohdaten oder AOI‑Metriken verfügbar.
- Nicht genutzte Metriken: keine Pupillometrie, keine millisekundengenaue Sakkadenanalyse, keine Time‑to‑First‑Fixation/TTFF, kein Fixation Count/Dwell‑Time pro AOI (nicht geliefert); ausschließlich Fixationsaggregation aus den Visualisierungen.
- RealEye-Hinweise: Heatmap-Farben kodieren Intensität, nicht Dauer; Viewmap/Fog‑View zeigen Verteilung ohne nummerierte Reihenfolge; central fixation bias (erste ~0,5 s) bei Bedarf ausblenden; Zeitfenster verschieben/verkürzen bei Sequenzfragen; Filter (Qualität/Tags/AOI) nur zur visuellen Sichtung, keine CSV-Downloads.

**Visualisierungstypen und Funktionen**

#todo: Fließtextüberführung ergänzen

- Heatmap: Kernel‑Dichte‑basierte Fixationsdichtekarte; zeigt Hotspots/Coldspots und relative Aufmerksamkeitsverteilung.
- Viewmap/Gaze‑Plot: Sequenzielle Darstellung von Fixationen (Kreise proportional zur Fixationsdauer) und Pfaden; macht Pfadtypik, Orientierungswechsel und Rekursionen sichtbar.
- Fog‑View: Invertierte Fixationsdarstellung; markiert systematisch ignorierte UI‑Zonen (Nebel über nicht fixierten Bereichen).

Table: Stimulusauswahl \label{tab:stimulus-auswahl}

| Stimulus | Inhalt (kurz)            | FU (primär)  | Fokus (kurz)                 |
| :------: | :----------------------- | :----------: | :--------------------------- |
|  F2‑S2   | Navigation, Interaktion  |   FU4b/FU3   | Salienz Navigation           |
|  F3‑S3   | Aufgabenbereich          |   FU4b/FU1   | Info-Hierarchie/Blickführung |
|  F10‑S3  | Lernplan, Kompetenzen    | FU4b/FU6/FU1 | Verständlichkeit             |
|  F11‑S3  | Weiterführende Quellen   |  FU4b/FU2a   | Auffindbarkeit/Link-Salienz  |
|  F14‑S3  | Lernmaterial, Sicherheit |   FU4b/FU6   | Salienz Sicherheit           |

(Kurzbeschreibung; Auswertung in Abschnitt \hyperref[sec:EyeTracking-Umfrage-Vergleich]{4.3.9})

Auswertungsvorgehen (FU‑geführt)

1. Verortung des Stimulus im LMS‑Kontext.  
2. Heatmap‑Analyse (Salienz, Aufmerksamkeitszentren).  
3. Viewmap‑Analyse (Pfadtypik, Orientierungswechsel).  
4. Fog‑View‑Analyse (ignorierte Zonen).  
5. Ableitung technisch‑gestalterischer Wirkmechanismen (Gestaltgesetze, Salienz, Navigierbarkeit).  
6. Verknüpfung mit FU4b sowie, je nach Stimulus, FU1/FU2a/FU3/FU4a/FU6.  
7. Formulierung einer kurzen, FU‑spezifischen Wirkungsdiagnose je Stimulus.

**Einschränkungen und Bias**

#todo: Flussdiagramm ergänzen

- Webcam‑Tracking liefert geringere Präzision als stationäre Systeme; Genauigkeit sinkt bei Bewegung oder suboptimalen Lichtverhältnissen.  
- Interpretationen basieren auf relativen Mustern, nicht auf punktgenauen Blickpositionen.  
- Fehlende Rohdaten limitieren inferenzstatistische Analysen; qualitative Befundung bleibt jedoch belastbar.  
- Ergebnisse sind indikativ, nicht repräsentativ; die Stichprobengröße wird transparent gemacht und in Abschnitt 4.3.9 mit Konfidenzintervallen ergänzt.
- KI‑gestützte Bildauswertung: Falls KI‑Modelle zur Bildbeschreibung genutzt werden, dienen sie ausschließlich als Assistenz (kein automatisiertes Urteil); Modell/Version wird dokumentiert (#todo), und alle Interpretationen werden manuell gegengeprüft (COPE/DFG‑konform).

### 4.2.5 Umfrage zum LMS: Instrument, Gewichtungen und Auswertung {#sec:Umfrage-LMS}

Die LMS-Umfrage erfasst subjektive Wahrnehmungen und Bewertungen der Nutzenden und flankiert die Eye-Tracking-Daten durch Selbstauskünfte zu Akzeptanz, Nutzen und Hemmnissen. Sie stützt primär FU1 (Akzeptanz und Nützlichkeit) sowie FU2a/FU2b.

Die Erhebung ist vollständig anonymisiert, freiwillig und unabhängig vom Eye-Tracking-Studienteil; Abbruch jederzeit ohne Angabe von Gründen. Laufzeit ca. 15 Minuten, Rekrutierung über das LMS-Umfeld. Instruktion und Einwilligung sind vorab bereitgestellt und verschriftlicht.

- **Struktur/Item-Gruppen:** Klarheit/Struktur der Informationen, Diskussion/Austausch, Kollaboration, Flexibilität, Ressourcenzugang, Integration externer Materialien, Lernfortschritt, Rolle multimedialer Inhalte, Anpassung/Personalisierung. Zuordnung und Gewichtungen sind vorab festgelegt (vor/nach Anpassung je Frage).
- **Gewichtung der Dimensionen:** Nach Vortest wurden zentrale Knoten des Wirkungsgefüges höher gewichtet: Klarheit/Struktur stieg auf $0{,}8$, Diskussion/Austausch auf $0{,}6$, Kollaboration auf $0{,}7$, Flexibilität auf $0{,}7$, Ressourcenzugang und Integration externer Materialien auf $0{,}6$. Lernfortschritt wurde auf $0{,}5$ festgesetzt, multimediale Inhalte auf $0{,}5$, Anpassung auf $0{,}6$ und Personalisierung auf $0{,}5$. Damit rücken Verständlichkeit, Interaktion und Kollaboration in den Fokus, ohne periphere Dimensionen auszublenden.

- **Ziel und Konstruktion:** Ableitung der Items aus den Forschungsunterfragen; Kombination aus Akzeptanz-, Nutzungs- und Wirkungsdimensionen; Pretest dokumentiert.
- **Instrument:** Strukturierter Fragebogen mit Informationsblatt und Einwilligung; abgestützte Gewichtungen der Dimensionen.
- **Stichprobe:** Rekrutierung über das LMS-Umfeld; Ein- und Ausschlusskriterien dokumentiert; Dropouts ausgewiesen.
- **Durchführung:** Online-Erhebung über das LMS; identische Instruktionen; pseudonymisierte IDs; technische Checks vor Freigabe.
- **Auswertung:** Deskriptive Kennzahlen pro Dimension, gewichtetes Gesamtmaß gemäß Synopse, Vergleich nach Subgruppen (z.B. Nutzungshäufigkeit, Rolle); fehlende Werte per Listewise/Pairwise je Analyse; Rückbindung an FU1/FU2 und Abgleich mit Eye-Tracking-Befunden.
- **Gütekriterien/Reflexion:** Reliabilität über interne Konsistenz geprüft; Validität über Experten-Review und Pretest; mögliche Bias (Selbstselektion, soziale Erwünschtheit) werden in der Diskussion transparent gemacht.

**Auswertungsvorgehen (Schema, FU‑geführt)**  
Analog zum Eye‑Tracking werden die Umfragedaten in einem einheitlichen, dokumentierten Schema ausgewertet und für die Triangulation vorbereitet:

1. **Datenbasis und Subgruppen:** Auswertung auf Basis der Online‑Exporttabelle (`08 Metaquellen/08-04 Daten/UmfrageOnline-Beantwortungen.csv`). Die Jahrgangszuordnung erfolgt über die Kurskennzeichnung (z.B. `21‑…`, `22‑…`, `23‑…`). Abbrüche/fehlende Werte werden itemweise transparent ausgewiesen (n je Jahrgang und je Item).
2. **Item‑Level statt Blackbox‑Index:** Primäre Auswertung pro Item (statt ausschließlich aggregierter Skalen), um FU‑Bezüge und konkrete Gestaltungsdimensionen nachvollziehbar zu halten.
3. **Deskriptive Kennzahlen pro Item:** Für Likert‑Items (1–5) werden je Jahrgang und Gesamtstichprobe `n`, Mittelwert, Standardabweichung, Median, IQR sowie Zustimmungs-/Ablehnungsanteile (>=4 / <=2) berichtet. Für binäre Items (Ja/Nein) wird der Ja‑Anteil ausgewiesen.
4. **Gewichtungslogik (Transparenz):** Die in der Synopse dokumentierten Vor-/Nach‑Gewichtungen dienen als nachvollziehbarer Übersetzungsschritt von Selbstauskünften in die weitere Modellierungs-/Verdichtungslogik (Zuordnung „Frage → Begriffspaar → Einfluss“).
5. **Freitext als qualitative Ergänzung:** Offene Antworten werden getrennt ausgewiesen und als Ausgangspunkt für eine knappe Kategorienbildung genutzt (Triangulation/Validierung, keine Überinterpretation bei geringer Fallzahl).
6. **Dokumentation/Artefaktspur:** Alle Item‑Auswertungen werden als reproduzierbare Arbeitsartefakte im identischen Berichtschema abgelegt (Index + Itemdateien; `03 Quellenanalyse/03-06 Umfrage/Analysen-Auswertungen/…`). Die verbindliche Vorlage ist in \hyperref[sec:A-10]{Anhang A‑10} dokumentiert; die Ergebnisse werden in Abschnitt \hyperref[sec:EyeTracking-Umfrage-Vergleich]{4.3.9} mit Eye‑Tracking‑Befunden kontrastiert.

Die Konstruktion des Instruments folgt dem Prinzip der Forschungsfragengeleitetheit. Jede Itemgruppe ist einem FU zugeordnet, was eine direkte Rückbindung der Ergebnisse ermöglicht. Die Gewichtungen sind vorab festgelegt, um Skalierungsentscheidungen nachvollziehbar zu machen und Sensitivitätsanalysen (mit/ohne Gewichtung) zu ermöglichen. Pretests und Experten-Review stellen sicher, dass die Items verständlich und inhaltlich valide sind.

Analytisch werden die Umfrageergebnisse mit den Eye-Tracking-Befunden verschränkt: Divergenzen zwischen berichteter Nützlichkeit und beobachteter Nutzung werden als Hinweis auf Interface- oder Erwartungsinkonsistenzen interpretiert, Kongruenzen stützen die Modellannahmen zur Wirksamkeit. Subgruppenanalysen (v.a. Jahrgänge sowie Teilnahme am Eye‑Tracking: Ja/Nein) liefern Kontext für differenzierte Handlungsempfehlungen.

## 4.3 Datenanalyse {#sec:Datenanalyse}

### 4.3.1 Grundlogik der Datenanalyse: Analysen erster bis dritter Ordnung {#sec:Datenanalyse-Grundlogik}

Die Datenanalyse folgt einem dreistufigen, systemisch gedachten Beobachtungsmodell, das deduktive Kategorienbildung mit probabilistischer Validierung systemisch ordnet. Damit bleibt jeder Schritt eng an die Forschungsunterfragen gekoppelt und gleichzeitig anschlussfähig an die dokumentarischen Qualitätsanforderungen nach Döring [-@doring_forschungsmethoden_2023].

- **Analysen erster Ordnung (Primäranalysen):** Einzelquellen werden entlang vordefinierter Kategorien (Akzeptanz, Nutzen, Grenzen usw.) ausgewertet. Das Ergebnis ist eine strukturierte, FU-spezifische Inhaltsanalyse pro Dokument.
- **Analysen zweiter Ordnung (Sekundäranalysen):** Die Primäranalysen einer FU werden gespiegelt, verdichtet und theoriebezogen gerankt. Daraus entstehen deduktive Cluster, SWOT-Profile und Korrelationsmatrizen.
- **Analysen dritter Ordnung (P-QIA):** Die probabilistisch-qualitative Inhaltsanalyse überführt die Ergebnisse der zweiten Ebene in einen Vektorraum, prüft sie über k-means-Clustering und bewertet die Kohärenz mittels Silhouette-Scores.

Gemeinsam bilden diese Ordnungen einen iterativen Zyklus. Jede Stufe liefert die Grundlage für die nächste und fließt nach erfolgter Validierung wieder in die Forschungsunterfragen zurück.

Systemtheoretisch folgt die Dreiteilung der Idee von Beobachtungen erster, zweiter und dritter Ordnung: Analysen erster Ordnung beobachten die Quellen direkt und beschreiben, was Akteure über Akzeptanz, Nutzen oder Grenzen des LMS aussagen; Analysen zweiter Ordnung beobachten diese Beobachtungen, identifizieren Muster und Metastrukturen auf FU-Ebene; Analysen dritter Ordnung beobachten schließlich die daraus entstehenden Strukturen im semantischen Raum und prüfen ihre Stabilität und Kohärenz [@luhmann_zwischen_1982; @arnold_rolf_luhmann_2015]. Damit wird das luhmannsche Beobachtungskonzept operativ auf die mehrstufige Literatur- und Datenanalyse übertragen und in eine reproduzierbare Pipeline überführt.

### 4.3.2 Primäranalysen: Analyse 1. Ordnung {#sec:Primaranalysen}

Die Primäranalysen bilden das Fundament der weiteren Verdichtungen. Jede wissenschaftliche Quelle wird mit einem dedizierten Prompt ausgewertet, der aus der jeweiligen Forschungsunterfrage abgeleitet ist (z.B. `FU5 Primäranalysen (125).md`; siehe Anhang A.2, Prompt zur Analyse einer Quelle, {#sec:A-2}). Die Prompts stellen sicher, dass alle Analysen identische Bausteine enthalten (Kontext, Argument, Limitationen, Implikationen).

1. **Quellenimport und Tagging:** Aus Zotero exportierte Einträge werden über ihre Tags den FUs zugeordnet.
2. **Promptbasierte Auswertung:** Ein KI-gestütztes Textanalysewerkzeug erzeugt strukturierte Markdown-Analysen, die deduktiv definierte Kategorien ausfüllen und mit Originalzitaten aus der Quelle verknüpfen.
3. **Dokumentation:** Jede Analyse erhält einen Header mit Metadaten (Quelle, Datum, Prompt-Version). Die Ergebnisse liegen versioniert in Obsidian vor und können jederzeit erneut validiert werden.
4. **Qualitätssicherung:** Quellen, die inhaltlich nicht in den digitalen Bildungsraum passen, werden bereits auf dieser Ebene identifiziert und als „irrelevant" markiert. So bleiben nur überprüfte Texte im weiteren Prozess.
5. **Zotero-Export inkl. Notizen:** Die Primäranalysen werden über einen laufend aktualisierten Export aus Zotero in das Literaturverzeichnis der Arbeit überführt und bilden so die maschinenlesbare Grundlage für die anschließenden Netzwerk-, Cluster- und Pfadanalysen.

Insgesamt wurden 786 Analysen erster Ordnung durchgeführt. Die Verteilung auf die Forschungsunterfragen zeigt einen deutlichen Schwerpunkt bei FU4a und FU5 (Didaktik, Mechanismen, Möglichkeiten/Grenzen), gefolgt von FU3 und den nutzungsbezogenen FU2a/FU4b. FU1 und FU6 liegen im mittleren einstelligen Prozentbereich, FU2b und FU7 bilden kleinere, aber inhaltlich zentrale Vertiefungsfelder. Abbildung \ref{fig:primaranalysen-verteilung} visualisiert diese Gewichtung.

```{=latex}
\input{08 Metaquellen/08-01 Abbildungen/statistik/primaranalysen-verteilung.tex}
```

Für die Analysen zweiter Ordnung wird je Forschungsunterfrage ein FU-spezifischer Korpus aus dem Literaturverzeichnis gebildet: Alle Einträge, die den FU-Tag (`Promotion:FUx`) tragen und eine Analyse 1. Ordnung im Feld `annote` enthalten, werden extrahiert und in einer FU-spezifischen Arbeitsdatei zusammengeführt, wobei der jeweilige BibTeX-Key als Referenzanker mitgeführt wird. Diese Arbeitsdateien dienen der Reproduzierbarkeit und Nachvollziehbarkeit der FU-Korpora, sind jedoch nicht Bestandteil des Anhangs. Die FU-Korpora bilden die direkte Eingabe der P‑QIA-Metaanalyse (vgl. \hyperref[sec:P-QIA]{Abschnitt 4.3.4} sowie \hyperref[sec:A-3]{Anhang A.3}) und sichern, dass Ankerbeispiele und Zuordnungen reproduzierbar auf konkrete Quellen zurückverweisen.

### 4.3.3 Sekundäranalysen: Analyse 2. Ordnung {#sec:Sekundaranalysen}

Die zweite Ordnung synthetisiert alle Primäranalysen einer Forschungsunterfrage. Die entsprechenden Prompts (z.B. `FU1 Prompt Sekundäranalyse.md`) führen mehrere Einzelanalysen zusammen, spiegeln sie an theoretischen Bezugsrahmen und erzeugen daraus erste Metastrukturen:

- **Operatives Vorgehen (FU‑weise):** Für jede FU wird zunächst ein FU‑Korpus aus den Analysen 1. Ordnung gebildet (vgl. \hyperref[sec:Primaranalysen]{Abschnitt 4.3.2}). Auf diesem Korpus wird die P‑QIA als Metaanalyse umgesetzt: (1) Segmentierung in Sinnabschnitte, (2) semantische Vektorisierung (Embeddings), (3) k‑means‑Clustering mit FU‑spezifischem $k$, (4) Qualitätsprüfung über Silhouette‑Kennwerte, (5) Kategorienbildung und Codierschema (Definitionen, Ankerbeispiele, Kodierregeln), (6) narrative Synthese sowie theoretische Einbettung und Reflexion. Der exemplarische Prompt und das reproduzierbare Vorgehen sind in \hyperref[sec:A-3]{Anhang A.3} dokumentiert; die FU‑spezifischen Ergebnisse werden im einheitlichen Schema in \hyperref[sec:A-9]{Anhang A.9} ausgewiesen und in Kapitel \hyperref[sec:Ergebnisse]{5} verdichtet.

- **Vergleich und Ranking:** Wiederkehrende Aussagen werden identifiziert, divergierende Befunde kontrastiert und entlang der FU priorisiert.
- **Theoriebasierte Spiegelung:** Konzepte wie TAM, SDT oder TPACK dienen als Referenz, um die Primäranalysen in bestehende Modelle einzubetten.
- **Manuelle Clusterlogik:** Vor der probabilistischen Verdichtung entstehen deduktive Cluster (z.B. „Akzeptanzmuster" oder „Risiko-Faktoren"), SWOT-Profile oder Korrelationsmatrizen.

Damit liefert die zweite Ordnung den semantischen Rahmen, in dem die probabilistische Verdichtung der dritten Ordnung operiert.

### 4.3.4 Probabilistisch-Qualitative Inhaltsanalyse (P-QIA): Analyse 3. Ordnung {#sec:P-QIA}
\label{term:p-qia}

Die P-QIA ergänzt die klassischen Methoden um eine reproduzierbare, embedding-basierte Strukturierung. Sie versteht sich als semantische Analyse im Sinne einer regelgeleiteten Erschließung, Verdichtung und relationalen Zuordnung bedeutungstragender Einheiten.

**Konzept und Abgrenzung**

- Deduktive Rahmung durch die Forschungsunterfragen (FU1–FU7).
- Segmentierung aller Texte in Sinnabschnitte (1–3 Sätze; bei FU7 1–2 Sätze).
- Transformation der Segmente in hochdimensionale Embeddings.
- k-means-Clustering und Gütebewertung via Silhouette-Koeffizient.
- KI-gestützte Label-Vorschläge, die durch die Forschende überprüft und theoretisch validiert werden.
- Ableitung konsistenter Kodiermanuale mitsamt Ankerbeispielen.

Die eingesetzten KI-basierten Textmodelle wirken als strukturierende Werkzeuge; Steuerung und Interpretation liegen vollständig bei der Forschenden.

**Algorithmische Umsetzung**

Der Workflow wurde in Anlehnung an Mayring gestaltet und verbindet klassische Schritte mit probabilistischen Erweiterungen:

1. **Forschungsunterfrage und Materialfestlegung (Mayring)** – Definition der FU und Auswahl des Materials (Primäranalysen, Notizen, Quellen).
2. **Festlegung der Analyseeinheiten (Mayring)** – Definition von Sinnabschnitten und Kontextebenen.
3. **Segmentierung (P-QIA)** – Automatische Zerlegung der Texte in 1–3 Sätze (bei FU7 1–2 Sätze) inklusive Dokumentation der Regeln.
4. **Embedding und probabilistische Strukturierung (P-QIA)** – vektorbasiert berechnete Textrepräsentationen und k-means-Clustering mit FU-spezifischem *k*.
5. **Qualitätssicherung der Cluster (P-QIA)** – Berechnung des Silhouette-Koeffizienten und Bereinigung instabiler Cluster.
6. **Ableitung und Revision der Kategorien (Mayring + P-QIA)** – KI-gestützte Label, theoretische Validierung, Kodiermanual.
7. **Kodierung des Materials (Mayring)** – Anwendung des Manuals, Dokumentation von Grenzfällen.
8. **Synthese, Metamodellierung und Theoriebildung (Mayring + P-QIA)** – Rückbindung an die FU und Dokumentation der Kennwerte.

```{=latex}
\input{08 Metaquellen/08-01 Abbildungen/prozesse/p-qia-flow.tex}
```

**Validierung und empirische Kennwerte**

Die Datei [[P-QIA Statistik]] dokumentiert Segmentierungsregeln, Embedding-Modelle, gewählte *k*-Werte und Silhouette-Mittelwerte für alle FUs. Über alle Forschungsunterfragen hinweg liegt *k* zwischen 8 und 15, die Silhouette-Werte bewegen sich zwischen 0.87 und 0.93 (Mittelwert ca. 0.89).

|FU|k|Silhouette|Interpretation nach @rousseeuw_silhouettes_1987|
|---|---|---|---|
|FU1|8|0.91|sehr starke Clustertrennung|
|FU2a|12|0.88|starke Clusterstruktur|
|FU2b|14|0.89|starke Clusterstruktur|
|FU3|15|0.87|starke Clusterstruktur|
|FU4a|12|0.90|sehr starke Clustertrennung|
|FU4b|12|0.92|nahezu perfekte Trennung|
|FU5|14|0.88|starke Clusterstruktur|
|FU6|12|0.89|starke Clusterstruktur|
|FU7|10|0.93|nahezu perfekte Trennung|

In Anlehnung an @rousseeuw_silhouettes_1987 lässt sich der mittlere Silhouette‑Wert als Maß für die **geometrische Trennschärfe** einer Clusterlösung lesen: Werte nahe 1 deuten darauf hin, dass Segmente im Embedding‑Raum im Mittel deutlich näher an ihrem eigenen Cluster liegen als am nächstgelegenen Alternativ‑Cluster. Als pragmatische **Faustregel** werden Werte über 0,70 häufig als „stark“ und Werte über 0,90 als „sehr stark“ interpretiert; in diesem Sinne zeigen die Kennwerte für die Analysen 2. Ordnung eine durchgängig hohe Separierbarkeit der FU‑spezifischen Cluster.

Wichtig ist die methodische Einordnung der Aussagekraft: Der Silhouette‑Wert validiert **nicht** die inhaltliche „Richtigkeit“ der Kategorien, sondern ausschließlich die Separierbarkeit der Segmente im verwendeten Repräsentationsraum. Sehr hohe Werte können zudem durch homogene Textbausteine oder stark formatierte/standardisierte Notizen begünstigt werden. Deshalb wird die Silhouette‑Prüfung hier als **Qualitätssicherungs‑ und Plausibilitätsindikator** eingesetzt und konsequent mit inhaltlicher Validierung (Codierschema, Ankerbeispiele, theoretische Einbettung) trianguliert. Ergänzend verweisen @low_data_2023 auf die Reproduzierbarkeit deterministischer Pipelines.

**Qualitätssicherung und Beispiele**

Die KI-gestützte Analyse dient auch der Plausibilitätsprüfung. So wurde der Artikel von @westlake_international_2023 – trotz korrekter Schlagwortzuordnung – als thematisch irrelevant markiert, weil er BDSM-Praktiken untersucht und somit keinen Bezug zum digitalen Bildungsraum aufweist. Diese Prüfung geht über eine reine Stichwortsuche hinaus und verhindert, dass fachfremde Texte in die Auswertung gelangen.

Zur Überprüfung der Trennschärfe wurde die P-QIA auf die klassisch kodierte Studie von @kerman_online_2024 angewendet. Die KI-gestützte Analyse erzielte einen Silhouette-Score von 0,92, die menschliche Kodierung lediglich 0,62. Damit wird sichtbar, dass die probabilistische Validierung methodische Schwächen in manuellen Kodierungen offenlegt und als Ergänzung zur klassischen Inhaltsanalyse fungiert.

**Test- und Diskursbeiträge**

Die Validierung umfasst automatische Kodierungstests, erneute Clusterbildungen mit $k$-means sowie Mehrfachberechnungen des Silhouette-Scores, um die Stabilität über verschiedene Läufe hinweg zu belegen. Zudem wurde geprüft, ob klassische Tools wie ATLAS.ti oder NVivo die gleichen Prüfungen leisten können. Da diese Werkzeuge primär der Unterstützung menschlicher Kodierung dienen, liefern sie keine belastbaren Kennwerte zur objektiven Clustervalidierung. Die P-QIA adressiert damit eine Lücke in der aktuellen Diskussion (z.B. [@biswas_chatgpt_2023; @van_niekerk_addressing_2025; @storey_ai_2023; @parker_negotiating_2024]), indem sie ein überprüfbares Verfahren zur Qualitätsbewertung KI-gestützter Analysen bereitstellt.

**Rolle des Menschen und Grenzen**

Trotz der probabilistischen Komponente bleibt die interpretative Verantwortung grundsätzlich menschlich. Grenzen ergeben sich aus:

- **Parameter- und Modellvariabilität:** Embedding-Modelle und Clusterparameter beeinflussen die Ergebnisse; Entscheidungen müssen dokumentiert und begründet werden.
- **Black-Box-Charakter der Modelle:** Interne Repräsentationen sind nur begrenzt interpretierbar. Transparente Protokolle mildern, aber eliminieren das Problem nicht.
- **Gefahr der Scheinobjektivität:** Statistische Kennwerte ersetzen keine inhaltliche Reflexion. Sie fungieren als Unterstützungs-, nicht als Entscheidungsinstanz.
- **Ethik und Bias:** Fragen nach Datensouveränität, Verzerrungen und Verantwortung müssen explizit adressiert werden.

### 4.3.5 Mehrdimensional-analytische Clustervalidierung (mdaCV) {#sec:mdaCV}

\label{term:mdacv}

Im Zuge der systematischen Literaturarbeit wurde die statistische Clusteranalyse zunächst als Ergänzung zur P-QIA ausprobiert. Die Anwendung des $k$-Means-Algorithmus auf einen bereits deduktiv strukturierten Quellenkorpus bestätigte die bestehenden semantischen Erkenntnisse. Diese Stabilität wurde zur Grundlage eines eigenständigen Validierungsverfahrens, der mehrdimensional-analytischen Clustervalidierung (mdaCV). Sie spannt einen semantischen Raum entlang theoretisch begründeter Achsen (Kategorien, Forschungsfragen, Schlagworte) auf, positioniert die Datenpunkte darin und bewertet deren Trennschärfe über Silhouette-Scores [-@rousseeuw_silhouettes_1987].

Die Methode wird mit zwei modularen Skripten umgesetzt: `analyse_netzwerk.py` erzeugt das semantische Netz samt multidimensionaler Visualisierungen; `analyse_korrelation.py` führt die deduktive k-means-Clusterung und bivariate Korrelationen aus. Beide Module sind versioniert publiziert [@hanisch-johannsen_systematische_2025; @hanisch-johannsen_systematische_2025-1] und im Repository https://github.com/jochen-hanisch/charite-promotion dokumentiert. Ihre theoretische Herleitung fußt auf drei Komponenten:

1. **Deduktive Strukturierung des semantischen Raums:** Theoriegeleitete Dimensionen ([@baur_datenaufbereitung_2022; @baur_qualitative_2022]) definieren die Achsen und ermöglichen eine geordnete Positionierung der Daten.
2. **Geometrische Modellierung:** Begriffliche Relationen werden in numerische Vektoren überführt. Konzepte wie CBOW/Skip-gram [@mikolov_efficient_2013] zeigen, dass sich so hochdimensionale, semantisch präzise Repräsentationen erzeugen lassen.
3. **Statistische Validierung:** Die vorstrukturierten Daten werden mittels $k$-Means analysiert. Die Anzahl der Cluster $k$ wird theoriegeleitet festgelegt oder durch Silhouette-Kennwerte feinjustiert [@sud_k-means_2020; @rakhlin_stability_nodate].

Die Pipeline (analyse_netzwerk/analyse_korrelation) überführt die Dimensionen (Forschungsfragen, Kategorien, Suchbegriffe) in Vektoren, berechnet k-means mit Random Starts und liefert Silhouette-Scores sowie Korrelationsmatrizen; dieselben Parameter ($k = 4$, Euklidische Distanz, Lloyd-Iteration) liegen den Visualisierungen in Abschnitt \ref{sec:Korrelations-Cluster}, zugrunde.

Im Verlauf der Dissertation wurde die mdaCV als dauerhafte Feedback-Schleife eingesetzt. Beispielhaft stieg nach der Bereinigung eines Korpus auf $n = 3502$ Quellen der Silhouette-Score von $0,964$ auf $0,9751$, was als Hinweis auf semantische Schärfung bewertet werden kann. Ein ergänzender methodischer Hinweis betrifft die Interpretation der ab 2023 sichtbar werdenden semantischen Drift im Literaturkorpus. Die Kombination aus steigenden Publikationszahlen bei gleichzeitig sinkenden Silhouette-Scores weist auf eine strukturelle Reorganisation der thematischen Landschaft hin. Dieses Muster ist in datenintensiven Diskursfeldern nicht ungewöhnlich und gilt als typischer Indikator dafür, dass sich die Begriffs- und Themenräume eines Forschungsfeldes verändern, ohne dass dies zwingend mit einer qualitativen Abwertung einhergeht. Vielmehr entstehen in solchen Phasen neue semantische Ankerpunkte, die die bisherigen Strukturzentren überlagern oder ergänzen.

Für die methodische Einordnung signalisiert der Rückgang der Clusterkohärenz verschobene epistemische Schwerpunkte, keine Schwäche der Datenbasis. In von technischer Innovation geprägten Feldern, etwa durch generative KI, die breitere Etablierung von Learning Analytics oder automatisierte Analyseverfahren, treten kurzfristige Fragmentierungen auf, die sich in den Kennwerten von mdaCV und Silhouette zeigen. Die Dynamik lässt sich als temporäre Reorganisation lesen: alte Strukturkerne verlieren an Stabilität, neue Cluster bilden sich aus. Methodisch folgt daraus, Übergänge als systemisch-epistemischen Beobachtungsgegenstand zu behandeln, statt sie als bloße Unschärfe abzutun. Die Drift verweist auf erhöhte Variabilität im Diskurs und macht sichtbar, dass sich die semantische Struktur des Feldes erweitert oder neu justiert. Eine interpretative Dimension ergänzt die empirische Bewertung der Clusterkohärenz und erlaubt eine präzisere Einordnung der Kennwerte. Nach erneuter Einbindung ausgeschlossener Konferenzbände ($n = 3572$) blieb der Score mit 0,9754 stabil. Selbst minimale Änderungen (ein entfernter Buchteil, $n = 3571$) führten zu messbaren Differenzen von 0,001 und machten mikrostrukturelle Effekte sichtbar.

Die mdaCV fungiert damit als seismografisches Instrument: Sie verbindet deduktive Kategorienstrukturen mit quantitativ validierbaren Kennwerten und eröffnet Analysepfade für mikrostrukturelle Dynamiken in semantisch strukturierten Räumen.

### 4.3.6 Epistemische Verlustfunktion ($\epsilon$) als Integritätsmaß {#sec:Epistemische-Verlustfunktion}

Allein der Silhouette-Score erfasst nur die geometrische Separierbarkeit von Clustern. Um zusätzlich die Datenvollständigkeit zu berücksichtigen, wurde eine epistemische Verlustfunktion $\epsilon$ eingeführt. Sie kombiniert die Clusterdifferenzierungsleistung mit dem Verhältnis aus intendierter und tatsächlich verarbeiteter Quellenzahl und fungiert als Monitoring-Größe für datenintensive Prozesse.

**Formel zur Definition der Verlustfunktion:**

$$
\epsilon = (1 - S) + \frac{n_{\text{Soll}} - n_{\text{Ist}}}{n_{\text{Soll}}}
$$ {#eq:verlust}

Ein Beispiel mit $S = 0{,}9754$, $n_{\text{Soll}} = 3585$ und $n_{\text{Ist}} = 3583$ ergibt $\epsilon \approx 0{,}0252$. Der Wert zeigt, dass trotz kleiner Datenlücken eine hohe Integrität erreicht wird. Die Verlustfunktion eignet sich insbesondere als Frühwarnsystem (Verlust von Quellen, unplausible Score-Sprünge) und als zusätzlicher Qualitätsindikator in reproduzierbaren Pipelines.

### 4.3.7 Synthese: Methodische Bedeutung für die Gesamtanalyse {#sec:Datenanalyse-Synthese}

#todo: ist das hier an der richtigen Stelle? Prüfen, $k$-meas n ggf. in 4.3.5 integrieren

Die strukturierte Abfolge aus Analysen erster bis dritter Ordnung, P-QIA, mdaCV und epistemischer Verlustfunktion verbindet deduktive Theorietreue mit datenbasierter Validierungslogik. Damit entsteht ein geschlossenes, aber transparentes System, das qualitative Tiefenanalyse, probabilistische Robustheit und kontinuierliche Selbstüberwachung vereint. Diese Methodik bereitet den Boden für die simulationsgestützten Modellierungen des folgenden Abschnitts.

**k-means-Verfahren (Kurzüberblick):** Für die Clusterbildung wird das klassische $k$-means genutzt (Euklidische Distanz, Lloyd-Iteration), mit $k$ aus Silhouette/Elbow und theoriegeleiteter Justierung sowie Initialisierung per mehrfachem Random Start zur Vermeidung lokaler Minima [@litzel_was_2018; @sud_k-means_2020]. Stabilität und Feature-Selektion werden über Wiederholungen/Stability-Checks reflektiert [@mavroeidis_novel_2011; @rakhlin_stability_nodate], die beschriebenen Limitationen (Sensitivität auf Ausreißer, sphärische Clusterannahme) werden berücksichtigt [@noauthor_drawbacks_2023; @noauthor_what_2024]. Die Zielfunktion lautet:

$$
\arg\min_{\{\mu_j\}, \{C_j\}} \sum_{j=1}^{k} \sum_{x_i \in C_j} \lVert x_i - \mu_j \rVert_2^2
$$ {#eq:kmeans}

Beispielhaft wurde für den Literaturkorpus ($n = 3733$) k = 4 gewählt, mit 20 Random Starts und Standard-Lloyd-Iteration (Konvergenz < 30 Iterationen); der Silhouette-Score lag bei $S \approx 0{,}9884$.

### 4.3.8 Visualisierte Korrelations- und Clusteranalysen {#sec:Korrelations-Cluster}

Zur Absicherung der deduktiven Clusterlogik wurden die zentralen Korrelations- und Clusterauswertungen in der Reihenfolge der Pipeline visualisiert: erst k-means, danach die FU-basierten Matrizen, anschließend Index- und Kategorienebene.

![Deduktive k-means-Clusteranalyse des Quellenkorpus.](08 Metaquellen/08-01 Abbildungen/methodik/clusteranalyse-kmeans-deduktiv-02-01-suchergebnisse.png){#fig:clusteranalyse-kmeans width=90%}

Die Abbildung zeigt die dreidimensionale, deduktiv angelegte Clusteranalyse des Literaturkorpus ($n = 3733$) auf Basis des $k$-Means-Algorithmus mit vier Clustern. Die Visualisierung projiziert die Datenpunkte entlang der drei deduktiv definierten Achsen Suchbegriffe, Kategorien und Forschungsfragen. Die Größe der Punkte repräsentiert die relative Clustergröße, während die farbliche Kodierung die thematische Zusammensetzung gemäß der zugrunde liegenden Tag-Struktur auswählt. Der insgesamt hohe Silhouette-Score ($S = 0{,}9884$) weist auf eine nahezu perfekte Trennschärfe hin, was sowohl die deduktive Vorstrukturierung als auch die semantische Stabilität der Cluster bestätigt.

**Analyse der Achsendimensionen**

Die drei Achsen bilden die theoretischen Dimensionen ab, die zuvor in Kapitel 4.2.3 und 4.3.1 bis 4.3.4 hergeleitet wurden:

- Suchbegriffe beschreiben die diskursiven Zugriffspunkte (z.B. „digital learning“, „online learning“, „learning management system“).
- Kategorien repräsentieren die deduktiv erstellten Inhaltsfelder (z.B. technologische Integration, Lehr- und Lerneffektivität, bildungswissenschaftliche Mechanismen).
- Forschungsfragen (FU1–FU7) bilden die oberste Deduktionsschicht, aus der die weiteren Analyseschritte abgeleitet wurden.

Durch diese Kombination entsteht ein semantischer, dreidimensionaler Raum, der die Struktur des Literaturkorpus entlang der zentralen Analyseachsen darstellt und eine geometrische Überprüfung der deduktiven Logik ermöglicht.

Die vier identifizierten Cluster sind deutlich voneinander abgegrenzt und bilden somit logisch konsistente Themenräume:

1. Cluster 1 (hellblau): Schwerpunkt im Schnittfeld digitale Medien, Buchtitel, Lernumgebung. Hoher Bezug zu FU3 (didaktische und technologische Merkmale).
2. Cluster 2 (dunkelblau): Fokus auf Online-Learning, Learning Analytics, bildwissenschaftlichen Theorien. Dominante Bezugspunkte zu FU4a und FU6.
3. Cluster 3 (grau): Bereich der technologiegestützten Lehr-Lern-Effektivität, oft verknüpft mit FU2a/b. Enthält Quellen, die empirische Wirkmechanismen, Vergleichsstudien und Evaluationsdesigns behandeln.
4. Cluster 4 (braun): Theoretische Kernliteratur (Kerngedanke der Promotion), mit starker Anbindung an Technologieintegration, Forschungsansätze und FU7. Auffällige Dichte an Basismodellen (TPACK, SDT, Systemtheorie).

#todo TPACK, SDT, Systemtheorie erklären bzw. referenzieren

Die Dreidimensionalität verdeutlicht, dass die deduktiven Achsen tatsächlich diskriminierende Kraft besitzen und die Literatur nicht durch zufällige Muster gruppiert wird, sondern strukturelle Kohärenzen im Diskurs sichtbar machen.

Methodologische Einordnung

Die Visualisierung erfüllt mehrere Funktionen innerhalb der mdaCV:

- Validierung der Deduktionslogik: Die drei Achsen sind nicht rein empirisch berechnet, sondern theoriebasiert definiert. Ihre Trennung im Raum zeigt, wie sich inhaltliche und methodische Ebenen der Literatur konsistent verhalten.
- Erkennung diskursiver Schwerpunktfelder: Die Cluster bilden unterschiedlich konzentrierte semantische Regionen ab (z.B. online learning $\to$ FU4a/FU6 vs. technologische Integration $\to$ FU3/FU7).
- Überprüfung der Segmentierungs- und Kategorisierungsentscheidungen: Die nahezu perfekte Silhouette zeigt, dass die Tags, Kategorien und FU-Zuordnungen in sich stabil und logisch aufgebaut sind, ohne Überlappungen, die auf methodische Unschärfe hindeuten würden.

Epistemische Funktion im Forschungsdesign

Die hohe Trennschärfe bestätigt, dass das Literaturfeld strukturell differenziert ist. Gleichzeitig ermöglichen die geometrischen Abstände eine Abschätzung, wie stark einzelne FU durch bestimmte Themenbereiche getragen werden.

Bedeutung für die Gesamtanalyse

Die 3D-Clusteranalyse wirkt als abschließende seismografische Validierungsstufe der vorangegangenen P-QIA und der mdaCV. Im Zusammenspiel mit der systematisch-forschungsfragengeleiteten Literaturpipeline ergibt sich damit ein methodischer Zugang, der etablierte Formen systematischer Reviews erweitert: Transparente Suchpfade, dokumentierte Screening- und Tagging-Schritte sowie standardisierte, GPT-unterstützte Inhaltsanalysen werden mit Netzwerk-, Pfad- und Korrelationsanalysen verknüpft. Die KI-Unterstützung fungiert dabei nicht als Ersatz, sondern als strukturierende Assistenz; alle Zuordnungen (Kategorien, FU, Relevanz) werden in einem zweiten Tagging-Schritt kontrolliert, konsolidiert und stichprobenartig manuell überprüft.

- Sie macht sichtbar, dass die Literaturbasis nicht nur volumetrisch, sondern auch semantisch ausgewogen ist.
- Sie zeigt, welche Themenräume dicht besetzt sind und welche die deduktiven Kategorien besonders stark stützen.
- Sie unterstreicht die Robustheit der Gesamtmethodik, indem sie die getrennten Analyseebenen (Suchbegriffe, Kategorien, FU) in einem kohärenten geometrischen Modell zusammenführt.

Damit bestätigt die 3D-Clusteranalyse die theoretisch-probabilistische Struktur des Forschungsdesigns und bietet einen visuell-analytischen Beleg dafür, dass die deduktive Kodierung, die P-QIA und die mdaCV konsistent ineinandergreifen. Zudem kann sie als Koherenzmaß der probabilistischen Analyse dienen, indem sie die semantische Struktur und Differenzierung des Literaturkorpus entlang der zentralen Analyseachsen verdeutlicht. Damit gelingt eine umfassende, methodisch stringent abgesicherte Kartierung des Forschungsfeldes und infolgedessen eine engere Verbindung zwischen deduktiver Theoriearbeit und datenbasierter Validierung.

Die korrelativen Visualisierungen stellen die semantischen Beziehungen zwischen den zentralen Analyseebenen des Literaturkorpus dar: Forschungsunterfragen (FU1–FU7), Kategorien, Indizes und Suchbegriffe. Sie ergänzen die dreidimensionale Clusteranalyse, indem sie die Stärke, Richtung und Verteilung der Beziehungen zwischen den deduktiv definierten Dimensionen sichtbar machen. Methodisch handelt es sich um eine quasi-multivariate Strukturanalyse, die die deduktive Architektur der mdaCV mit einer fein granulierten Beziehungssicht verbindet. Statt auf hohe absolute Korrelationswerte abzuzielen, liegt der Schwerpunkt auf Mustererkennung, semantischen Relationen und der Validierung der deduktiven Struktur. Die vollständigen Korrelationsmatrizen sind im \hyperref[sec:A-4]{Korrelationsatlas (Anhang A-4)} dokumentiert.

**Forschungsunterfragen × Forschungsunterfragen**

Die Korrelationsstruktur zwischen den Forschungsunterfragen dient der Validierung der deduktiven Logik und zeigt die Muster der Beziehungen, ohne dass hohe absolute Korrelationswerte im Vordergrund stehen. Entscheidend sind Verteilung, Richtung und relative Stärke der Zusammenhänge (vgl. \hyperref[fig:A-kor-fu]{Abb.~A.4.1}).

Analyse: Werte bleiben fast durchgängig im schwach negativen Bereich; punktuell leichte positive Ausreißer (z.B. FU4a/FU3). Es gibt keine dominanten Achsen, sondern ein fein gestreutes Muster mit einzelnen Verdichtungen bei FU4a.

Interpretation: Die FU sind inhaltlich sauber getrennt; die geringe Koppelung zeigt, dass die deduktive Struktur trägt und keine unbeabsichtigten Überschneidungen entstehen. Die wenigen positiven Paare markieren Anschlussstellen (z.B. FU4a $\leftrightarrow$ FU3) und bleiben methodisch tolerabel.

**Forschungsunterfragen × Suchbegriffe**

Die Korrelationsstruktur zwischen Forschungsunterfragen und Suchbegriffen dient der Validierung der deduktiven Logik und zeigt die Muster der Beziehungen, ohne dass hohe absolute Korrelationswerte im Vordergrund stehen. Entscheidend sind Verteilung, Richtung und relative Stärke der Zusammenhänge (vgl. \hyperref[fig:A-kor-fu-suchbegriffe]{Abb.~A.4.2}).

Analyse: Positiv verdichtet bei FU4a/FU4b in Kombination mit digital learning/medien und E‑Learning; geringe, vereinzelt negative Bezüge bei FU1/FU7 auf klassische Lernplattform-Begriffe. Werte bleiben insgesamt moderat.

Interpretation: Die Suchbegriffe spiegeln die thematische Fokussierung der FU wider (insb. FU4a/b), ohne Querbezüge zu dominieren. Das stützt die semantische Passung der Suchstring-Logik zu den FU-Schwerpunkten.

**Forschungsunterfragen × Kategorien**

Die Korrelationsstruktur zwischen Forschungsunterfragen und Kategorien dient der Validierung der deduktiven Logik und zeigt die Muster der Beziehungen, ohne dass hohe absolute Korrelationswerte im Vordergrund stehen. Entscheidend sind Verteilung, Richtung und relative Stärke der Zusammenhänge (vgl. \hyperref[fig:A-kor-fu-kategorien]{Abb.~A.4.3}).

Analyse: Schwerpunkte liegen bei „kerngedanke“ und „weiterführung“, jeweils mit moderaten positiven Bezügen zu FU4a, FU4b und FU5. „Argumentation“ koppelt erwartungsgemäß leicht an FU3/FU4a. Negative Werte bleiben marginal.

Interpretation: Die Kategorien greifen an den inhaltlich zugehörigen FU an und bleiben ansonsten entkoppelt. Die moderate Stärke stützt die deduktive Zuordnung und zeigt, dass Kategorien eher als Linsen denn als harte Cluster wirken.

**Forschungsunterfragen × Indizes**

Die Korrelationsstruktur zwischen Forschungsunterfragen und Indizes dient der Validierung der deduktiven Logik und zeigt die Muster der Beziehungen, ohne dass hohe absolute Korrelationswerte im Vordergrund stehen. Entscheidend sind Verteilung, Richtung und relative Stärke der Zusammenhänge (vgl. \hyperref[fig:A-kor-fu-indizes]{Abb.~A.4.4}).

Analyse: Stärkere positive Kopplungen bei technologische Integration, kollaboratives Lernen und Lehr-/Lerneffektivität, vor allem mit FU4a/b und FU6. Schwache oder neutrale Werte bei FU1/FU7; negative Ausreißer fehlen praktisch.

Interpretation: Die Index-Logik greift dort, wo die FU inhaltlich tief in Technologie- und Didaktikfragen eintauchen. Die gleichmäßige Verteilung ohne starke Negative zeigt, dass die Indizes die FU-Struktur stützen, nicht überlagern.

**Suchbegriffe × Suchbegriffe**

Die Korrelationsstruktur der Suchbegriffe dient der Validierung der deduktiven Logik und zeigt die Muster der Beziehungen, ohne dass hohe absolute Korrelationswerte im Vordergrund stehen. Entscheidend sind Verteilung, Richtung und relative Stärke der Zusammenhänge (vgl. \hyperref[fig:A-kor-suchbegriffe]{Abb.~A.4.5}).

Analyse: Schwach negative, punktuell positive Knoten entlang digital/blended learning; keine dominanten Hauptachsen. Querbezüge bleiben gering und verteilen sich auf wenige Suchwortpaare.

Interpretation: Die Suchbegriffe sind hinreichend fein granuliert, um Überschneidungen zu vermeiden. Das unterstreicht die Selektivität der Suchordner und verhindert semantische Überlappungen.

**Suchbegriffe × Kategorien**

Die Korrelationsstruktur zwischen Suchbegriffen und Kategorien dient der Validierung der deduktiven Logik und zeigt die Muster der Beziehungen, ohne dass hohe absolute Korrelationswerte im Vordergrund stehen. Entscheidend sind Verteilung, Richtung und relative Stärke der Zusammenhänge (vgl. \hyperref[fig:A-kor-suchbegriffe-kategorien]{Abb.~A.4.6}).

Analyse: Deutliche positive Bezüge zwischen digital/blended learning und den Kategorien „kerngedanke“/„weiterführung“; punktuell negative Werte bei einzelnen Medientiteln. Insgesamt bleibt das Niveau moderat.

Interpretation: Die Kategorien ziehen die Suchbegriffe an, die inhaltlich am Forschungsgegenstand anliegen; periphere Begriffe bleiben schwach oder negativ korreliert. Das bestätigt die Stringenz der dreistufigen Suchordner-Logik.

**Kategorien × Kategorien**

Die Korrelationsstruktur der Kategorien dient der Validierung der deduktiven Logik und zeigt die Muster der Beziehungen, ohne dass hohe absolute Korrelationswerte im Vordergrund stehen. Entscheidend sind Verteilung, Richtung und relative Stärke der Zusammenhänge (vgl. \hyperref[fig:A-kor-kategorien]{Abb.~A.4.7}).

Analyse: Vereinzelte, schwach positive Beziehungen zwischen „argumentation“/„kerngedanke“ und „weiterführung“; ansonsten überwiegend neutrale Felder und nur minimale Negativa.

Interpretation: Die Kategorien sind weitgehend orthogonal. Das stützt die Annahme, dass sie unterschiedliche argumentative Rollen adressieren und nicht kollabieren.

**Indizes × Indizes**

Die Korrelationsstruktur der Indizes dient der Validierung der deduktiven Logik und zeigt die Muster der Beziehungen, ohne dass hohe absolute Korrelationswerte im Vordergrund stehen. Entscheidend sind Verteilung, Richtung und relative Stärke der Zusammenhänge (vgl. \hyperref[fig:A-kor-indizes]{Abb.~A.4.8}).

Analyse: Deutliche positive Cluster bei technologische Integration, Datenschutz/IT-Sicherheit, kollaboratives Lernen und Lehr-/Lerneffektivität. Kaum negative Werte; neutrale Felder dominieren am Rand.

Interpretation: Die Indizes bilden ein konsistentes, technologie- und didaktikzentriertes Rückgrat. Die hohen Positiva zeigen, dass die deduktiven Achsen auch in der Index-Ebene kohärent wirken und sich gegenseitig verstärken.

**Indizes × Kategorien**

Die Korrelationsstruktur zwischen Indizes und Kategorien dient der Validierung der deduktiven Logik und zeigt die Muster der Beziehungen, ohne dass hohe absolute Korrelationswerte im Vordergrund stehen. Entscheidend sind Verteilung, Richtung und relative Stärke der Zusammenhänge (vgl. \hyperref[fig:A-kor-indizes-kategorien]{Abb.~A.4.9}).

Analyse: Positive Schwerpunkte zwischen „kerngedanke“/„weiterführung“ und Indizes zu technologische Integration, kollaboratives Lernen und Datenschutz/IT-Sicherheit; „argumentation“ koppelt moderat an Lehr-/Lerneffektivität. Negative Werte fehlen praktisch.

Interpretation: Kategorien greifen erwartungsgemäß an den technologie- und didaktiknahen Indizes an. Das Muster zeigt, dass die inhaltlichen Kategorien nicht diffundieren, sondern entlang der deduktiv gesetzten Indexachsen andocken.

**Indizes × Suchbegriffe**

Die Korrelationsstruktur zwischen Indizes und Suchbegriffen dient der Validierung der deduktiven Logik und zeigt die Muster der Beziehungen, ohne dass hohe absolute Korrelationswerte im Vordergrund stehen. Entscheidend sind Verteilung, Richtung und relative Stärke der Zusammenhänge (vgl. \hyperref[fig:A-kor-indizes-suchbegriffe]{Abb.~A.4.10}).

Analyse: Klar positive Paare bei technologische Integration, Bewertungsmethoden und kollaboratives Lernen mit Suchbegriffen zu digital learning, E‑Learning und blended learning. Negative Werte tauchen v.a. bei spezifischen Medientiteln auf, bleiben aber schwach.

Interpretation: Die Suchbegriffe folgen den indexbasierten Schwerpunkten und differenzieren sauber zwischen technologie-/didaktiknahen und peripheren Termfeldern. Das bestätigt die semantische Passung der Suchstrings zur Indexlogik.

### 4.3.9 Auswertung: Eye-Tracking und Umfrage im Vergleich {#sec:EyeTracking-Umfrage-Vergleich}

Die Auswertung koppelt Eye-Tracking-Befunde mit den Selbstauskünften der LMS-Umfrage, um Wahrnehmung und tatsächliche Aufmerksamkeit auf UI-Elemente zusammenzuführen.

- **Stichprobe/Repräsentativität (Eye-Tracking):** Kurs 21-NFS-09: $80\,\%$ ($95\,\%$-KI: $56{,}15$–$103{,}85\,\%$), Kurs 22-NFS-09: $72{,}73\,\%$ ($49{,}73$–$95{,}73\,\%$), Kurs 23-NFS-09: $33{,}33\,\%$ ($17{,}77$–$48{,}89\,\%$), Gesamt: $53{,}33\,\%$ ($44{,}51$–$62{,}15\,\%$). Identische Teilnehmendenzahl je Jahrgang ermöglicht vergleichbare AOI-Analysen; breite KIs in kleinen Kursen werden in der Interpretation berücksichtigt.
- **Eye-Tracking-Befunde (Beispiele):** Heatmaps/Viewmaps/Fog‑Views pro Stimulus zeigen Aufmerksamkeitszentren, Blickpfadtypiken und unbeachtete Zonen. Auffällige Muster werden als technisch‑gestalterische Mechanismen (FU4b) beschrieben und für den Abgleich mit Selbstauskünften operationalisiert.
- **Umfrage-Befunde (Struktur):** Itemweise deskriptive Kennzahlen (Likert/binar) je Jahrgang und Gesamtstichprobe; Freitext separat. Die Zuordnung „Frage → Begriffspaar → Einfluss“ (Synopse) dient als Brücke zur weiteren Verdichtung/Modellierung.
- **Triangulation:** Kongruenzen (z.B. hohe berichtete Nützlichkeit + hohe Dwell Time auf relevanten AOIs) stützen die Wirksamkeit der UI; Divergenzen (z.B. berichtet hoher Nutzen, aber geringe AOI-Aufmerksamkeit) markieren Interface-/Erwartungsbrüche und fließen in die Diskussion ein.
- **Limitierungen:** Ökologische Validität des Labors, potenzielle Reaktivität, breite KIs in kleinen Kursen, Selbstselektion in der Umfrage. Diese Punkte werden in Kapitel 4.2.4/4.2.5 adressiert und in der Ergebnisinterpretation transparent gemacht.

#todo Eye-Tracking-Stichprobe und Stimulusreferenzen (F10-S3, F11-S3, F14-S3, Gesamt-Visuals) hier knapp einfügen; Triangulation mit Umfragezahlen benennen.

Eine systematische Reflexion der Eye-Tracking-Daten erfolgt im Rahmen der methodenkritischen SWOT-Analyse (vgl. Abschnitt 4.5.1), um Potenziale und Limitationen der empirischen Erhebung im Zusammenspiel mit generativer KI zu analysieren.

## 4.4 Simulationsgestützte Modellierung der Kompetenzentwicklung {#sec:Simulation-Kompetenzentwicklung}

## 4.5 Reflexion der Methode {#sec:Methoden-Reflexion}

Die kritische Methodenreflexion hat den Zweck, die eigene Arbeitsweise transparent, nachvollziehbar und anhand des wissenschaftlichen Qualitätskriteriums „Methodische Strenge“ [@doring_forschungsmethoden_2023, Seite 89-90] beurteilbar zu machen. Inwiefern diese Arbeit die Anforderungen an eine methodisch saubere, nachvollziehbare und theoriegeleitete Forschung erfüllt, ist in diesem Kapitel zu klären.

Als Herleitungsgrundlage kann ein systemisch-konstruktivistisches Verständnis von Erkenntnis angesetzt werden, das mit bewährten Evaluationsmodellen (z. B. dem CIPP-Modell nach Stufflebeam in [@hanisch_nachhaltiges_2017, Kapitel  3.1]) sowie analytischen Verfahren wie Korrelations- und deduktiven Clusteranalysen verbunden wird. Diese Kombination ist weder beliebig noch additiv, sondern strukturell aufeinander bezogen und somit theoriekompatibel. Die Auswahl der Methoden ergibt sich aus der forschungsfragengeleiteten Logik. Sie folgt keiner Paradigmentreue, sondern einem funktionalen Verständnis von Methodeneinsatz und hat zur Folge, dass qualitative und quantitative Verfahren entlang der FU dort eingesetzt werden, wo sie zur Bearbeitung beitragen. Die theoretischen Begriffe (z. B. Kompetenz, Selbstorganisation, Nachhaltigkeit) werden auf konkrete Analyseebenen übertragen, etwa über Prädiktorvariablen (z. B. PV1a-PV3 bei Hanisch [-@hanisch_nachhaltiges_2017, Kapitel  3.4]) oder KI-gestützte Analysen . Sämtliche Analyseprozesse, von der Auswahl der Quellen, über die Generierung und Anwendung der Prompts, bis hin zur Auswertung und Rückführung in die FU, sind dokumentiert, versioniert und theoretisch hergeleitet. Die Struktur folgt einer nachvollziehenden analytischen Logik, die von der FU über die erste KI-gestützte Analyse bis zur Metaebene mit Clusterauswertungen übergeht. Als kuratierende Hilfsmittel unterstützen digitale Werkzeuge, unter deren Verwendung das Literatur- und Notizmanagement (Zotero), die Versionierungen (Gitea), sowie die statistischen Berechnungen und Visualisierungen (Python) durchgeführt werden konnten. Diese Kombination von Methoden und Werkzeugen gewährleistet sowohl Reproduzierbarkeit als auch in sich Konsistenz.

Bereits in der Zusammenstellung der Analyseeinheiten erfolgen bewusste Entscheidungen, zum Beispiel zur Nichtberücksichtigung von Masterarbeiten und reiner „grauer Literatur“ in bestimmten Clusteranalysen. Diese Schritte werden transparent dokumentiert und theoriebezogen begründet, wodurch sich die Validität der Aussagen erhöht.

Ein wesentlicher Bestandteil des methodischen Vorgehens ist die fortlaufende Selbstprüfung und Justierung. Dazu gehören die Prüfung der Wirksamkeit der Prompts, die Diskussion der Silhouette-Werte zur Clustertrennschärfe, aber auch die bewusste Unterscheidung zwischen Analysen 1. Ordnung (einzelne Quelle) und Analysen 2. Ordnung (übergreifende Auswertung, Rückführung auf die FU).
Mein methodisches Vorgehen erfüllt, trotz seiner systemisch-flexiblen Struktur, zentrale Anforderungen wissenschaftlicher Strenge. Die Methoden sind theoriebasiert, nachvollziehbar, funktional gewählt und systematisch eingesetzt. Zugleich werden klassische Evaluationsverfahren in ein offenes, komplexitätssensibles Design integriert.

Infolgedessen liegt die wissenschaftliche Eigenleistung in der Strukturierung des Analyseprozesses, der Definition und Trennung der Ordnungsebenen (1. Ordnung: Analyse, 2. Ordnung: Bewertung), der methodologischen Fundierung (deduktiv und theoriebasiert) sowie in der reflexiven Kontrolle des Systems. Dieses Vorgehen ist eigenständig, transparent dokumentiert und methodologisch weiterentwickelnd.

### 4.5.1 Methodenkritische SWOT-Analyse zum KI-gestützten Vorgehen

Die SWOT-Analyse wird im Rahmen dieser Arbeit als methodisches Reflexionsinstrument eingesetzt, um die Anwendung generativer KI in der literatur- und datengestützten Analyse systematisch zu bewerten. Sie dient neben der Auflistung von Aspekten, weiterhin strukturiert die Auseinandersetzung mit methodischer Robustheit, epistemologischen Potenzialen und Grenzen des gewählten Vorgehens. Damit werden die systemtheoretisch motivierte Forschungsperspektive und eine strategische Betrachtung der methodischen Güte miteinander verknüpft. Hierbei finden interne Faktoren (Stärken, Schwächen) und externe Rahmenbedingungen (Chancen, Risiken) Berücksichtigung. Orientierung bieten die Leitlinien zur SWOT-Analyse im wissenschaftlichen Kontext bei @niederberger_swot-analyse_2015, Seite 35–38 und @hogan_swot-analyse_2009, Seite 258–259.

Table: SWOT-Analyse des KI-gestützten methodischen Vorgehens \label{tab:swot_ki_methodik}

| Kategorie | Inhalt | Maßnahme |
|----------|--------|----------|
| **Stärken** | Analysegeschwindigkeit; transparente Analysepfade; skalierbare Reproduktion (Prompts/Skripte); hohe Clustertrennschärfe; Verbindung qualitativer und quantitativer Auswertung. | Versionierung aller Schritte; reproduzierbare Dokumentation; Sensitivitätsanalysen (Variation von *k*, erneute Clusterläufe). |
| **Schwächen** | Interpretationsspielräume (Black-Box); mögliche algorithmische Verzerrungen; Gefahr, dass Kennwerte Reflexion überlagern; hoher Initialaufwand für Kategorien, Prompts und Pipelines. | Protokollierung aller Parameter; Abgleich der Clusterstruktur mit theoriegeleiteten Kategorien; iterative Prompt-Revision; Voranstellen inhaltlicher Interpretation vor Kennwerten. |
| **Chancen** | Ergänzung klassischer Verfahren um Prüfgrößen (Silhouette, mdaCV); methodische Innovation (P-QIA, mdaCV); Erschließung großer Literaturkorpora; Förderung kollaborativer, versionierter Erkenntnissysteme. | Anwendung auf alle relevanten FU; Vergleich unterschiedlicher Modellläufe; Veröffentlichung von Skripten und Dokumentation; Einbettung in eine datenbasierte Curriculumsforschung. |
| **Risiken** | Scheinobjektivität der Kennwerte; ethische Fragen (Delegation von Bewertung, Datenumgang); Abhängigkeit von Modellarchitekturen/Infrastruktur; Replikationsrisiken; Unterschätzung manueller Kontextkenntnis. | Reflexionspassagen im Methodikteil; Benennung von Grenzen und Annahmen; manuelle Stichproben-Codierungen; Auswahl datenschutzkonformer Umgebungen; Replikationsstrategien bei Modellaktualisierungen. |

Die Tabelle bündelt damit die zentralen Befunde und zeigt, welche Maßnahmen unmittelbar mitgeführt werden. Die Stärken (Transparenz, Reproduzierbarkeit und Trennschärfe) werden neben den abstrakten Zuschreibungen in Sensitivitätsanalysen, Versionierungen und reproduzierbaren Dokumentationsketten aktiv genutzt.

Die SWOT-Analyse zeigt Schwächen und Risiken als kontinuierliche Arbeitsaufträge. Interpretationsspielräume, algorithmische Verzerrungen oder Modellabhängigkeiten bleiben nicht unbenannt; sie werden durch theoriegeleitete Gegenlesungen, manuelle Plausibilitätsprüfungen und die bewusste Begrenzung einzelner Kennwerte adressiert. Chancen und Risiken greifen ineinander, und erst in einem verantwortungsbewussten, theorieorientierten und transparent dokumentierten Methodendesign entfalten KI-gestützte Analysen ihren Mehrwert als Ergänzung klassischer Verfahren.

Methodische Stärken

- Forschungsfragengeleiteter Ansatz mit systemischer Perspektive.
- Kombination klassischer Methoden (Literatur, Simulation, Eye-Tracking) mit innovativen Ansätzen (KI, Python).

Methodische Herausforderungen und Limitationen

- Herausforderungen:
  - Retrospektive Integration einiger Methoden.
  - Entwicklung eines eigenen Paradigmas zur Bearbeitung der Forschungsfragen.
- Limitationen:
  - Komplexität der Datenintegration.
  - Abhängigkeit von KI-Tools und Simulationen.
