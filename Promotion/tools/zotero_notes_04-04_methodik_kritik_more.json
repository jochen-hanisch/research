[
  {
    "attachmentKey": "ND92B4LM",
    "shortTitle": "Van Niekerk et al. (2025) – Generative AI in Academic Writing",
    "tags": ["Methodenkritik", "GenAI", "Halluzinationen", "Referenzen", "Bias"],
    "noteHtml": "<p><strong>Methodenkritik (Anschlussstelle: KI-gest\u00fctzte Literatur-/Textarbeit, Evidenzlogik, Referenzpr\u00fcfung)</strong></p><p>Der Beitrag adressiert genau die Stelle, an der eine KI-gest\u00fctzte Analyse in meiner Methodik angreifbar w\u00e4re: GenAI kann falsche bzw. fabrizierte Informationen liefern (Halluzinationen) und damit die Evidenzlogik einer Argumentation unterlaufen; zugleich wird der Punkt gemacht, dass damit nicht nur Fakten, sondern auch die Eigenleistung im Sinne origin\u00e4rer gedanklicher Formulierungs- und Bewertungsarbeit tangiert ist. F\u00fcr mein Vorgehen folgt daraus, dass GenAI nicht als Quelle/Autor behandelt wird, sondern als Arbeitsoberfl\u00e4che, deren Outputs in jedem Schritt an Prim\u00e4rtexte zur\u00fcckgebunden und gegenpr\u00fcfbar dokumentiert werden m\u00fcssen. (Van Niekerk et al., 2025, S. 2)</p><p>Besonders anschlussf\u00e4hig ist die konkrete Operationalisierung: Studierende sollen Referenzen, die von ChatGPT in einem generierten Text genannt werden, aktiv auf Existenz pr\u00fcfen, um fabrizierte Zitationen auszuschlie\u00dfen, und erst danach die Qualit\u00e4t der Quelle bewerten. Das ist f\u00fcr meine Methodik ein direktes Argument f\u00fcr ein verpflichtendes Referenz-Audit (Existenz, Passung, Prim\u00e4rquelle) als Teil des Workflows. (Van Niekerk et al., 2025, S. 4)</p><p>Zus\u00e4tzlich wird die Notwendigkeit klarer Anleitung und Interventionen betont, um Missbrauch bzw. unangemessene Nutzung zu begrenzen. Das st\u00fctzt in meiner Methodik die Entscheidung, Governance nicht als Randthema zu f\u00fchren, sondern als Bestandteil der Methode (Leitplanken, Offenlegung, Pr\u00fcfroutinen). (Van Niekerk et al., 2025, S. 10)</p>"
  },
  {
    "attachmentKey": "6DDDWQ6N",
    "shortTitle": "Biswas (2023) – ChatGPT for Research and Publication",
    "tags": ["Methodenkritik", "GenAI", "Ethik", "Bias", "Plagiat"],
    "noteHtml": "<p><strong>Methodenkritik (Anschlussstelle: Promptworkflow, wissenschaftliche Integrit\u00e4t, Grenzen der Delegation)</strong></p><p>Biswas rahmt ChatGPT explizit als Tool, das nur unter ethischer Reflexion sinnvoll integrierbar ist: Bias, Interpretierbarkeit und Plagiatsrisiken werden als zentrale Problemzonen markiert. Das st\u00fctzt in meiner Methodik die Setzung, dass KI-Ausgaben nicht als Ergebnis gelten, sondern als Vorstufe, die durch menschliche Pr\u00fcfung, argumentative Einordnung und referenzierte Nachweise stabilisiert werden muss. (Biswas, 2023, S. 1)</p><p>Sehr klar wird die rote Linie im Methodendesign gezogen: ChatGPT darf nicht zur Fabrikation von Daten oder Ergebnissen eingesetzt werden; bestimmte Abschnitte (hier: Patientendaten/Results) m\u00fcssen authentisch bleiben und k\u00f6nnen nicht an das Modell delegiert werden. Das ist ein direktes Argument, die Delegationsgrenze in meiner Methodik explizit zu markieren (was KI darf und was nicht) und die Authentizit\u00e4t von Daten/Ergebnissen als nicht substituierbaren Kern auszuweisen. (Biswas, 2023, S. 7)</p>"
  },
  {
    "attachmentKey": "6S432NV7",
    "shortTitle": "Parker et al. (2024) – AI in Doctoral Writing Pedagogy",
    "tags": ["Methodenkritik", "GenAI", "Academic Integrity", "AI Literacy", "Policy"],
    "noteHtml": "<p><strong>Methodenkritik (Anschlussstelle: KI im Schreib-/Syntheseprozess, Integrit\u00e4t, institutionelle Leitplanken)</strong></p><p>Der Beitrag positioniert den KI-Einsatz im Doktorandenschreiben als hybriden Prozess, der kognitiv/metakognitiv produktiv sein kann, aber unmittelbar Fragen der akademischen Integrit\u00e4t und der notwendigen AI-Literacy aufruft. F\u00fcr mein Vorgehen ist das ein Argument, KI-Nutzung nicht stillschweigend als \u201enormalen Workflow\u201c zu behandeln, sondern sie explizit als methodisch kontrollierten Teilprozess mit offengelegter Rolle zu f\u00fchren. (Parker et al., 2024, S. 1)</p><p>Gleichzeitig wird der Risikohorizont f\u00fcr akademisches Schreiben stark gemacht: Mit dem Konzept \u201epostplagiarism\u201c wird beschrieben, dass hybride Human-KI-Texterzeugung neue Integrit\u00e4tsfragen aufwirft und klassische Grenzziehungen (Plagiat/Autorenschaft) verschiebt. Das unterst\u00fctzt die Notwendigkeit, meine methodische Autorenschaft \u00fcber Pr\u00fcf- und Dokumentationslogiken sichtbar zu halten (Entscheidungsketten, Begr\u00fcndungen, Revisionen), statt KI-Outputs in die Argumentation zu \u201everstecken\u201c. (Parker et al., 2024, S. 2)</p><p>Sehr konkret wird zudem der Bedarf nach klaren Policies herausgestellt, die angemessene Nutzung demarkieren; fehlende/inkonsistente Kursregeln f\u00fchren zu stark divergierenden Nutzungsstrategien. Das st\u00fctzt in meiner Methodik die Entscheidung, Leitplanken (Do/Don\u2019t, Offenlegung, Pr\u00fcfroutinen) nicht implizit zu lassen, sondern als methodischen Standard festzuschreiben. (Parker et al., 2024, S. 13)</p>"
  },
  {
    "attachmentKey": "2U8T92S8",
    "shortTitle": "Rakhlin & Caponnetto (o. J.) – Stability of K-Means Clustering",
    "tags": ["Methodenkritik", "Clustering", "Stability", "K-Means"],
    "noteHtml": "<p><strong>Methodenkritik (Anschlussstelle: Clustering/Segmentierung im embedding-basierten Workflow, Robustheit der Kategorien)</strong></p><p>Der Beitrag liefert die theoretische Sch\u00e4rfung f\u00fcr eine typische Schwachstelle embedding-basierter Strukturierungen: K-Means l\u00e4sst sich als Empirical-Risk-Minimization fassen, und Stabilit\u00e4t ist nicht garantiert, sondern an die Geometrie der Zielfunktion bzw. an die Frage gekoppelt, ob ein eindeutiger globaler Minimierer existiert. Im Fall eines eindeutigen globalen Minimierers ist die L\u00f6sung stabil, bei mehreren Minimierern existiert ein Bereich, in dem relativ moderate Stichproben\u00e4nderungen einen Stabilit\u00e4ts-zu-Instabilit\u00e4ts-\u00dcbergang ausl\u00f6sen k\u00f6nnen. Das st\u00fctzt in meiner Methodik die Forderung nach Robustheitspr\u00fcfungen (Sensitivit\u00e4t \u00fcber Seeds/Splits/Resampling) und die Zur\u00fcckbindung der Clusterverdichtungen an interpretative Anker, statt Cluster als \u201enat\u00fcrliche\u201c Kategorien zu reifizieren. (Rakhlin & Caponnetto, o. J., S. 1\u20132)</p><p>Wichtig ist auch der methodische Hinweis, dass Stabilit\u00e4t in der Praxis h\u00e4ufig zur Wahl von K verwendet wird und deshalb theoretisch fundierte Rezepte ben\u00f6tigt. F\u00fcr mein Vorgehen hei\u00dft das: K wird nicht allein \u00fcber eine scheinbare Stabilit\u00e4t gesetzt, sondern \u00fcber eine Kombination aus theoriegeleiteten Erwartungen, empirischer Pr\u00fcfung und dokumentierten Alternativen. (Rakhlin & Caponnetto, o. J., S. 1)</p>"
  },
  {
    "attachmentKey": "KCRJNPVK",
    "shortTitle": "Yang & Krajbich (2021) – Webcam-Based Online Eye-Tracking",
    "tags": ["Methodenkritik", "Eye-Tracking", "Webcam", "Calibration", "Selection Bias"],
    "noteHtml": "<p><strong>Methodenkritik (Anschlussstelle: webcam-basiertes Eye-Tracking, Datenqualit\u00e4t, Ausschlusslogiken)</strong></p><p>Yang & Krajbich begr\u00fcnden, warum webcam-basiertes Eye-Tracking in Behavioral Research bislang z\u00f6gerlich eingesetzt wird: u. a. wegen aufwendiger Kalibrier-/Validierungsprozeduren, inkonsistenter zeitlicher Aufl\u00f6sung und Integrationsaufwand. Auch wenn sie technische Verbesserungen berichten (u. a. bessere Temporalaufl\u00f6sung), bleibt methodisch entscheidend, dass Datenerhebung ohne strenge Qualit\u00e4tskontrollen (Calibration/Validation, laufende Checks) nicht tragf\u00e4hig ist. Das st\u00fctzt in meiner Methodik die Setzung, Eye-Tracking als qualifikationsbed\u00fcrftige Zusatzspur zu f\u00fchren und Validierungslogiken nicht zu \u00fcberspringen. (Yang & Krajbich, 2021, S. 1)</p><p>Der Beitrag liefert zudem eine sehr konkrete Grenze: Online-Settings produzieren hohe Ausschlussraten; in ihrer Studie wird ein gro\u00dfer Teil der Probanden ausgeschlossen (hier: mehr als die H\u00e4lfte), woraus potenzielle Selektions- und Generalisierbarkeitsprobleme folgen. F\u00fcr mein Vorgehen hei\u00dft das, dass Ausschlusskriterien, Abbruchraten und Hardwarechecks als Teil der Methode transparent zu berichten und in der Interpretation mitzudenken sind. (Yang & Krajbich, 2021, S. 17)</p><p>Schlie\u00dflich wird die Frage der Persistenz der r\u00e4umlichen Aufl\u00f6sung \u00fcber die Zeit als offenes Problem markiert; daher sind laufende Validierungspunkte bzw. Rekalibrationen als Designentscheidung methodisch begr\u00fcndbar. (Yang & Krajbich, 2021, S. 9)</p>"
  },
  {
    "attachmentKey": "V3KW4HTL",
    "shortTitle": "Wisiecka et al. (2022) – Comparison of Webcam and Remote Eye Tracking",
    "tags": ["Methodenkritik", "Eye-Tracking", "Webcam", "Measurement Error"],
    "noteHtml": "<p><strong>Methodenkritik (Anschlussstelle: Messfehler von webcam-basiertem Eye-Tracking, Interpretationsgrenzen)</strong></p><p>Der Beitrag liefert eine klare, empirische Einordnung: Webcam-basiertes Eye-Tracking wird zwar als vielversprechend gerahmt, aber zugleich explizit mit geringerer Accuracy und Precision verbunden; damit ist die Methode als skalierbarer N\u00e4herungszugang zu verstehen, nicht als gleichwertiger Ersatz f\u00fcr pr\u00e4zise Labormessungen. Das st\u00fctzt in meiner Methodik die Entscheidung, gaze-basierte Befunde nur in robusten/aggregierten Formen zu interpretieren und argumentativ zu triangulieren. (Wisiecka et al., 2022, S. 1)</p><p>F\u00fcr die Operationalisierung ist die Messfehleranalyse zentral: In der Punktdetektionsaufgabe zeigt sich ein signifikanter Unterschied der Messfehler zwischen Bedingungen; der durchschnittliche Fehler ist in der Webcam-Bedingung h\u00f6her (M = 45.1px, SE = 2.81) als in der Remote-Bedingung (M = 34.2px, SE = 2.75). Damit wird Messfehler als systematischer Faktor sichtbar, der in der Interpretation (AOIs, Schwellen, Sensitivit\u00e4t) ber\u00fccksichtigt werden muss. (Wisiecka et al., 2022, S. 5)</p>"
  },
  {
    "attachmentKey": "UKNUDS9S",
    "shortTitle": "Dominici et al. (2024) – Causal Opacity and Verification",
    "tags": ["Methodenkritik", "Embeddings", "Opacity", "Verification", "Interpretability"],
    "noteHtml": "<p><strong>Methodenkritik (Anschlussstelle: Embeddings als latenter Ordnungsraum, Opazit\u00e4t, Verifikation)</strong></p><p>Dominici et al. liefern die argumentative Grundlage, um Embeddings als leistungsf\u00e4hige Verdichtungsstufe zu nutzen, ohne sie zur Erkl\u00e4rungsebene zu \u00fcberh\u00f6hen: Causal opacity wird als Schwierigkeit gefasst, die \u201eversteckte\u201c Struktur eines DNN zu verstehen; daraus folgt eine eingeschr\u00e4nkte F\u00e4higkeit, Systeme (insbesondere in sensiblen Kontexten) verl\u00e4sslich zu pr\u00fcfen und auf sie zu vertrauen. \u00dcbertragen auf mein Vorgehen st\u00fctzt das die Forderung nach expliziten Pr\u00fcf- und Dokumentationslogiken, wenn embedding-basierte Ordnungen in Kategorien \u00fcbersetzt werden (Audit-Trail, Ankerbeispiele, manuelle R\u00fcckbindung). (Dominici et al., 2024, S. 1)</p>"
  },
  {
    "attachmentKey": "WY86HJ85",
    "shortTitle": "Geyer & Stampfl (2025) – Wissenschaftliches Schreiben und KI",
    "tags": ["Methodenkritik", "GenAI", "Validierung", "Transparenz", "Wissenschaftliche Integrität"],
    "noteHtml": "<p><strong>Methodenkritik (Anschlussstelle: KI im wissenschaftlichen Schreiben, Validierung, Prozessdokumentation)</strong></p><p>Der Beitrag rahmt das zentrale Spannungsfeld, das ich methodisch adressieren muss: KI-Systeme bringen Effizienzgewinne, erzeugen aber epistemische Risiken (u. a. Halluzinationen, ideologische Verzerrungen, sprachliche Homogenisierung). Damit ist klar, dass KI-Ausgaben nicht als \u201eWissen\u201c behandelt werden d\u00fcrfen, sondern als vorl\u00e4ufige Vorschl\u00e4ge, die eine kritische Pr\u00fcfung erfordern. (Geyer & Stampfl, 2025, S. 1)</p><p>Sehr anschlussf\u00e4hig f\u00fcr die Methodik ist die Forderung nach menschlicher Aufsicht: Um Verzerrungen und Fehlinformationen zu vermeiden, bleibt menschliche Kontrolle zentral; daraus wird abgeleitet, dass eine kritische Evaluation der Limitationen von KI-Systemen f\u00fcr die Wahrung wissenschaftlicher Integrit\u00e4t notwendig ist. Das st\u00fctzt in meinem Vorgehen die konsequente R\u00fcckbindung an Prim\u00e4rtexte und die explizite Validierungslogik (nicht nur Ergebnis, sondern Prozess). (Geyer & Stampfl, 2025, S. 9)</p><p>Zus\u00e4tzlich wird das Validierungsproblem bei der Erkennung KI-generierter Texte betont und als praktikabler L\u00f6sungsansatz eine transparente Prozessdokumentation des KI-Einsatzes vorgeschlagen (z. B. tabellarische Erfassung von Systemen, Funktionen, Einsatzgebieten und Revisionen). Damit kann ich die Offenlegung als methodischen Standard begr\u00fcnden, statt sie als formale Ethikfloskel zu behandeln. (Geyer & Stampfl, 2025, S. 10)</p>"
  }
]

